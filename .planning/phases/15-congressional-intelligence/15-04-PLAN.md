---
phase: 15-congressional-intelligence
plan: 04
type: execute
wave: 2
depends_on: [15-01]
files_modified:
  - src/scrapers/congress_gov.py
  - scripts/build_congressional_intel.py
  - config/scanner_config.json
  - data/congressional_intel.json
autonomous: true

must_haves:
  truths:
    - "CongressGovScraper._fetch_bill_detail() fetches sponsors, actions, cosponsors, subjects, and text URLs from Congress.gov API sub-endpoints for a given bill"
    - "Bill-to-program mapping scores each bill against 16 tracked programs using subject overlap, CFDA references, and keyword matching with relevance threshold 0.30"
    - "congressional_intel.json contains bill records validated against BillIntelligence Pydantic model with matched_programs and relevance_score fields populated"
    - "Delegation data in congressional_cache.json is enhanced with committee assignments already present; voting records noted as pending Senate API availability"
    - "API key is used via X-Api-Key header (not query params); rate limit respected with 0.3s delays"
  artifacts:
    - path: "src/scrapers/congress_gov.py"
      provides: "Bill detail fetching with sub-endpoint queries"
      contains: "_fetch_bill_detail"
    - path: "scripts/build_congressional_intel.py"
      provides: "Bill intelligence cache builder"
      contains: "build_congressional_intel"
    - path: "config/scanner_config.json"
      provides: "Congressional intelligence configuration section"
      contains: "congressional_intel"
    - path: "data/congressional_intel.json"
      provides: "Cached bill intelligence data"
  key_links:
    - from: "src/scrapers/congress_gov.py"
      to: "data/congressional_intel.json"
      via: "build_congressional_intel.py orchestrates scraper -> file"
    - from: "scripts/build_congressional_intel.py"
      to: "src/schemas/models.py"
      via: "Validates bill data against BillIntelligence model from Plan 01"
    - from: "config/scanner_config.json"
      to: "src/scrapers/congress_gov.py"
      via: "congressional_intel config section drives bill detail parameters"
---

<objective>
Extend the Congress.gov scraper with bill detail fetching (sub-endpoints for sponsors, actions, cosponsors, subjects, text URLs), implement bill-to-program relevance mapping, and create the congressional intelligence cache builder script that produces data/congressional_intel.json.

Purpose: INTEL-01 (bill detail fetcher), INTEL-03 (bill-to-program mapping), and INTEL-04 (delegation enhancement) enable the DOCX renderers (Plan 05) to include real congressional intelligence in advocacy packets.

Output: Extended scraper, new cache builder script, config updates, and congressional_intel.json cache file.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/15-congressional-intelligence/15-RESEARCH.md
@.planning/phases/15-congressional-intelligence/15-CONTEXT.md
@.planning/phases/15-congressional-intelligence/15-01-SUMMARY.md
@src/scrapers/congress_gov.py
@src/scrapers/base.py
@scripts/build_congress_cache.py
@config/scanner_config.json
@data/program_inventory.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add bill detail fetching to CongressGovScraper</name>
  <files>src/scrapers/congress_gov.py</files>
  <action>
Add a new async method `_fetch_bill_detail()` to CongressGovScraper:

```python
async def _fetch_bill_detail(
    self, session, congress: int, bill_type: str, bill_number: str,
) -> dict:
    """Fetch full bill detail including sponsors, actions, cosponsors, subjects, text.

    Queries 4 sub-endpoints of the Congress.gov API v3 for a specific bill:
    /actions, /cosponsors, /subjects, /text. The main bill record includes
    sponsor info inline.

    Args:
        session: aiohttp ClientSession.
        congress: Congress number (e.g., 119).
        bill_type: Bill type code (hr, s, etc.) -- lowercase for URL.
        bill_number: Bill number as string.

    Returns:
        Dict with keys: bill, actions, cosponsors, subjects, policy_area, text_versions.
    """
    base = f"{self.base_url}/bill/{congress}/{bill_type.lower()}/{bill_number}"

    # Main bill detail (includes sponsor inline)
    detail = await self._request_with_retry(session, "GET", base)
    bill = detail.get("bill", {})

    # Sub-endpoint fetches with individual error handling
    actions = []
    cosponsors = []
    subjects = []
    policy_area = {}
    text_versions = []

    try:
        actions_data = await self._request_with_retry(
            session, "GET", f"{base}/actions?limit=250"
        )
        actions = actions_data.get("actions", [])
    except Exception:
        logger.warning("Failed to fetch actions for %s-%s-%s", congress, bill_type, bill_number)

    await asyncio.sleep(0.3)

    try:
        cosponsors_data = await self._request_with_retry(
            session, "GET", f"{base}/cosponsors?limit=250"
        )
        cosponsors = cosponsors_data.get("cosponsors", [])
    except Exception:
        logger.warning("Failed to fetch cosponsors for %s-%s-%s", congress, bill_type, bill_number)

    await asyncio.sleep(0.3)

    try:
        subjects_data = await self._request_with_retry(
            session, "GET", f"{base}/subjects?limit=250"
        )
        subj = subjects_data.get("subjects", {})
        subjects = subj.get("legislativeSubjects", [])
        policy_area = subj.get("policyArea", {})
    except Exception:
        logger.warning("Failed to fetch subjects for %s-%s-%s", congress, bill_type, bill_number)

    await asyncio.sleep(0.3)

    try:
        text_data = await self._request_with_retry(
            session, "GET", f"{base}/text?limit=20"
        )
        text_versions = text_data.get("textVersions", [])
    except Exception:
        logger.warning("Failed to fetch text for %s-%s-%s", congress, bill_type, bill_number)

    return {
        "bill": bill,
        "actions": actions,
        "cosponsors": cosponsors,
        "subjects": subjects,
        "policy_area": policy_area,
        "text_versions": text_versions,
    }
```

Key constraints:
- API key via X-Api-Key header (already set in __init__)
- 0.3s delay between sub-endpoint fetches (rate limit safety)
- Individual try/except per sub-endpoint so one failure doesn't lose all data
- Use existing `_request_with_retry` from BaseScraper
  </action>
  <verify>
Read the modified file to confirm _fetch_bill_detail exists with 4 sub-endpoint fetches, 0.3s delays, and error handling per sub-endpoint.
  </verify>
  <done>CongressGovScraper._fetch_bill_detail() fetches bill + 4 sub-endpoints with rate limiting and graceful degradation.</done>
</task>

<task type="auto">
  <name>Task 2: Create congressional intel cache builder and config</name>
  <files>scripts/build_congressional_intel.py, config/scanner_config.json</files>
  <action>
**A) Create scripts/build_congressional_intel.py:**

Script that:
1. Loads scanner_config.json and program_inventory.json
2. Instantiates CongressGovScraper with config
3. Runs paginated bill search (using the paginated methods from Plan 02)
4. For each unique bill, calls _fetch_bill_detail() to get full detail
5. Scores bill-to-program relevance using:
   - Subject overlap: bill's legislativeSubjects vs program keywords (from config search_queries + tribal_keywords)
   - CFDA/ALN reference: bill text/title mentions program's CFDA number
   - Committee match: bill referred to committees relevant to program (SLIA, HSII, SSAP, etc.)
   - Keyword density: Tribal-relevant keyword matches in bill title
   - Combined score: weighted average with threshold 0.30
6. Validates each bill against BillIntelligence Pydantic model (from Plan 01)
7. Writes validated bills to data/congressional_intel.json with metadata
8. Skips bill detail fetch for bills below relevance threshold (fetch detail only for top 50 by initial relevance)

File structure of congressional_intel.json:
```json
{
  "metadata": {
    "generated_at": "2026-02-12T...",
    "congress": 119,
    "total_bills_scanned": 150,
    "bills_with_detail": 50,
    "bills_above_threshold": 25,
    "relevance_threshold": 0.30
  },
  "bills": [
    {
      "bill_id": "119-HR-1234",
      "congress": 119,
      "bill_type": "HR",
      "bill_number": 1234,
      "title": "...",
      "sponsor": {...},
      "cosponsors": [...],
      "cosponsor_count": 5,
      "actions": [...],
      "latest_action": {...},
      "committees": [...],
      "subjects": [...],
      "policy_area": "...",
      "text_url": "...",
      "congress_url": "...",
      "relevance_score": 0.72,
      "matched_programs": ["tribal_climate_resilience", "bia_housing"],
      "update_date": "...",
      "introduced_date": "..."
    }
  ]
}
```

Key constraints:
- Use encoding="utf-8" for all file operations
- Import FISCAL_YEAR from src.config (don't hardcode)
- Use logging.getLogger(__name__)
- Atomic write pattern: write to tmp file, then os.replace()
- Import and validate with BillIntelligence from src.schemas.models

**B) Update config/scanner_config.json:**

Add a `congressional_intel` section to the config:
```json
"congressional_intel": {
  "data_path": "data/congressional_intel.json",
  "relevance_threshold": 0.30,
  "max_bills_detail": 50,
  "congress": 119,
  "detail_delay_seconds": 0.3,
  "bill_types": ["hr", "s", "hjres", "sjres"]
}
```

**C) INTEL-04 delegation enhancement:**
The existing congressional_cache.json already contains committee assignments per member. The delegation is already "enhanced" with committee data. For voting records, add a comment in the script noting that House roll call votes are available (Congress.gov API v3 beta, 118th+ Congress) but Senate votes are NOT yet available in the API. Log this as an INFO message:
```python
logger.info("Delegation enhancement: committee data from cache; voting records pending Senate API availability")
```
  </action>
  <verify>
1. scripts/build_congressional_intel.py exists and is syntactically valid: `python -c "import ast; ast.parse(open('scripts/build_congressional_intel.py', encoding='utf-8').read())"`
2. Config has congressional_intel section: `python -c "import json; c = json.load(open('config/scanner_config.json', encoding='utf-8')); print(c['congressional_intel']['relevance_threshold'])"`
3. Existing tests pass: `python -m pytest tests/ -x -q`
  </verify>
  <done>Congressional intel cache builder script creates data/congressional_intel.json with validated BillIntelligence records; config updated with congressional_intel section; delegation enhancement noted with committee data present and voting records deferred.</done>
</task>

</tasks>

<verification>
1. CongressGovScraper._fetch_bill_detail() exists with 4 sub-endpoint fetches
2. scripts/build_congressional_intel.py is syntactically valid Python
3. data/congressional_intel.json structure matches BillIntelligence schema
4. config/scanner_config.json has congressional_intel section
5. No API keys in URL query params (X-Api-Key header only)
6. No hardcoded fiscal years (imports from src.config)
7. encoding="utf-8" on all file operations
8. Existing tests pass: `python -m pytest tests/ -x -q`
</verification>

<success_criteria>
- INTEL-01: Bill detail fetcher returns complete records with sponsors, committees, actions, subjects, text URLs
- INTEL-03: Bill-to-program mapping with relevance scores and matched_programs populated
- INTEL-04: Delegation data enhanced (committee assignments present in cache; voting records documented as pending)
- Bills validated against BillIntelligence Pydantic model from Plan 01
</success_criteria>

<output>
After completion, create `.planning/phases/15-congressional-intelligence/15-04-SUMMARY.md`
</output>
