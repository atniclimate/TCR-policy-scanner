---
phase: 15-congressional-intelligence
plan: 07
type: execute
wave: 4
depends_on: [15-01, 15-02, 15-04, 15-05]
files_modified:
  - tests/test_e2e_congressional.py
  - .github/workflows/daily-scan.yml
  - .github/workflows/generate-packets.yml
  - scripts/verify_air_gap.py
  - tests/test_xcut_compliance.py
autonomous: true

must_haves:
  truths:
    - "End-to-end test traces congressional data from congressional_intel.json through TribePacketContext through DOCX rendering through structural validation for all 4 doc types"
    - "CI pipeline daily-scan.yml includes congressional intelligence scan step"
    - "CI pipeline generate-packets.yml includes congressional intel loading and DOCX validation"
    - "Air gap compliance script returns zero hits for ATNI, NCAI, or tool name references across all source and output files"
    - "v1.2 Four Fixes verified clean: logger naming, FY hardcoding, format_dollars, graph paths"
    - "Zero third-party tracking, zero analytics, zero cookies verified"
  artifacts:
    - path: "tests/test_e2e_congressional.py"
      provides: "End-to-end congressional pipeline test"
      contains: "test_e2e_congressional"
    - path: ".github/workflows/daily-scan.yml"
      provides: "Updated CI with congressional scan"
      contains: "congressional"
    - path: ".github/workflows/generate-packets.yml"
      provides: "Updated CI with congressional intel loading"
      contains: "congressional_intel"
    - path: "tests/test_xcut_compliance.py"
      provides: "Cross-cutting compliance tests"
      contains: "test_air_gap"
  key_links:
    - from: "tests/test_e2e_congressional.py"
      to: "data/congressional_intel.json"
      via: "Loads test fixture data matching production format"
    - from: "tests/test_e2e_congressional.py"
      to: "src/packets/docx_engine.py"
      via: "Generates actual DOCX documents and validates structure"
    - from: "tests/test_xcut_compliance.py"
      to: "src/"
      via: "Scans all source files for air gap violations"
---

<objective>
Create end-to-end pipeline test for congressional intelligence, extend CI workflows, and verify all cross-cutting requirements (air gap, data sovereignty, v1.2 fixes).

Purpose: INTEL-10 (E2E test), INTEL-11 (CI pipeline), XCUT-01 (air gap), XCUT-02 (data sovereignty), XCUT-03 (v1.2 fixes) complete the Phase 15 verification layer.

Output: E2E test file, updated CI workflows, air gap verification script, and cross-cutting compliance test file.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/15-congressional-intelligence/15-RESEARCH.md
@.planning/phases/15-congressional-intelligence/15-01-SUMMARY.md
@.planning/phases/15-congressional-intelligence/15-05-SUMMARY.md
@.github/workflows/daily-scan.yml
@.github/workflows/generate-packets.yml
@tests/test_e2e_phase8.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create E2E congressional pipeline test</name>
  <files>tests/test_e2e_congressional.py</files>
  <action>
Create an end-to-end test that traces congressional data through the full pipeline:

1. **Test fixture**: Create a sample congressional_intel.json-format dict with:
   - 3 bills with varying relevance scores (0.8, 0.5, 0.2)
   - Each bill has sponsor, cosponsors, actions, subjects, committees
   - Metadata with generated_at timestamp

2. **Context building test** (~5 tests):
   - Load fixture into TribePacketContext.congressional_intel
   - Verify bills filtered correctly for a sample Tribe (by state, programs)
   - Verify confidence scoring produces valid HIGH/MEDIUM/LOW levels
   - Verify delegation_activity cross-references bills with delegation

3. **DOCX rendering test** (~8 tests):
   - Generate Doc A with congressional intel -> verify bill section exists in document
   - Generate Doc B with congressional intel -> verify facts only, no strategy words
   - Generate Doc C with regional aggregation -> verify shared bills counted
   - Generate Doc D with regional aggregation -> verify facts only
   - Verify section ordering: bill intelligence appears before delegation
   - Verify confidence badge appears in section heading
   - Verify zero numeric scores in any paragraph text
   - Open generated DOCX with python-docx and scan all paragraphs

4. **Structural validation test** (~3 tests):
   - Generated DOCX opens without corruption
   - Page count within expected range (existing patterns)
   - No placeholder text ("TBD", "TODO") in output

Use tmpdir fixtures for DOCX output. Create minimal but realistic test data.
Import DOC_A, DOC_B, DOC_C, DOC_D from src.packets.doc_types.

Pattern: Follow test_e2e_phase8.py structure for fixtures and assertions.
  </action>
  <verify>
Run: `python -m pytest tests/test_e2e_congressional.py -v --tb=short`
All tests must pass. Count must be 15+.
  </verify>
  <done>E2E test traces congressional data from JSON fixture through context building through all 4 DOCX doc types with structural validation.</done>
</task>

<task type="auto">
  <name>Task 2: CI pipeline extension + cross-cutting compliance tests</name>
  <files>.github/workflows/daily-scan.yml, .github/workflows/generate-packets.yml, tests/test_xcut_compliance.py</files>
  <action>
**A) Update daily-scan.yml:**

Add a step after the main scan step:
```yaml
    - name: Congressional intelligence scan
      run: |
        python scripts/build_congressional_intel.py --verbose || echo "Congressional intel scan completed with warnings"
      env:
        CONGRESS_API_KEY: ${{ secrets.CONGRESS_API_KEY }}
```

This runs the congressional intel builder after the daily scan. The `|| echo` ensures a non-zero exit from the script (e.g., API unavailable) doesn't fail the entire workflow.

**B) Update generate-packets.yml:**

Add a step before packet generation:
```yaml
    - name: Load congressional intelligence
      run: |
        if [ -f data/congressional_intel.json ]; then
          echo "Congressional intel data found ($(wc -c < data/congressional_intel.json) bytes)"
        else
          echo "WARNING: No congressional intel data found, packets will have empty congressional sections"
        fi
```

Add congressional model validation to existing test step (if there is one), or add:
```yaml
    - name: Validate congressional data
      run: |
        python -c "
        import json
        from pathlib import Path
        p = Path('data/congressional_intel.json')
        if p.exists():
            data = json.loads(p.read_text(encoding='utf-8'))
            print(f'Congressional intel: {len(data.get(\"bills\", []))} bills')
        else:
            print('No congressional intel file (expected for first run)')
        "
```

**C) Create tests/test_xcut_compliance.py (20+ tests):**

Cross-cutting compliance tests:

1. **XCUT-01 Air gap tests** (~8 tests):
   - Scan all .py files in src/ for "ATNI" (case-insensitive) -> zero hits
   - Scan all .py files in src/ for "NCAI" (case-insensitive) -> zero hits
   - Scan all .py files in src/ for "TCR Policy Scanner" (case-insensitive) -> zero hits
   - Scan all .py files in src/ for "ATNI Climate Resilience" -> zero hits
   - Scan all .py files in src/ for "NCAI Climate Action" -> zero hits
   - Scan docs/web/ HTML/JS files for same patterns -> zero hits
   - Scan templates/ for same patterns -> zero hits
   - Scan generated DOCX test output for same patterns (if test fixtures generate docs)

2. **XCUT-02 Data sovereignty tests** (~6 tests):
   - Scan all HTML/JS files for "google-analytics" or "ga(" -> zero hits
   - Scan for "googletagmanager" -> zero hits
   - Scan for Google Fonts CDN URLs -> zero hits
   - Scan for cookie-setting patterns ("document.cookie", "Set-Cookie") -> zero hits
   - Scan for tracking pixels or beacon patterns -> zero hits
   - Verify no PII fields in data models (no email, phone, address fields)

3. **XCUT-03 v1.2 fix verification tests** (~8 tests):
   - Logger naming: grep all .py files for `getLogger("` (with a string literal, not __name__) -> zero hits (excluding test files that legitimately test logger names)
   - FY hardcoding: grep for `"FY26"` or `"FY2026"` as string literals in src/ (excluding comments, test fixtures) -> zero hits
   - format_dollars: grep for `def.*format_dollars` or `def.*_format_dollars` -> exactly 1 hit (in src/utils.py)
   - Graph paths: grep for hardcoded graph_schema.json paths (absolute or relative string paths, not pathlib) -> zero hits

Use pathlib and the Glob pattern to find files. Do NOT use subprocess/shell commands in tests.
  </action>
  <verify>
1. `.github/workflows/daily-scan.yml` has congressional intelligence scan step
2. `.github/workflows/generate-packets.yml` has congressional intel validation step
3. `python -m pytest tests/test_xcut_compliance.py -v --tb=short` -- all pass
4. Full suite: `python -m pytest tests/ -q --tb=short` -- total > 900, zero failures
  </verify>
  <done>CI pipelines extended with congressional intel steps; XCUT-01 (air gap), XCUT-02 (data sovereignty), and XCUT-03 (v1.2 fixes) all verified programmatically.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_e2e_congressional.py -v` -- 15+ tests pass
2. `python -m pytest tests/test_xcut_compliance.py -v` -- 20+ tests pass
3. `.github/workflows/daily-scan.yml` includes congressional scan step
4. `.github/workflows/generate-packets.yml` includes congressional intel validation
5. Full suite passes: `python -m pytest tests/ -q` -- total > 900
6. Air gap: zero ATNI/NCAI/tool name hits in source
7. Data sovereignty: zero tracking/analytics/cookies
8. v1.2 fixes: logger naming, FY hardcoding, format_dollars, graph paths all clean
</verification>

<success_criteria>
- INTEL-10: E2E test traces congressional_intel.json through context through DOCX for all 4 doc types
- INTEL-11: CI pipeline extended with congressional scan and DOCX validation
- XCUT-01: Air gap compliance verified (zero hits)
- XCUT-02: Indigenous data sovereignty verified (zero tracking)
- XCUT-03: v1.2 fixes verified clean
- Total test count exceeds 900
</success_criteria>

<output>
After completion, create `.planning/phases/15-congressional-intelligence/15-07-SUMMARY.md`
</output>
