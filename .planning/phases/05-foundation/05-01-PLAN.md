---
phase: 05-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/packets/__init__.py
  - src/packets/ecoregion.py
  - src/packets/context.py
  - src/graph/schema.py
  - data/ecoregion_config.json
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "src/packets/ package exists and is importable"
    - "rapidfuzz, pyyaml, python-docx are in requirements.txt and installable"
    - "All 50 states + DC map to one of 7 ecoregions"
    - "Ecoregion-to-program priority mapping returns ranked program lists per ecoregion"
    - "TribePacketContext holds identity, congressional, award, and hazard fields"
    - "TribeNode and CongressionalDistrictNode exist in graph schema alongside existing nodes"
  artifacts:
    - path: "src/packets/__init__.py"
      provides: "Package init"
    - path: "src/packets/ecoregion.py"
      provides: "EcoregionMapper with state-to-ecoregion lookup and program priority mapping"
      exports: ["EcoregionMapper"]
    - path: "src/packets/context.py"
      provides: "TribePacketContext dataclass with all fields for downstream DOCX rendering"
      exports: ["TribePacketContext"]
    - path: "src/graph/schema.py"
      provides: "TribeNode, CongressionalDistrictNode dataclass additions"
      contains: "class TribeNode"
    - path: "data/ecoregion_config.json"
      provides: "7 ecoregion definitions with program priority rankings"
    - path: "requirements.txt"
      provides: "Updated dependencies including rapidfuzz, pyyaml, python-docx"
  key_links:
    - from: "src/packets/ecoregion.py"
      to: "data/ecoregion_config.json"
      via: "Loads program priority data from JSON at runtime"
      pattern: "ecoregion_config\\.json"
    - from: "src/packets/context.py"
      to: "src/graph/schema.py"
      via: "TribePacketContext fields align with TribeNode and CongressionalDistrictNode"
---

<objective>
Create the `src/packets/` module package with dependency installation, the ecoregion classification system (REG-02), the TribePacketContext dataclass (REG-03), and graph schema additions (TribeNode, CongressionalDistrictNode). This establishes the foundational types and data structures that all other Phase 5 plans depend on.

Purpose: Every downstream module (registry, congress, orchestrator) imports from this package and uses these data types. Getting the type contracts right first prevents rework.
Output: Importable `src/packets/` package with ecoregion module, context dataclass, updated graph schema, and updated requirements.txt.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-foundation/05-RESEARCH.md
@.planning/phases/05-foundation/05-CONTEXT.md
@src/graph/schema.py
@requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create src/packets/ package, install dependencies, update requirements.txt</name>
  <files>
    src/packets/__init__.py
    requirements.txt
  </files>
  <action>
1. Create `src/packets/__init__.py` as an empty file (just a docstring: "Tribe-specific advocacy packet generation modules.").

2. Update `requirements.txt` to add three new dependencies after the existing entries:
```
rapidfuzz>=3.14.0
pyyaml>=6.0.0
python-docx>=1.1.0
```

3. Run `pip install -r requirements.txt` to install the new dependencies.

Do NOT add geopandas, shapely, fiona, GDAL, rich, or Pydantic. The existing dependencies (aiohttp, python-dateutil, jinja2) must remain unchanged.
  </action>
  <verify>
    - `python -c "from src.packets import __doc__; print('OK')"` succeeds
    - `python -c "import rapidfuzz; print(rapidfuzz.__version__)"` prints version >= 3.14.0
    - `python -c "import yaml; print(yaml.__version__)"` prints version >= 6.0
    - `python -c "import docx; print('OK')"` succeeds
    - `requirements.txt` contains all 6 entries (3 existing + 3 new)
  </verify>
  <done>src/packets/ is an importable Python package; rapidfuzz, pyyaml, python-docx are installed and importable; requirements.txt is updated.</done>
</task>

<task type="auto">
  <name>Task 2: Create ecoregion module, context dataclass, and graph schema additions</name>
  <files>
    src/packets/ecoregion.py
    src/packets/context.py
    src/graph/schema.py
    data/ecoregion_config.json
  </files>
  <action>
**A. Create `data/ecoregion_config.json`** — Static data file with 7 ecoregion definitions and per-ecoregion program priority rankings:

```json
{
  "ecoregions": {
    "alaska": {
      "name": "Alaska",
      "states": ["AK"],
      "description": "Arctic and subarctic climate impacts",
      "priority_programs": ["bia_tcr", "epa_gap", "denali_commission", "noaa_habitat_restoration"]
    },
    "pacific_northwest": {
      "name": "Pacific Northwest",
      "states": ["WA", "OR"],
      "description": "Marine, forest, and salmon habitat impacts",
      "priority_programs": ["bia_tcr", "fema_bric", "usfs_tribal_forest", "noaa_habitat_restoration"]
    },
    "southwest": {
      "name": "Southwest",
      "states": ["AZ", "NM", "NV", "UT", "CA"],
      "description": "Drought, wildfire, and water scarcity",
      "priority_programs": ["bia_tcr", "fema_bric", "usfs_tribal_forest", "epa_gap"]
    },
    "mountain_west": {
      "name": "Mountain West",
      "states": ["CO", "MT", "WY", "ID", "ND", "SD", "NE"],
      "description": "Wildfire, drought, and extreme temperature",
      "priority_programs": ["bia_tcr", "fema_bric", "usfs_tribal_forest", "ihs_sanitation"]
    },
    "great_plains_south": {
      "name": "Great Plains & South",
      "states": ["OK", "TX", "KS", "AR", "LA", "IA"],
      "description": "Tornado, flood, and extreme heat",
      "priority_programs": ["bia_tcr", "fema_bric", "fema_hmgp", "hud_icdbg"]
    },
    "southeast": {
      "name": "Southeast",
      "states": ["FL", "NC", "SC", "VA", "GA", "AL", "MS", "TN", "KY", "WV"],
      "description": "Hurricane, sea level rise, and flood",
      "priority_programs": ["bia_tcr", "fema_bric", "fema_hmgp", "hud_icdbg"]
    },
    "northeast_midwest": {
      "name": "Northeast & Midwest",
      "states": ["CT", "ME", "MA", "NY", "MN", "WI", "MI", "NH", "NJ", "PA", "RI", "VT", "DE", "MD", "IL", "IN", "OH", "MO", "HI"],
      "description": "Extreme precipitation, flooding, and coastal erosion",
      "priority_programs": ["bia_tcr", "fema_bric", "epa_gap", "noaa_habitat_restoration"]
    }
  },
  "metadata": {
    "scheme": "NCA5-derived 7-region advocacy classification",
    "version": "1.0",
    "note": "Hawaii mapped to northeast_midwest for simplicity; no federally recognized Tribes in HI use TCR programs"
  }
}
```

Note: Include Hawaii in northeast_midwest (closest climate analog for precipitation patterns; effectively a no-op since no HI Tribes in TCR scope). The `priority_programs` list uses program IDs from `data/program_inventory.json`. Include the top 4 most relevant programs per ecoregion based on climate hazard alignment. Claude should verify exact program IDs exist in program_inventory.json and adjust if needed.

**B. Create `src/packets/ecoregion.py`** — EcoregionMapper class:

```python
"""Ecoregion classification for Tribes based on state location.

Maps each Tribe to one or more of 7 NCA5-derived advocacy ecoregions
using state-to-ecoregion lookup. No geospatial dependencies.
"""
```

Class `EcoregionMapper`:
- `__init__(self, config: dict)` — reads `data_path` from `config.get("packets", {}).get("ecoregion", {}).get("data_path", "data/ecoregion_config.json")`. Lazy loads the JSON.
- Private `STATE_TO_ECOREGION` dict built from the JSON data (invert the states arrays to create state -> ecoregion mapping).
- `classify(self, states: list[str]) -> list[str]` — returns sorted, deduplicated ecoregion IDs for the given state list. Multi-state Tribes return multiple ecoregions (per CONTEXT.md: "multi-ecoregion Tribes listed under ALL applicable ecoregions").
- `get_priority_programs(self, ecoregion: str) -> list[str]` — returns the `priority_programs` list for a given ecoregion ID.
- `get_all_ecoregions(self) -> dict` — returns the full ecoregion config dict.

Use `encoding="utf-8"` on all file opens. Use `logging.getLogger("tcr_scanner.packets.ecoregion")`.

**C. Create `src/packets/context.py`** — TribePacketContext dataclass:

```python
"""Per-Tribe packet context aggregating all data layers.

The TribePacketContext is the single data object passed to the DOCX
generation engine in Phase 7. It is assembled by PacketOrchestrator
from the registry, congressional cache, and (in later phases) award
data and hazard profiles.
"""
```

Dataclass `TribePacketContext`:
- Identity (REG-01, REG-03): `tribe_id: str`, `tribe_name: str`, `states: list[str]`, `ecoregions: list[str]`, `bia_code: str = ""`, `epa_id: str = ""`
- Congressional (CONG-01, CONG-02): `districts: list[dict]`, `senators: list[dict]`, `representatives: list[dict]`
- Phase 6 stubs: `awards: list[dict]`, `hazard_profile: dict`
- Phase 7 stubs: `economic_impact: dict`
- Metadata: `generated_at: str = ""`, `congress_session: str = "119"`
- Method `to_dict(self) -> dict` that returns a serializable dict of all fields (using `dataclasses.asdict`).

All list/dict fields use `field(default_factory=list)` or `field(default_factory=dict)`.

**D. Add TribeNode and CongressionalDistrictNode to `src/graph/schema.py`**:

Add AFTER the existing `ObligationNode` class and BEFORE the `# -- Edge Types --` section:

```python
@dataclass
class TribeNode:
    """Federally recognized Tribal Nation."""
    id: str              # epa_{epaTribalInternalId}
    name: str            # Official BIA name
    state: str = ""      # Primary state (or comma-separated for multi-state)
    ecoregion: str = ""  # Primary ecoregion

@dataclass
class CongressionalDistrictNode:
    """U.S. Congressional District (119th Congress)."""
    id: str              # e.g., "AZ-01", "AK-AL"
    state: str = ""
    representative: str = ""
    party: str = ""
```

Also add two new edge types to the Edge docstring:
- `REPRESENTED_BY  (TribeNode -> CongressionalDistrictNode) -- many-to-many Tribe-to-district`
- `IN_ECOREGION    (TribeNode -> ecoregion_id) -- Tribe's climate advocacy region`

Do NOT modify any existing node or edge definitions.
  </action>
  <verify>
    - `python -c "from src.packets.ecoregion import EcoregionMapper; print('OK')"` succeeds
    - `python -c "from src.packets.context import TribePacketContext; ctx = TribePacketContext(tribe_id='test', tribe_name='Test Tribe'); print(ctx.to_dict())"` prints a dict with all expected fields
    - `python -c "from src.graph.schema import TribeNode, CongressionalDistrictNode; print('OK')"` succeeds
    - `python -c "from src.packets.ecoregion import EcoregionMapper; m = EcoregionMapper({}); print(m.classify(['AZ', 'NM', 'UT']))"` returns `['southwest']`
    - `python -c "from src.packets.ecoregion import EcoregionMapper; m = EcoregionMapper({}); print(m.classify(['AZ', 'WA']))"` returns `['pacific_northwest', 'southwest']` (multi-ecoregion)
    - `data/ecoregion_config.json` is valid JSON and loads without error
  </verify>
  <done>
    EcoregionMapper classifies any state list into 1-7 ecoregions and returns ranked program priorities per ecoregion. TribePacketContext holds all fields needed for DOCX rendering in Phase 7. TribeNode and CongressionalDistrictNode are defined in graph schema. All 50 states + DC + HI map to an ecoregion.
  </done>
</task>

</tasks>

<verification>
1. `python -c "import src.packets"` -- package exists
2. `python -c "from src.packets.ecoregion import EcoregionMapper; from src.packets.context import TribePacketContext; from src.graph.schema import TribeNode, CongressionalDistrictNode; print('All imports OK')"` -- all types importable
3. `pip freeze | grep -i "rapidfuzz\|pyyaml\|python-docx"` -- all three installed
4. Verify ecoregion coverage: every state in the FIPS_TO_STATE dict from research maps to an ecoregion
5. Verify TribePacketContext has stubs for awards, hazard_profile, economic_impact (Phase 6/7 compatibility)
</verification>

<success_criteria>
- src/packets/ is a valid Python package with ecoregion.py and context.py
- EcoregionMapper.classify() handles single-state, multi-state, and Alaska Tribes
- TribePacketContext dataclass has fields for all 5 requirements (REG-01 through CONG-02) plus Phase 6/7 stubs
- TribeNode and CongressionalDistrictNode exist in schema.py without breaking existing node types
- requirements.txt includes all 6 dependencies
- No geospatial libraries installed
</success_criteria>

<output>
After completion, create `.planning/phases/05-foundation/05-01-SUMMARY.md`
</output>
