---
phase: 19-schema-core-data
plan: 06
type: execute
wave: 3
depends_on: ["19-01", "19-02", "19-03", "19-04", "19-05"]
files_modified:
  - tests/test_phase19_integration.py
  - tests/test_xcut04_encoding.py
autonomous: true

must_haves:
  truths:
    - "All vulnerability schemas import cleanly from src.schemas.vulnerability"
    - "Vocabulary constants are self-consistent (no forbidden terms in headings, all gaps have sovereignty framing)"
    - "NRI expanded builder and SVI builder both produce output matching their Pydantic schemas"
    - "All file operations across Plan 01-05 artifacts use encoding='utf-8'"
    - "All cache writes across Plan 01-05 artifacts use atomic write pattern (tempfile + os.replace)"
    - "No FY26 hardcodes remain in functional packet code"
    - "All 964+ existing tests still pass"
  artifacts:
    - path: "tests/test_phase19_integration.py"
      provides: "Cross-plan integration tests for Phase 19"
      contains: "test_schema_to_builder_contract"
    - path: "tests/test_xcut04_encoding.py"
      provides: "XCUT-04 compliance tests for encoding and atomic writes"
      contains: "test_all_open_calls_have_encoding"
  key_links:
    - from: "tests/test_phase19_integration.py"
      to: "src/schemas/vulnerability.py"
      via: "Schema import verification"
      pattern: "from src.schemas.vulnerability import"
    - from: "tests/test_xcut04_encoding.py"
      to: "src/packets/*.py"
      via: "AST scanning for open() calls"
      pattern: "encoding"
---

<objective>
Write cross-cutting integration tests and XCUT-04 compliance tests that verify all Phase 19 artifacts work together correctly: schemas validate builder output, vocabulary constants are internally consistent, encoding and atomic write patterns are used everywhere.

Purpose: XCUT-04 (encoding + atomic writes) and overall Phase 19 success criteria verification. These tests catch integration bugs that individual plan tests miss -- e.g., schema field name mismatches between builder and model, or a file operation missing the encoding parameter.

Output: Two test files covering cross-plan integration and XCUT-04 compliance.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/19-schema-core-data/19-01-SUMMARY.md -- Tech debt fixes + paths + context field
@.planning/phases/19-schema-core-data/19-02-SUMMARY.md -- Vulnerability Pydantic schemas
@.planning/phases/19-schema-core-data/19-03-SUMMARY.md -- Vocabulary constants
@.planning/phases/19-schema-core-data/19-04-SUMMARY.md -- NRI expanded builder
@.planning/phases/19-schema-core-data/19-05-SUMMARY.md -- SVI builder
@src/schemas/vulnerability.py -- All vulnerability models
@src/packets/vocabulary.py -- All framing constants
@src/packets/nri_expanded.py -- NRI expanded builder
@src/packets/svi_builder.py -- SVI builder
@tests/test_xcut_compliance.py -- Existing XCUT compliance test patterns
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write Phase 19 integration tests</name>
  <files>tests/test_phase19_integration.py</files>
  <action>
    Create `tests/test_phase19_integration.py` with cross-plan integration tests:

    **TestSchemaImports:**
    - test_all_vulnerability_models_importable: Import VulnerabilityProfile, NRIExpanded, SVIProfile, SVITheme, CompositeScore, CompositeComponent, InvestmentPriorityTier, DataGapType from src.schemas.vulnerability
    - test_models_re_exported_from_init: Same imports work via src.schemas
    - test_no_circular_imports: Importing schemas does not trigger circular import (import src.schemas, src.packets.vocabulary, src.packets.nri_expanded, src.packets.svi_builder in sequence)

    **TestSchemaToBuilderContract:**
    - test_nri_builder_output_matches_schema: Create a sample NRI builder output dict (matching the structure _aggregate_tribe_nri returns), validate it against NRIExpanded model. This catches field name mismatches between builder and schema.
    - test_svi_builder_output_matches_schema: Create a sample SVI builder output dict, validate against SVIProfile model.
    - test_composite_score_from_components: Given sample NRI and SVI profiles, compute composite per the formula (0.40 hazard + 0.35 social + 0.25 adaptive), validate against CompositeScore model.
    - test_vulnerability_profile_assembles_all: Create a VulnerabilityProfile with NRI, SVI, and Composite sub-profiles, verify it validates and serializes to JSON.

    **TestTierMapping:**
    - test_all_boundary_scores: Test score->tier mapping at each boundary:
      - 0.00 -> LOW
      - 0.19 -> LOW
      - 0.20 -> MODERATE
      - 0.39 -> MODERATE
      - 0.40 -> ELEVATED
      - 0.59 -> ELEVATED
      - 0.60 -> HIGH
      - 0.79 -> HIGH
      - 0.80 -> CRITICAL
      - 1.00 -> CRITICAL
    - test_boundary_rule_favors_tribe: 0.80 maps to CRITICAL (>=), not HIGH

    **TestVocabularyIntegrity:**
    - test_gap_messages_match_schema_enum: Every key in GAP_MESSAGES matches a DataGapType enum value
    - test_tier_displays_match_schema_enum: Every key in TIER_DISPLAYS matches an InvestmentPriorityTier value
    - test_section_headings_no_raw_vulnerability: "vulnerability" not in any heading (case-insensitive)
    - test_forbidden_terms_not_in_constants: No FORBIDDEN_DOC_B_TERMS word appears in SECTION_HEADINGS, RATING_LABEL, or EXPOSURE_CONTEXT

    **TestDynamicFiscalYear:**
    - test_doc_types_use_dynamic_fy: Import DOC_A, DOC_B, DOC_C, DOC_D and verify title_template contains FISCAL_YEAR_SHORT value (not literal "FY26")
    - test_format_filename_uses_dynamic_fy: DOC_A.format_filename("test") contains FISCAL_YEAR_SHORT.lower()
    - test_no_fy26_in_packet_code: Scan src/packets/ Python files (excluding iija_sunset.py) for "FY26" in non-comment lines. This is a regression guard.

    **TestPathConstants:**
    - test_new_path_constants_under_data_dir: All 6 new paths are under DATA_DIR
    - test_vulnerability_profile_path_helper: vulnerability_profile_path("epa_100000001") returns expected path under VULNERABILITY_PROFILES_DIR
    - test_context_has_vulnerability_field: TribePacketContext(tribe_id="x", tribe_name="X").vulnerability_profile == {}
  </action>
  <verify>
    Run: `python -m pytest tests/test_phase19_integration.py -v` -- all tests pass.
  </verify>
  <done>
    Integration tests verify: schema imports, builder-to-schema contract, tier mapping boundaries, vocabulary-to-schema alignment, dynamic FY regression guard, path constants. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write XCUT-04 encoding and atomic write compliance tests</name>
  <files>tests/test_xcut04_encoding.py</files>
  <action>
    Create `tests/test_xcut04_encoding.py` with compliance scanning tests:

    **TestEncodingCompliance:**
    - test_all_open_calls_have_encoding: Use Python's `ast` module to scan all Phase 19 source files (nri_expanded.py, svi_builder.py, vocabulary.py) for `open()` calls. Every `open()` call that is NOT in binary mode (`"rb"`, `"wb"`) MUST have an `encoding` keyword argument. Fail if any text-mode `open()` lacks encoding.
    - test_all_path_write_text_have_encoding: Scan for `.write_text()` calls in Phase 19 files. All must have `encoding="utf-8"`.
    - test_no_bare_open_in_new_files: List all files created in Phase 19, parse AST, check open() compliance.

    Implementation approach for AST scanning:
    ```python
    import ast
    from pathlib import Path

    def find_open_calls_without_encoding(filepath: Path) -> list[int]:
        """Return line numbers of open() calls missing encoding parameter."""
        source = filepath.read_text(encoding="utf-8")
        tree = ast.parse(source)
        violations = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                func = node.func
                # Check for open() or builtins.open()
                if (isinstance(func, ast.Name) and func.id == "open") or \
                   (isinstance(func, ast.Attribute) and func.attr == "open"):
                    # Check if mode is binary
                    mode_is_binary = False
                    for kw in node.keywords:
                        if kw.arg == "mode" and isinstance(kw.value, ast.Constant):
                            if "b" in str(kw.value.value):
                                mode_is_binary = True
                    # Check positional mode arg (2nd positional)
                    if len(node.args) >= 2 and isinstance(node.args[1], ast.Constant):
                        if "b" in str(node.args[1].value):
                            mode_is_binary = True
                    if mode_is_binary:
                        continue
                    # Check for encoding keyword
                    has_encoding = any(kw.arg == "encoding" for kw in node.keywords)
                    if not has_encoding:
                        violations.append(node.lineno)
        return violations
    ```

    **TestAtomicWriteCompliance:**
    - test_nri_builder_uses_atomic_write: Scan nri_expanded.py for `os.replace()` pattern. Must be present.
    - test_svi_builder_uses_atomic_write: Scan svi_builder.py for `os.replace()` pattern. Must be present.
    - test_no_direct_json_dump_to_file: Scan Phase 19 builder files for `json.dump()` calls. Every json.dump must be preceded by tempfile.mkstemp pattern (within same function). This is a heuristic -- verify by checking that `tempfile` is imported.
    - test_temp_file_cleanup_pattern: Scan for `contextlib.suppress(OSError)` in both builder files -- confirms cleanup on exception.

    **TestExistingFileCompliance:**
    - test_doc_types_format_filename_no_fy26: Verify DOC_A.format_filename("test") does NOT contain literal "fy26" string
    - test_paths_module_no_runtime_checks: Verify src/paths.py does not call .exists() or .mkdir() at import time (it's a constants-only module)

    All compliance tests should clearly report the file and line number of any violation so the executor can fix immediately.
  </action>
  <verify>
    Run: `python -m pytest tests/test_xcut04_encoding.py -v` -- all tests pass.
    Run: `python -m pytest tests/ -x -q` -- all tests pass (no regressions).
  </verify>
  <done>
    XCUT-04 compliance tests verify: all text-mode open() calls have encoding parameter, all cache writes use atomic write pattern (tempfile + os.replace), temp file cleanup with contextlib.suppress. These tests serve as regression guards for future development.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_phase19_integration.py tests/test_xcut04_encoding.py -v` -- all tests pass
2. `python -m pytest tests/ -x -q` -- all tests pass (964+ baseline maintained)
3. All Phase 19 success criteria from ROADMAP.md verified by at least one test
</verification>

<success_criteria>
- Integration tests verify schema imports, builder-to-schema contracts, tier boundaries, vocabulary alignment
- XCUT-04 compliance tests verify encoding on all open() calls and atomic writes on all cache files
- FY26 regression guard test catches any future hardcoded fiscal year strings
- All Phase 19 success criteria from ROADMAP.md are covered by at least one test
- Total test count: 964 baseline + ~50-60 new Phase 19 tests
</success_criteria>

<output>
After completion, create `.planning/phases/19-schema-core-data/19-06-SUMMARY.md`
</output>
