---
phase: 19-schema-core-data
plan: 05
type: execute
wave: 2
depends_on: ["19-01", "19-02"]
files_modified:
  - src/packets/svi_builder.py
  - tests/test_svi_builder.py
autonomous: true

must_haves:
  truths:
    - "SVI 2022 county CSV parsed with -999 sentinel handling"
    - "Only Themes 1, 2, 4 extracted (Theme 3 intentionally excluded)"
    - "Custom Tribal SVI composite = average(RPL_THEME1, RPL_THEME2, RPL_THEME4)"
    - "Area-weighted crosswalk aggregation produces per-Tribe SVI profiles"
    - "Coverage reported as percentage of 592 Tribes with SVI data"
    - "SVIProfile Pydantic model validates all output profiles"
    - "Atomic writes with utf-8 encoding on all output files"
  artifacts:
    - path: "src/packets/svi_builder.py"
      provides: "SVIProfileBuilder following 9-step template"
      contains: "class SVIProfileBuilder"
    - path: "tests/test_svi_builder.py"
      provides: "Tests for SVI integration including sentinel handling, theme exclusion"
      contains: "test_sentinel_minus_999"
  key_links:
    - from: "src/packets/svi_builder.py"
      to: "src/paths.py"
      via: "import SVI_COUNTY_PATH, TRIBAL_COUNTY_WEIGHTS_PATH, AIANNH_CROSSWALK_PATH"
      pattern: "from src.paths import"
    - from: "src/packets/svi_builder.py"
      to: "src/schemas/vulnerability.py"
      via: "SVIProfile, SVITheme models for output validation"
      pattern: "from src.schemas.vulnerability import SVIProfile"
    - from: "src/packets/svi_builder.py"
      to: "src/packets/hazards.py"
      via: "_safe_float() pattern reuse, crosswalk loading"
      pattern: "_safe_float"
---

<objective>
Build the CDC/ATSDR SVI 2022 integration pipeline: parse county-level CSV, exclude Theme 3, compute custom 3-theme Tribal SVI composite, aggregate to Tribal areas via existing area-weighted crosswalk.

Purpose: VULN-02 (CDC/ATSDR SVI 2022 integration). This provides the social vulnerability component (0.35 weight) of the composite vulnerability score. Theme 3 is excluded per user decision with full sovereignty framing.

Output: `src/packets/svi_builder.py` with SVIProfileBuilder class that reads SVI 2022 county CSV and writes per-Tribe SVI profile JSON.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/packets/hazards.py -- 9-step builder template, _safe_float(), crosswalk loading, area-weighted aggregation (lines 570-644)
@src/paths.py -- SVI_COUNTY_PATH, TRIBAL_COUNTY_WEIGHTS_PATH, AIANNH_CROSSWALK_PATH (+ new constants from Plan 01)
@src/schemas/vulnerability.py -- SVIProfile, SVITheme models (from Plan 02)
@.planning/phases/19-schema-core-data/19-RESEARCH.md -- SVI CSV parsing code example, _safe_svi_float(), sentinel handling, pitfall 1/4
@.planning/phases/19-schema-core-data/19-CONTEXT.md -- SVI Theme 3 exclusion decision, data gap messages
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement SVIProfileBuilder with sentinel handling and 3-theme composite</name>
  <files>src/packets/svi_builder.py</files>
  <action>
    Create `src/packets/svi_builder.py` following the 9-step HazardProfileBuilder template. This is a SIMPLER builder than NRI expanded because SVI has fewer fields and a single CSV source.

    **Step 1: __init__(config: dict)**
    - Accept optional config dict with keys: `svi_csv_path`, `output_dir`
    - Default `svi_csv_path` to `SVI_COUNTY_PATH` from src.paths
    - Default `output_dir` to a subdirectory under vulnerability profiles
    - Load crosswalk and area weights

    **Steps 2-3: _load_crosswalk() and _load_area_weights()**
    - IDENTICAL to hazards.py pattern. Import from same paths.

    **_safe_svi_float() helper:**
    ```python
    def _safe_svi_float(value, default: float = 0.0) -> float:
        """Convert SVI CSV value to float, handling -999 sentinel.

        SVI uses -999 to represent null/no data. This extends the
        standard _safe_float() with sentinel detection.
        """
        result = _safe_float(value, default=default)
        if result == -999 or result == -999.0:
            return default
        return result
    ```
    Import `_safe_float` from `src.packets.hazards` if possible, otherwise duplicate with attribution comment.

    **Step 4: _load_svi_csv()**
    - Open with `encoding="utf-8-sig"` (handles BOM and no-BOM)
    - Use `csv.DictReader`
    - FIPS column: Try `row.get("STCNTY")` first, fall back to `row.get("FIPS")` (SVI uses different column names in different download variants)
    - Zero-pad FIPS to 5 digits: `fips.zfill(5)`
    - Extract per county:
      ```python
      {
          "rpl_theme1": _safe_svi_float(row.get("RPL_THEME1")),  # Socioeconomic Status
          "rpl_theme2": _safe_svi_float(row.get("RPL_THEME2")),  # Household Characteristics
          "rpl_theme4": _safe_svi_float(row.get("RPL_THEME4")),  # Housing Type & Transportation
          "rpl_themes": _safe_svi_float(row.get("RPL_THEMES")),  # Overall (stored for reference, includes Theme 3)
          "e_totpop": int(_safe_svi_float(row.get("E_TOTPOP"))),
          "f_theme1": int(_safe_svi_float(row.get("F_THEME1"))),
          "f_theme2": int(_safe_svi_float(row.get("F_THEME2"))),
          "f_theme4": int(_safe_svi_float(row.get("F_THEME4"))),
      }
      ```
    - NOTE: Do NOT extract RPL_THEME3 at all. Theme 3 is excluded per user decision.
    - Log: row count, unique FIPS count, any rows with missing FIPS

    **Step 5: _aggregate_tribe_svi(tribe_id, geoids)**
    - Collect county weights from crosswalk (sum when same county via multiple GEOIDs)
    - Match to loaded SVI county data
    - Normalize weights to MATCHED counties only
    - Compute area-weighted values for: rpl_theme1, rpl_theme2, rpl_theme4, flag counts
    - Compute custom 3-theme composite: `composite = mean(weighted_theme1, weighted_theme2, weighted_theme4)`
    - ANTI-PATTERN: Do NOT use RPL_THEMES (includes Theme 3). Always compute from 3 individual themes.
    - Compute coverage_pct = matched weight fraction
    - Determine data_gaps: if coverage_pct == 0 -> MISSING_SVI; if coverage_pct < 0.5 -> PARTIAL_NRI (reuse partial flag)
    - Build SVITheme objects for each theme
    - Return dict matching SVIProfile schema

    **Step 6: No overrides needed for SVI (skip)**

    **Step 7: build_all_profiles()**
    - Iterate all tribe_ids from crosswalk
    - Call _aggregate_tribe_svi for each
    - Validate against SVIProfile Pydantic model
    - Write per-Tribe JSON via atomic write
    - Track: total built, themes available, data gaps
    - Return count

    **Step 8: _atomic_write()**
    - Same pattern as hazards.py: mkstemp + fdopen + replace + suppress cleanup

    **Step 9: generate_coverage_report()**
    - Count Tribes with SVI data, coverage percentage
    - Per-state breakdown
    - Theme-level coverage (how many Tribes have each theme)
    - Output JSON + markdown summary

    **Module-level constants:**
    ```python
    SVI_INCLUDED_THEMES: frozenset[str] = frozenset({"theme1", "theme2", "theme4"})
    SVI_EXCLUDED_THEMES: frozenset[str] = frozenset({"theme3"})
    SVI_SOURCE_YEAR: int = 2022
    ```

    CRITICAL:
    - Use `logging.getLogger(__name__)` for all logging
    - All `open()` calls use `encoding="utf-8"` (or `"utf-8-sig"` for CSV)
    - All writes use atomic pattern
    - Path traversal guard on tribe_id
  </action>
  <verify>
    Run: `python -c "from src.packets.svi_builder import SVIProfileBuilder; print('Import OK')"` -- succeeds.
    Run: `python -c "from src.packets.svi_builder import SVI_INCLUDED_THEMES; assert 'theme3' not in SVI_INCLUDED_THEMES; print('Theme 3 excluded OK')"` -- succeeds.
  </verify>
  <done>
    SVIProfileBuilder implements all applicable builder steps: CSV parsing with -999 sentinel handling, Theme 3 exclusion, 3-theme composite computation, area-weighted crosswalk aggregation, atomic writes. All patterns follow hazards.py exactly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write SVI builder tests</name>
  <files>tests/test_svi_builder.py</files>
  <action>
    Create `tests/test_svi_builder.py` with comprehensive test coverage:

    **TestSafeSviFloat:**
    - test_sentinel_minus_999_returns_default: _safe_svi_float(-999) -> 0.0
    - test_sentinel_minus_999_float_returns_default: _safe_svi_float(-999.0) -> 0.0
    - test_sentinel_string_returns_default: _safe_svi_float("-999") -> 0.0
    - test_valid_percentile_passthrough: _safe_svi_float(0.75) -> 0.75
    - test_none_returns_default: _safe_svi_float(None) -> 0.0
    - test_empty_string_returns_default: _safe_svi_float("") -> 0.0
    - test_custom_default: _safe_svi_float(-999, default=-1.0) -> -1.0

    **TestThemeExclusion:**
    - test_included_themes_are_1_2_4: SVI_INCLUDED_THEMES == frozenset({"theme1", "theme2", "theme4"})
    - test_theme3_not_included: "theme3" not in SVI_INCLUDED_THEMES
    - test_excluded_themes_is_theme3: SVI_EXCLUDED_THEMES == frozenset({"theme3"})
    - test_csv_parsing_skips_theme3: Parse sample CSV row, verify no rpl_theme3 in output

    **TestSVICompositeComputation:**
    - test_three_theme_average: themes [0.8, 0.6, 0.4] -> composite 0.6
    - test_all_zeros: themes [0.0, 0.0, 0.0] -> composite 0.0
    - test_all_ones: themes [1.0, 1.0, 1.0] -> composite 1.0
    - test_unequal_themes: themes [0.9, 0.3, 0.6] -> composite 0.6
    - test_composite_not_rpl_themes: Composite != RPL_THEMES value (because RPL_THEMES includes Theme 3)

    **TestSVIAreaWeightedAggregation (mocked data):**
    - test_single_county_tribe: One county maps directly, weight = 1.0
    - test_two_county_weighted_average: Two counties with 0.6/0.4 weights
    - test_missing_county_in_data: Crosswalk references county not in SVI CSV -> excluded from aggregation
    - test_weight_normalization: Matched counties normalize to sum 1.0
    - test_zero_weight_fallback: Equal weight 1/N when total_w = 0
    - test_coverage_pct_partial: 1 of 2 counties matched -> coverage ~0.5

    **TestSVIProfileBuilder (unit tests):**
    - test_builder_init: Default paths resolve correctly
    - test_path_traversal_rejection: tribe_id with ".." raises error
    - test_atomic_write_creates_file: Write produces valid JSON
    - test_output_validates_against_schema: Output dict creates valid SVIProfile model

    **TestSVIDataGaps:**
    - test_zero_coverage_yields_missing_svi: No matched counties -> MISSING_SVI gap
    - test_partial_coverage_yields_partial: < 50% coverage -> appropriate gap flag
    - test_full_coverage_no_gaps: 100% coverage -> empty data_gaps list

    **TestSVIIntegration (conditional):**
    - `@pytest.mark.skipif(not SVI_COUNTY_PATH.exists(), reason="SVI CSV not available")`
    - test_real_csv_loads: If CSV exists, parsing succeeds
    - test_real_csv_has_theme_columns: RPL_THEME1, RPL_THEME2, RPL_THEME4 headers present
    - test_real_csv_no_theme3_in_output: Verify no rpl_theme3 in parsed data

    Use pytest fixtures and tmp_path for filesystem tests. All unit tests use synthetic data, NOT real CSV files.
  </action>
  <verify>
    Run: `python -m pytest tests/test_svi_builder.py -v` -- all tests pass.
    Run: `python -m pytest tests/ -x -q` -- all tests pass (no regressions).
  </verify>
  <done>
    Comprehensive test suite for SVI builder with 30+ tests covering sentinel handling, theme exclusion, composite computation, area-weighted aggregation, data gaps, atomic writes, and path traversal guards. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_svi_builder.py -v` -- all SVI tests pass
2. `python -m pytest tests/ -x -q` -- all 964+ tests pass
3. `python -c "from src.packets.svi_builder import SVIProfileBuilder, SVI_INCLUDED_THEMES; assert 'theme3' not in SVI_INCLUDED_THEMES"` -- Theme 3 excluded
4. `python -c "from src.packets.svi_builder import _safe_svi_float; assert _safe_svi_float(-999) == 0.0"` -- sentinel handling works
</verification>

<success_criteria>
- SVIProfileBuilder follows HazardProfileBuilder 9-step template
- SVI 2022 CSV parsed with -999 sentinel handling
- Theme 3 explicitly excluded from all extraction and computation
- Custom 3-theme composite = mean(theme1, theme2, theme4)
- Area-weighted crosswalk aggregation with normalized matched-only weights
- Coverage percentage and data gap detection per Tribe
- Atomic writes with utf-8 encoding
- 30+ tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/19-schema-core-data/19-05-SUMMARY.md`
</output>
