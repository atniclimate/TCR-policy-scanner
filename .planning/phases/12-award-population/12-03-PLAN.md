---
phase: 12-award-population
plan: 03
type: execute
wave: 2
depends_on: ["12-01", "12-02"]
files_modified:
  - scripts/populate_awards.py
  - tests/test_populate_awards.py
autonomous: true

must_haves:
  truths:
    - "Running scripts/populate_awards.py fetches real USASpending data, matches to Tribes, and writes 592 cache files"
    - "592 award cache JSON files contain real data (not placeholder structures)"
    - "450+ Tribes have at least one non-zero award record"
    - "A JSON report summarizes coverage, unmatched names, and consortium awards"
    - "The script supports --dry-run (fetch+match without writing) and --tribe (single Tribe debug)"
  artifacts:
    - path: "scripts/populate_awards.py"
      provides: "Standalone CLI script for award population"
      min_lines: 100
    - path: "tests/test_populate_awards.py"
      provides: "Tests for CLI script argument parsing and orchestration flow"
      min_lines: 40
  key_links:
    - from: "scripts/populate_awards.py"
      to: "src/scrapers/usaspending.py"
      via: "USASpendingScraper.fetch_all_tribal_awards_multi_year()"
      pattern: "fetch_all_tribal_awards_multi_year"
    - from: "scripts/populate_awards.py"
      to: "src/packets/awards.py"
      via: "TribalAwardMatcher.deduplicate_awards() + match_all_awards() + write_cache()"
      pattern: "deduplicate_awards.*match_all_awards.*write_cache"
    - from: "scripts/populate_awards.py"
      to: "data/award_cache/"
      via: "write_cache() writes 592 JSON files"
      pattern: "award_cache"
---

<objective>
Create the standalone CLI script that orchestrates the full award population pipeline: fetch from USASpending, deduplicate, match to Tribes, write enhanced cache files, and produce a coverage report. Then run it to populate real data.

Purpose: Plans 12-01 and 12-02 built the query engine and matching/caching engine. This plan wires them together in a standalone CLI script (following the `scripts/build_tribal_aliases.py` pattern), runs it against the live USASpending API to populate all 592 cache files, and validates coverage meets the 450+ target.

Output: `scripts/populate_awards.py` CLI script, integration test, populated `data/award_cache/` with real data, and `outputs/award_population_report.json` coverage report.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-award-population/12-RESEARCH.md
@.planning/phases/12-award-population/12-CONTEXT.md
@.planning/phases/12-award-population/12-01-SUMMARY.md
@.planning/phases/12-award-population/12-02-SUMMARY.md
@scripts/build_tribal_aliases.py
@src/scrapers/usaspending.py
@src/packets/awards.py
@src/config.py
@src/paths.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create populate_awards.py CLI script + tests</name>
  <files>scripts/populate_awards.py, tests/test_populate_awards.py</files>
  <action>
  **Create `scripts/populate_awards.py`** following the pattern from `scripts/build_tribal_aliases.py`:

  ```python
  #!/usr/bin/env python3
  """Populate award cache files from USASpending API.

  Fetches Tribal government awards for all tracked CFDA numbers across
  FY22-FY26, matches recipients to the 592-Tribe registry using
  two-tier name resolution, and writes per-Tribe JSON cache files.

  Usage:
      python scripts/populate_awards.py                    # All 592 Tribes
      python scripts/populate_awards.py --dry-run          # Fetch + match, no writes
      python scripts/populate_awards.py --tribe epa_100000001  # Single Tribe
      python scripts/populate_awards.py --report path.json  # Custom report path
  """
  ```

  Structure:
  1. **sys.path setup** (same pattern as build_tribal_aliases.py):
     ```python
     _SCRIPT_DIR = Path(__file__).resolve().parent
     _PROJECT_ROOT = _SCRIPT_DIR.parent
     if str(_PROJECT_ROOT) not in sys.path:
         sys.path.insert(0, str(_PROJECT_ROOT))
     ```

  2. **Imports** after sys.path:
     ```python
     from src.config import FISCAL_YEAR_INT
     from src.paths import SCANNER_CONFIG_PATH, OUTPUTS_DIR
     from src.scrapers.usaspending import USASpendingScraper
     from src.packets.awards import TribalAwardMatcher
     ```

  3. **`parse_args()` function** with argparse:
     - `--dry-run`: fetch and match but don't write cache files
     - `--tribe TRIBE_ID`: process only this Tribe (still fetches all data, but only writes one cache file)
     - `--report PATH`: path for JSON report (default: `outputs/award_population_report.json`)
     - `--fy-start INT`: first fiscal year (default: FISCAL_YEAR_INT - 4)
     - `--fy-end INT`: last fiscal year (default: FISCAL_YEAR_INT)

  4. **`async def run_pipeline(args)` function** -- the core orchestration:
     a. Load config from SCANNER_CONFIG_PATH
     b. Create USASpendingScraper and TribalAwardMatcher instances
     c. Call `scraper.fetch_all_tribal_awards_multi_year(fy_start, fy_end)` -- log progress
     d. Call `matcher.deduplicate_awards(awards_by_cfda)` -- log dedup stats
     e. Call `matcher.match_all_awards(deduped_awards)` -- log match stats
     f. If not `--dry-run`: call `matcher.write_cache(matched, fy_start, fy_end)` -- log write stats
     g. If `--tribe`: filter write_cache to only write that single Tribe's file
     h. Build report dict (see below)
     i. Write report JSON to `--report` path
     j. Print console summary

  5. **Report schema** (`outputs/award_population_report.json`):
     ```python
     report = {
         "timestamp": datetime.now(timezone.utc).isoformat(),
         "fiscal_year_range": {"start": fy_start, "end": fy_end},
         "queries": {
             "cfda_count": len(CFDA_TO_PROGRAM),
             "fy_count": fy_end - fy_start + 1,
             "total_queries": len(CFDA_TO_PROGRAM) * (fy_end - fy_start + 1),
         },
         "fetched": {
             "total_awards": total_raw,
             "after_dedup": total_deduped,
             "duplicates_removed": total_raw - total_deduped,
         },
         "matching": {
             "matched_awards": matched_count,
             "unmatched_awards": unmatched_count,
             "consortium_awards": len(consortium),
             "match_rate_pct": round(matched_count / max(total_deduped, 1) * 100, 1),
         },
         "coverage": {
             "total_tribes": 592,
             "tribes_with_awards": tribes_with_awards,
             "tribes_without_awards": 592 - tribes_with_awards,
             "coverage_pct": round(tribes_with_awards / 592 * 100, 1),
             "target_met": tribes_with_awards >= 450,
         },
         "top_unmatched": top_unmatched_names,  # list of top 20 unmatched recipient names by obligation
         "consortium_summary": consortium_summary,  # list of consortium names + total obligations
         "dry_run": args.dry_run,
     }
     ```

  6. **Console summary** (printed to stdout):
     ```
     === Award Population Report ===
     Fiscal years: FY22 - FY26
     Queries: 70 (14 CFDAs x 5 FYs)
     Awards fetched: {N} (after dedup: {M})
     Matched: {X} ({pct}%) | Unmatched: {Y} | Consortium: {Z}
     Coverage: {A}/592 Tribes ({B}%) -- target 450+: {PASS/FAIL}
     Report: outputs/award_population_report.json
     ```

  7. **`def main()` function:**
     ```python
     def main():
         args = parse_args()
         logging.basicConfig(level=logging.INFO, format="%(asctime)s %(name)s %(levelname)s %(message)s")
         asyncio.run(run_pipeline(args))
     ```

  8. **`if __name__ == "__main__": main()`**

  Important: Use `encoding="utf-8"` on all file opens. Use `OUTPUTS_DIR` from src.paths for report output. Create output directory if needed (`OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)`). Use `datetime.now(timezone.utc)` not `datetime.utcnow()`.

  **Create `tests/test_populate_awards.py`** with:

  1. **test_parse_args_defaults**: Assert default values for all args.
  2. **test_parse_args_dry_run**: Assert `--dry-run` sets `args.dry_run = True`.
  3. **test_parse_args_tribe**: Assert `--tribe epa_100000001` sets `args.tribe = "epa_100000001"`.
  4. **test_parse_args_fy_range**: Assert `--fy-start 2023 --fy-end 2025` sets correct values.

  Import `parse_args` from the script (after sys.path setup similar to the script itself).
  </action>
  <verify>
  - `python scripts/populate_awards.py --help` prints usage info without error
  - `python -m pytest tests/test_populate_awards.py -v` -- all tests pass
  - `ruff check scripts/populate_awards.py tests/test_populate_awards.py` passes clean
  </verify>
  <done>
  scripts/populate_awards.py CLI script is complete with --dry-run, --tribe, --report, --fy-start, --fy-end flags. Test file covers argument parsing. Script is ready to run against live API.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run award population and validate coverage</name>
  <files>data/award_cache/*.json, outputs/award_population_report.json</files>
  <action>
  Execute the award population script against the live USASpending API:

  1. **Run the population script:**
     ```bash
     python scripts/populate_awards.py
     ```
     This will make ~70 API calls (14 CFDAs x 5 fiscal years), match awards to Tribes, write 592 cache files, and produce a JSON report. Expected runtime: 2-5 minutes depending on API response times.

  2. **Verify the report:**
     - Read `outputs/award_population_report.json`
     - Check `coverage.tribes_with_awards >= 450`
     - Check `coverage.target_met == true`
     - Check `fetched.total_awards > 0`
     - Check `matching.match_rate_pct` (should be > 60%)

  3. **Verify cache files:**
     - Spot-check 3-5 cache files for Tribes known to receive federal awards:
       - `data/award_cache/epa_100000316.json` (Navajo Nation -- should have many awards)
       - `data/award_cache/epa_100000001.json` (Absentee-Shawnee -- likely has HUD IHBG)
       - `data/award_cache/epa_100000233.json` (Muckleshoot -- should have some awards)
     - Verify enhanced schema: `fiscal_year_range`, `yearly_obligations`, `trend` fields present
     - Verify awards have real data: `total_obligation > 0`, `award_count > 0`

  4. **If coverage < 450:**
     - Check `top_unmatched` in the report for patterns
     - If many unmatched names are slight variants of known Tribes, consider running `python scripts/build_tribal_aliases.py` to regenerate the alias table, then re-running the population
     - Log the gap in the summary but do not block -- the existing alias table with 3,751 entries should cover most cases

  5. **Validate no regressions:**
     ```bash
     python -m pytest tests/ -v
     ```
     Ensure all existing tests still pass (cache file changes should not affect tests that mock data).

  Important: If the USASpending API is unavailable (maintenance window, network issue), the script should complete with warnings and partial data. This is expected behavior -- log it in the summary and note the partial coverage.
  </action>
  <verify>
  - `outputs/award_population_report.json` exists and `coverage.target_met == true`
  - `python -c "import json,os; files=[f for f in os.listdir('data/award_cache') if f.endswith('.json')]; print(len(files))"` prints 592
  - Spot-check: Navajo Nation cache file has `award_count > 0` and `yearly_obligations` dict
  - `python -m pytest tests/ -v` -- all tests pass
  </verify>
  <done>
  592 award cache files populated with real USASpending data. 450+ Tribes have at least one non-zero award record. Coverage report at outputs/award_population_report.json confirms target met. Enhanced cache schema includes yearly_obligations and trend for every Tribe.
  </done>
</task>

</tasks>

<verification>
- `python scripts/populate_awards.py --help` shows usage
- `outputs/award_population_report.json` exists with `coverage.target_met == true`
- 592 cache files in `data/award_cache/` contain enhanced schema (fiscal_year_range, yearly_obligations, trend)
- 450+ Tribes have `award_count > 0`
- `python -m pytest tests/ -v` -- all tests pass
- `ruff check scripts/populate_awards.py` -- zero violations
</verification>

<success_criteria>
1. scripts/populate_awards.py runs end-to-end against live USASpending API
2. 592 award cache JSON files contain real data (not placeholder structures)
3. 450+ Tribes have at least one non-zero award record (verified in report)
4. JSON report includes coverage stats, unmatched names, consortium summary
5. Script supports --dry-run, --tribe, --report, --fy-start, --fy-end
6. All existing and new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-award-population/12-03-SUMMARY.md`
</output>
