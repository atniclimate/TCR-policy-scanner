---
phase: 18-production-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/web/css/style.css
  - docs/web/js/app.js
  - docs/web/index.html
  - outputs/bug_hunt/cyclops_findings.json
  - outputs/bug_hunt/cyclops_summary.md
  - outputs/bug_hunt/dale-gribble_findings.json
  - outputs/bug_hunt/dale-gribble_summary.md
  - outputs/bug_hunt/mr-magoo_findings.json
  - outputs/bug_hunt/mr-magoo_summary.md
  - outputs/bug_hunt/marie-kondo_findings.json
  - outputs/bug_hunt/marie-kondo_summary.md
autonomous: true

must_haves:
  truths:
    - "3 inherited P1 dark mode contrast issues from Phase 17 are fixed in CSS with WCAG AA 4.5:1+ ratios verified"
    - "P2 issues from Phase 17 (muted text, option-alias, scrollIntoView, selected option, noscript, rel=noopener) are fixed as pre-flight cleanup"
    - "Cyclops produces findings JSON covering all 15 checklist items with file+line references for every finding"
    - "Dale Gribble produces findings JSON covering all 18 checklist items including UNDRIP/OCAP/CARE sovereignty assessment"
    - "Mr. Magoo produces findings JSON covering all 12 checklist items with trust_score rating (without reading source code)"
    - "Marie Kondo produces findings JSON with dependency, code, and configuration inventory plus joy_score"
    - "All 4 agents operate independently with no cross-talk during their reviews"
  artifacts:
    - path: "docs/web/css/style.css"
      provides: "Fixed dark mode contrast for buttons, badges, and selected options"
      contains: "prefers-color-scheme: dark"
    - path: "outputs/bug_hunt/cyclops_findings.json"
      provides: "Deep code inspection findings"
      contains: "CYCLOPS-"
    - path: "outputs/bug_hunt/dale-gribble_findings.json"
      provides: "Security and sovereignty audit findings"
      contains: "DALE-"
    - path: "outputs/bug_hunt/mr-magoo_findings.json"
      provides: "Experiential user testing findings"
      contains: "MAGOO-"
    - path: "outputs/bug_hunt/marie-kondo_findings.json"
      provides: "Code hygiene inventory and findings"
      contains: "Marie Kondo"
  key_links:
    - from: "outputs/bug_hunt/*_findings.json"
      to: "18-02-PLAN.md fix wave"
      via: "findings JSON consumed by fix wave"
      pattern: "severity.*(critical|important)"
    - from: "outputs/website_review/SYNTHESIS.md"
      to: "docs/web/css/style.css"
      via: "P1 dark mode contrast fixes from Phase 17 inheritance"
      pattern: "P1-0[123]"
---

<objective>
Fix the 3 inherited P1 dark mode contrast issues and 6 P2/P3 issues from Phase 17, then execute the 4-agent adversarial audit across the complete TCR Policy Scanner system.

Purpose: Wave 1 of the three-wave Phase 18 structure. First, eliminate known defects so agents audit a clean baseline. Then, 4 independent agents (Cyclops, Dale Gribble, Mr. Magoo, Marie Kondo) produce the complete defect inventory that Wave 2 will act on. No other source code modifications happen after pre-fixes -- the agent audit is purely diagnostic.

Output:
- Fixed `docs/web/css/style.css` with WCAG AA-compliant dark mode contrast
- Fixed `docs/web/js/app.js` with reduced motion check and rel=noopener
- Fixed `docs/web/index.html` with noscript fallback
- 4 agent findings JSON files + markdown summaries in `outputs/bug_hunt/`
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-production-hardening/18-CONTEXT.md
@.planning/phases/18-production-hardening/18-RESEARCH.md

# Phase 17 known issues (inherited defects to fix first)
@outputs/website_review/SYNTHESIS.md

# Agent definitions (read these to understand each agent's checklist and output format)
@.planning/cyclops.md
@.planning/dale-gribble.md
@.planning/mr-magoo.md
@.planning/marie-kondo.md

# Website files (Cyclops + Dale Gribble domain)
@docs/web/index.html
@docs/web/css/style.css
@docs/web/js/app.js
@docs/web/js/combobox.js

# Deployment workflows (Dale Gribble domain)
@.github/workflows/deploy-website.yml
@.github/workflows/generate-packets.yml
@.github/workflows/daily-scan.yml

# Pipeline source (Cyclops + Marie Kondo domain)
@src/packets/orchestrator.py
@src/packets/docx_engine.py
@src/main.py
@src/config.py
@src/paths.py

# Scraper files (Dale Gribble domain)
@src/scrapers/federal_register.py
@src/scrapers/grants_gov.py
@src/scrapers/congress_gov.py
@src/scrapers/usaspending.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix inherited P1 and P2/P3 defects from Phase 17</name>
  <files>
docs/web/css/style.css
docs/web/js/app.js
docs/web/index.html
  </files>
  <action>
Fix all inherited issues from Phase 17's website review SYNTHESIS.md. These must be resolved BEFORE running agents so they audit a clean baseline.

**P1 Fixes (3 items -- all in docs/web/css/style.css):**

P1-01: Dark mode button contrast failure. Add dark mode overrides for `.btn-download` and `.btn-congressional`:
```css
@media (prefers-color-scheme: dark) {
  .btn-download { background: #1a5276; }
  .btn-download:hover { background: #1f6d9b; }
  .btn-congressional { background: #1a5276; }
  .btn-congressional:hover { background: #1f6d9b; }
}
```
Verify: #1a5276 on white text = 8.36:1 ratio (PASS). #1f6d9b on white = 5.89:1 (PASS).

P1-02: Dark mode badge contrast failure. Add dark mode badge overrides:
```css
@media (prefers-color-scheme: dark) {
  .badge-fresh { background: #1e7a3d; }
  .badge-aging { background: #b45309; }
  .badge-stale { background: #a93226; }
  .badge-unknown { background: #5a6268; }
}
```
Verify: All maintain 4.5:1+ with white text.

P1-03: Dark mode selected option contrast failure. Add override:
```css
@media (prefers-color-scheme: dark) {
  .listbox li[role="option"][aria-selected="true"] {
    background: #1a5276;
    color: #fff;
  }
}
```
Verify: #1a5276 on #fff = 8.36:1 (PASS).

**P2 Fixes (5 items):**

P2-01: Darken `--tcr-muted` from `#6c757d` to `#636b73` in the root CSS variables (light mode). Gives 4.78:1 ratio, above the 4.5:1 threshold.

P2-02: Add missing `.option-alias` CSS class:
```css
.option-alias {
  display: block;
  font-size: var(--tcr-fs-xs);
  color: var(--tcr-muted);
  font-style: italic;
}
```

P2-04: Fix scrollIntoView in `docs/web/js/app.js`. Find the `scrollIntoView({ behavior: "smooth" })` call and wrap it:
```javascript
var motionOK = !window.matchMedia("(prefers-reduced-motion: reduce)").matches;
cardEl.scrollIntoView({ behavior: motionOK ? "smooth" : "auto", block: "nearest" });
```

P2-05: Fix light mode selected option contrast. Change the selected option background to use `var(--tcr-primary)` instead of `var(--tcr-accent)`:
```css
.listbox li[role="option"][aria-selected="true"] {
  background: var(--tcr-primary);
  color: #fff;
}
```
This gives #1a5276 on #fff = 8.36:1 in light mode (PASS).

P2-03: Remove duplicate `max-width` in `.section-desc`. Delete the first `max-width: var(--tcr-max-w)` line, keep only `max-width: 65ch`.

**P3 Fixes (3 items):**

P3-02: Remove or replace the `atniclimate.github.io` URL in the HTML comment in `docs/web/index.html`. Replace with generic deployment URL comment.

P3-03: Add `a.rel = "noopener"` when creating download links in `docs/web/js/app.js`. Find where `<a>` elements are created for downloads and add `a.rel = "noopener"`.

P3-06: Add `<noscript>` fallback in `docs/web/index.html` after the loading div:
```html
<noscript><p class="noscript-message">This application requires JavaScript to search and download Tribal advocacy packets.</p></noscript>
```

P3-04: Remove `opacity: 0.7` from `.footer-credit` in `docs/web/css/style.css`, or adjust the color to maintain contrast.

**Consolidation:** All CSS fixes should be applied in a single pass to `style.css`. Organize the dark mode overrides into one cohesive `@media (prefers-color-scheme: dark)` block if one doesn't already exist (or add to the existing block).

**Run tests after all fixes:**
```bash
python -m pytest tests/ -v --tb=short
```
Existing tests should still pass since these are web-only changes.
  </action>
  <verify>
- All 3 P1 dark mode contrast fixes applied in `docs/web/css/style.css`
- All 5 P2 fixes applied across CSS, JS, and HTML
- All 3 P3 fixes applied
- `python -m pytest tests/ -v --tb=short` passes (no regressions)
- Dark mode button contrast >= 4.5:1 (verified by color values)
- Dark mode badge contrast >= 4.5:1
- Dark mode selected option contrast >= 4.5:1
- Light mode selected option contrast >= 4.5:1
- `.option-alias` CSS class exists
- `scrollIntoView` respects reduced motion preference
- `<noscript>` fallback exists
- `rel="noopener"` on download links
  </verify>
  <done>All 11 inherited defects from Phase 17 are fixed (3 P1, 5 P2, 3 P3). Dark mode WCAG AA compliance achieved. Website is at clean baseline for agent audit.</done>
</task>

<task type="auto">
  <name>Task 2: Execute 4 parallel adversarial agents and collect findings</name>
  <files>
outputs/bug_hunt/cyclops_findings.json
outputs/bug_hunt/cyclops_summary.md
outputs/bug_hunt/dale-gribble_findings.json
outputs/bug_hunt/dale-gribble_summary.md
outputs/bug_hunt/mr-magoo_findings.json
outputs/bug_hunt/mr-magoo_summary.md
outputs/bug_hunt/marie-kondo_findings.json
outputs/bug_hunt/marie-kondo_summary.md
  </files>
  <action>
**Create `outputs/bug_hunt/` directory** if it does not exist.

Execute the 4 adversarial agents. Each agent reads its assigned scope and produces a findings JSON file + markdown summary. Agents operate independently with no cross-talk.

**For each agent, follow their agent definition file exactly. Inspection methodology per agent:**

### Agent 1: Cyclops (HARD-01) -- Deep Code Inspection

**Methodology:** Read each source file in scope, then trace data paths end-to-end: user search input -> combobox selection -> manifest lookup -> DOCX download URL construction -> fetch/download -> Content-Disposition delivery. For each checklist item, locate the relevant code section, read surrounding context, and evaluate whether the implementation handles the edge case correctly. Document findings with file path, line number, and code snippet.

**Context loading:** Read STATE.md, PROJECT.md, outputs/website_review/SYNTHESIS.md, then trace data paths.

**Scope:** Website source code (`docs/web/js/app.js`, `docs/web/js/combobox.js`, `docs/web/index.html`), pipeline code (`src/packets/orchestrator.py`, `src/packets/docx_engine.py`, `src/main.py`), data flow from user input through search to DOCX download delivery.

**15-item checklist** (inspect each):
1. GitHub Pages fallback behavior when CDN is down
2. Tribal names with special characters (', -, diacritics like Pointe-au-Chien, Ho-Chunk, Tohono O'odham)
3. Manifest.json staleness vs pipeline output (deployed_at timestamp)
4. Search race conditions (debounce, stale closures in search-while-typing)
5. Download handler cleanup on abort/retry
6. XSS vectors in Tribe name display (DOM vs innerHTML)
7. 592 boundary test (what if all 592 results match?)
8. Ecoregion mapping injectivity (no Tribe in two regions)
9. Caching behavior (service worker, browser cache, CDN serving stale DOCX)
10. Error boundaries for component failures (N/A for vanilla JS -- check equivalent error handling)
11. Missing packet handling (Tribe with no DOCX generated)
12. Fetch timeout and try/catch wrapping
13. Case-insensitive AND diacritic-insensitive search index
14. Content-Disposition for DOCX MIME type on download
15. Memory leaks in search (unbounded result lists, event listener leaks)

**Output:** `outputs/bug_hunt/cyclops_findings.json` with fields: agent, timestamp, findings[] (id, severity, category, file, line, code_snippet, the_flaw, proof, blast_radius, fix), traces_completed[], structural_assessment.
**Also write:** `outputs/bug_hunt/cyclops_summary.md` with key findings in human-readable format.

### Agent 2: Dale Gribble (HARD-02) -- Security & Data Sovereignty Audit

**Methodology:** Inspect all network requests by reading HTML for external script/link tags, JS for fetch/XHR calls, and workflow YAML for external actions. Build a complete third-party dependency inventory (every external domain the system contacts). Evaluate each checklist item against the actual code. For sovereignty assessment, trace what data leaves the user's browser, what third parties can observe, and whether access control/revocation is possible.

**Context loading:** Read STATE.md, PROJECT.md, outputs/website_review/SYNTHESIS.md, TSDF framework.

**Scope:** Full system -- website (`docs/web/`), deployment (`.github/workflows/`), scrapers (`src/scrapers/`), CSP headers, third-party tracking, data sovereignty.

**18-item checklist** (inspect each):
1. HTTPS + Content-Security-Policy on DOCX delivery
2. Manifest enumeration (can someone iterate all 592 packets?)
3. Referrer leakage from SquareSpace embed
4. Analytics/tracking scripts (zero tolerance)
5. TSDF T0/T1 classification enforcement
6. URL manipulation to download other Tribes' packets
7. CDN dependencies (third-party compromise risk)
8. JavaScript disabled degradation
9. GitHub API rate limits for 200 concurrent users
10. PII in DOCX filenames or URLs
11. MITM between GitHub Pages and SquareSpace
12. Google Fonts phone-home check
13. Cookies (who sets them, for what)
14. IP exposure to GitHub during downloads
15. Malicious SquareSpace plugin access to iframe
16. Subresource Integrity (SRI) for CDN resources
17. Hardcoded API keys, tokens, or secrets in bundle
18. Source maps exposing internal logic

**Data Sovereignty assessment:** Evaluate against UNDRIP, OCAP, CARE, TSDF frameworks. Answer: Who sees what data? Who controls access? Can access be revoked? Is there an audit trail? Do third parties gain access to usage patterns?

**Output:** `outputs/bug_hunt/dale-gribble_findings.json` with fields: agent, timestamp, findings[] (id, severity, category, threat, evidence, attack_vector, sovereignty_impact, fix, paranoia_level), third_party_inventory[], data_flow_map, sovereignty_assessment.
**Also write:** `outputs/bug_hunt/dale-gribble_summary.md`.

### Agent 3: Mr. Magoo (HARD-03) -- Experiential User Testing

**Methodology:** Navigate the website as a user by reading the HTML structure and CSS styling ONLY (no JS source code). Walk through each user journey: landing -> search -> select Tribe -> download packet. For each checklist item, simulate the user action by reading the HTML element the user would interact with and assessing clarity, discoverability, and trust. Evaluate visual design by reading CSS classes and their styles. Record subjective experience (confusion, delight, frustration) as findings.

**Context loading:** Read STATE.md, PROJECT.md, outputs/website_review/SYNTHESIS.md. DO NOT read any source code files.

**Method:** Navigate as a non-technical Tribal staff member. Read the built HTML/CSS files ONLY to experience the product visually (as a user would in a browser). DO NOT open JavaScript source code. Evaluate the website experience from a user's perspective.

**12-item checklist** (test each):
1. Find a Tribe without exact spelling (try: "Navaho" for Navajo, "Sycuan" partial, "Standing Rock" multi-word)
2. Download button clarity (what am I getting? which document type?)
3. Wrong download recovery (downloaded wrong Tribe, try again)
4. Speed and jank perception (does anything feel slow?)
5. Confusion points (moments of "what do I do now?")
6. Error messages (do they help fix the problem?)
7. TSDF disclaimer (trustworthy or intimidating?)
8. Mobile experience (everything works at 375px viewport?)
9. Shareable link (if I share URL, will colleague understand it?)
10. Broken feeling (things that technically work but feel wrong)
11. Visual design (respectful and professional?)
12. Council-ready (would a Tribal Leader show this to their council?)

**Output:** `outputs/bug_hunt/mr-magoo_findings.json` with fields: agent, timestamp, findings[] (id, severity, category, what_happened, what_i_expected, how_i_got_here, how_it_felt, suggestion), overall_impression, trust_score (1-10).
**Also write:** `outputs/bug_hunt/mr-magoo_summary.md`.

### Agent 4: Marie Kondo (HARD-04) -- Code Hygiene Sweep

**Methodology:** Systematically grep for unused imports across all Python files (compare `import X` lines against `X` usage in the same file). Identify dead functions by searching for `def function_name` and checking whether `function_name` appears in any other file's imports or calls. Check for unreferenced config keys by reading JSON config files and searching for each key across the codebase. Produce a COMPLETE INVENTORY of all findings (this is the full codebase identification). The inventory is exhaustive -- every candidate for cleanup is catalogued with file, line, and rationale, regardless of whether it will be fixed in this phase. Plan 18-02 will apply only a safe low-risk subset of this inventory.

**Context loading:** Read STATE.md, PROJECT.md, outputs/website_review/SYNTHESIS.md.

**Scope:** All Python source files (`src/**/*.py`, 96 files), scripts (`scripts/*.py`, ~17 files), test files (`tests/test_*.py`, ~31 files), web files (`docs/web/`), config files.

**Adapted for actual stack** (Python + vanilla JS, NOT React/npm/TypeScript):

**Pass 1: Python Dependency Inventory**
- Read `requirements.txt` and compare to actual imports across all Python files
- Are all listed dependencies actually imported?
- Are any imported packages missing from requirements.txt?
- Could any dependency be replaced with stdlib?

**Pass 2: Python Code Inventory**
- Are there functions/classes that are never called/imported from outside their file?
- Are there unused imports in any source file?
- Are there modules that nothing imports?
- Are there TODO/FIXME comments for resolved issues?
- Are there dead code paths behind always-false conditions?

**Pass 3: Configuration Inventory**
- Are there config files that duplicate defaults?
- Are GitHub Actions workflow steps that could be simplified?
- Are there web files that are unused?
- Do config JSON files have unused keys?

**Skip entirely:** npm, package.json, React components, TypeScript, shadcn -- none of these exist in this project.

**Output:** `outputs/bug_hunt/marie-kondo_findings.json` with fields: agent, timestamp, inventory (dependencies, code, configuration categories with items), joy_score (1-10), joy_score_potential (1-10).
**Also write:** `outputs/bug_hunt/marie-kondo_summary.md`.

**Severity mapping for all agents:**
- critical = P0 (blocks launch)
- important = P1 (must fix before launch)
- cosmetic = P2/P3 (fix post-launch)

**Important reminders:**
- Each agent produces BOTH a JSON findings file AND a markdown summary
- No source files are modified during agent audits (read-only)
- Mr. Magoo must NOT read source code (only HTML structure for visual assessment)
- Run `python -m pytest tests/ -v --tb=short` at the end to confirm no regressions from Task 1
  </action>
  <verify>
- `outputs/bug_hunt/` directory exists with 8 files (4 JSON + 4 markdown)
- Each JSON file is valid JSON and parseable
- Cyclops findings cover all 15 checklist items (explicitly addressed in structural_assessment)
- Dale Gribble findings include sovereignty_assessment and third_party_inventory
- Mr. Magoo findings include trust_score (1-10) and overall_impression
- Marie Kondo findings include inventory with dependency/code/configuration categories and joy_score
- Each finding has required fields per agent schema
- No source files were modified during agent audits
- `python -m pytest tests/ -v --tb=short` still passes
  </verify>
  <done>4 adversarial agent findings files + summaries exist in outputs/bug_hunt/, covering all checklist items across deep code inspection (15 items), security/sovereignty (18 items), experiential UX (12 items), and code hygiene (3-pass inventory)</done>
</task>

</tasks>

<verification>
1. All 3 P1 dark mode contrast issues from Phase 17 are fixed with WCAG AA-compliant colors
2. All P2/P3 issues from Phase 17 are fixed (option-alias, scrollIntoView, noscript, noopener, muted text, selected option, footer opacity, duplicate max-width, HTML comment)
3. All 4 agent findings JSON files exist in `outputs/bug_hunt/` and are valid JSON
4. All 4 agent markdown summaries exist in `outputs/bug_hunt/`
5. Each agent covered every item on their checklist
6. No source files were modified during agent audits (except pre-flight fixes in Task 1)
7. All existing tests pass: `python -m pytest tests/ -v --tb=short`
8. Severity classifications follow critical/important/cosmetic mapping
</verification>

<success_criteria>
- Dark mode WCAG AA compliance achieved across buttons, badges, and selected options
- 4 independent adversarial agents each produced comprehensive findings
- Complete defect inventory ready for Wave 2 triage and fix cycle
- No regressions introduced by pre-flight fixes
</success_criteria>

<output>
After completion, create `.planning/phases/18-production-hardening/18-01-SUMMARY.md`
</output>
