---
phase: 14-integration
plan: 05
type: execute
wave: 3
depends_on: ["14-03", "14-04"]
files_modified:
  - src/packets/quality_review.py
  - src/packets/orchestrator.py
  - tests/test_quality_review.py
autonomous: true

must_haves:
  truths:
    - "Quality review detects strategy/leverage content in Doc B and Doc D (audience leakage)"
    - "Quality review detects air gap violations (organizational names in any document)"
    - "Quality review detects placeholder text in documents for Tribes with real data"
    - "Batch generation produces Doc A + Doc B for 400+ Tribes and Doc C + Doc D for 8 regions"
  artifacts:
    - path: "src/packets/quality_review.py"
      provides: "DocumentQualityReviewer with automated content checks"
      exports: ["DocumentQualityReviewer"]
    - path: "tests/test_quality_review.py"
      provides: "Tests for quality review detection logic"
      min_lines: 50
  key_links:
    - from: "src/packets/quality_review.py"
      to: "src/packets/doc_types.py"
      via: "Reviewer uses DocumentTypeConfig to determine expected content rules"
      pattern: "DocumentTypeConfig"
    - from: "src/packets/orchestrator.py"
      to: "src/packets/quality_review.py"
      via: "Orchestrator runs quality review after batch generation"
      pattern: "DocumentQualityReviewer"
---

<objective>
Build automated quality review and run batch generation to produce complete document sets for 400+ Tribes and all 8 regions.

Purpose: This plan validates that the full pipeline produces correct, audience-differentiated, air-gap-compliant documents at scale. The quality reviewer catches content leakage, placeholder text, and formatting issues. Batch generation confirms INTG-02 (400+ Tribes with complete packets).

Output: quality_review.py module with automated checks; batch generation completed with quality report; 400+ Tribes have Doc A + Doc B; 8 regions have Doc C + Doc D.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/PHASE-14-DESIGN-DECISIONS.md
@.planning/phases/14-integration/14-03-SUMMARY.md
@.planning/phases/14-integration/14-04-SUMMARY.md
@src/packets/orchestrator.py
@src/packets/doc_types.py
@src/packets/agent_review.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DocumentQualityReviewer with automated checks</name>
  <files>src/packets/quality_review.py, tests/test_quality_review.py</files>
  <action>
  Create `src/packets/quality_review.py` with automated document quality checking.

  **DocumentQualityReviewer class:**
  ```python
  class DocumentQualityReviewer:
      """Automated quality review for generated advocacy documents.

      Checks audience differentiation, air gap compliance, placeholder detection,
      and content completeness.
      """

      # Words/phrases that must NEVER appear in congressional docs (B/D)
      INTERNAL_ONLY_PATTERNS = [
          "strategic leverage", "approach strategy", "messaging framework",
          "pressure point", "leverage point", "window of opportunity",
          "sequencing", "prioritize meeting", "approach.*with.*frame",
          "voting record", "political dynamic", "lobby", "lobbying",
          "push for", "the lever", "impoundment", "hollowing",
          "withholding", "circumventing",
      ]

      # Words/phrases that must NEVER appear in any document (air gap)
      AIR_GAP_VIOLATIONS = [
          "TCR Policy Scanner", "ATNI", "NCAI",
          "IndigenousACCESS", "Climate Resilience Committee",
          "Tribal Advocacy Packet", "Generated by",
          "Prepared by", "our organization", "the Task Force",
          "the Committee",
      ]

      # Placeholder patterns that should not survive in docs with real data
      PLACEHOLDER_PATTERNS = [
          "data pending", "TBD", "placeholder", "[INSERT",
          "PLACEHOLDER", "data not available",
      ]

      def review_document(self, docx_path, doc_type_config) -> ReviewResult:
          """Review a single document against quality criteria.

          Returns ReviewResult with pass/fail for each check category.
          """
          doc = Document(str(docx_path))
          all_text = ' '.join(p.text for p in doc.paragraphs)
          all_text_lower = all_text.lower()

          issues = []

          # Check 1: Audience leakage (congressional docs only)
          if doc_type_config.is_congressional:
              for pattern in self.INTERNAL_ONLY_PATTERNS:
                  if re.search(pattern, all_text_lower):
                      issues.append(ReviewIssue(
                          category="audience_leakage",
                          severity="critical",
                          message=f"Internal-only pattern found in congressional doc: '{pattern}'",
                      ))

          # Check 2: Air gap violations (all docs)
          for pattern in self.AIR_GAP_VIOLATIONS:
              if pattern.lower() in all_text_lower:
                  issues.append(ReviewIssue(
                      category="air_gap",
                      severity="critical",
                      message=f"Air gap violation: '{pattern}' found in document",
                  ))

          # Check 3: Placeholder text
          for pattern in self.PLACEHOLDER_PATTERNS:
              if pattern.lower() in all_text_lower:
                  issues.append(ReviewIssue(
                      category="placeholder",
                      severity="warning",
                      message=f"Placeholder text found: '{pattern}'",
                  ))

          # Check 4: Confidential marking correctness
          if doc_type_config.confidential:
              if "confidential" not in all_text_lower:
                  issues.append(ReviewIssue(
                      category="formatting",
                      severity="warning",
                      message="Internal doc missing CONFIDENTIAL marking",
                  ))
          else:
              if "confidential" in all_text_lower and "for congressional" not in all_text_lower:
                  issues.append(ReviewIssue(
                      category="formatting",
                      severity="critical",
                      message="Congressional doc contains CONFIDENTIAL marking",
                  ))

          # Check 5: Minimum content (not an empty shell)
          if len(doc.paragraphs) < 20:
              issues.append(ReviewIssue(
                  category="content",
                  severity="warning",
                  message=f"Document has only {len(doc.paragraphs)} paragraphs (expected 20+)",
              ))

          # Check 6: Has executive summary
          if "executive summary" not in all_text_lower:
              issues.append(ReviewIssue(
                  category="content",
                  severity="warning",
                  message="Missing Executive Summary section",
              ))

          return ReviewResult(
              path=docx_path,
              doc_type=doc_type_config.doc_type,
              issues=issues,
              passed=not any(i.severity == "critical" for i in issues),
          )

      def review_batch(self, output_dir, doc_type_config_map=None) -> BatchReviewResult:
          """Review all documents in output directory.

          Returns aggregate results with pass/fail counts and issue summary.
          """
          # Scan internal/ and congressional/ subdirs
          # Review each .docx file with the appropriate doc_type_config
          # Return BatchReviewResult with totals

      def generate_report(self, batch_result) -> str:
          """Generate markdown report of batch review results."""
  ```

  **Supporting dataclasses:**
  ```python
  @dataclass
  class ReviewIssue:
      category: str    # "audience_leakage", "air_gap", "placeholder", "formatting", "content"
      severity: str    # "critical", "warning"
      message: str

  @dataclass
  class ReviewResult:
      path: Path
      doc_type: str
      issues: list[ReviewIssue]
      passed: bool

  @dataclass
  class BatchReviewResult:
      total_reviewed: int
      total_passed: int
      total_failed: int
      critical_issues: int
      warning_issues: int
      issues_by_category: dict[str, int]
      failed_documents: list[ReviewResult]
  ```

  **Tests (tests/test_quality_review.py):**
  1. `test_detects_audience_leakage`: Create a mock DOCX with "Strategic Leverage" text, review as DOC_B -> critical issue detected
  2. `test_no_false_positive_for_internal`: Same text reviewed as DOC_A -> no audience_leakage issue
  3. `test_detects_air_gap_violation`: Create DOCX with "TCR Policy Scanner", review -> air_gap critical
  4. `test_detects_placeholder`: Create DOCX with "data pending", review -> placeholder warning
  5. `test_clean_doc_passes`: Create DOCX with only factual content, review as DOC_B -> passes
  6. `test_confidential_correctness`: Internal doc without CONFIDENTIAL -> warning; congressional doc with CONFIDENTIAL -> critical
  7. `test_batch_review_aggregation`: Review multiple mock docs, verify batch totals correct

  Create mock DOCX files in tests using python-docx directly (small docs with targeted content).
  </action>
  <verify>
  1. `python -m pytest tests/test_quality_review.py -v` -- all tests pass
  2. `python -c "from src.packets.quality_review import DocumentQualityReviewer; print('Import OK')"`
  3. `python -m pytest tests/ -x -q` -- full suite passes
  </verify>
  <done>DocumentQualityReviewer detects audience leakage, air gap violations, placeholder text, and formatting issues; tests prove detection logic is correct; batch review aggregation works</done>
</task>

<task type="auto">
  <name>Task 2: Run batch generation and quality review for all Tribes and regions</name>
  <files>src/packets/orchestrator.py</files>
  <action>
  Wire quality review into the orchestrator and run batch generation.

  1. Add quality review to the orchestrator's batch flow:
     ```python
     def run_all_tribes(self):
         # ... existing Tribal doc generation (now produces Doc A + Doc B per Tribe) ...
         # ... regional doc generation (Doc C + Doc D per region) ...

         # Quality review
         reviewer = DocumentQualityReviewer()
         batch_result = reviewer.review_batch(self.output_dir)
         report = reviewer.generate_report(batch_result)

         # Save report
         report_path = self.output_dir / "quality_report.md"
         report_path.write_text(report)
         logger.info(f"Quality review: {batch_result.total_passed}/{batch_result.total_reviewed} passed")

         return batch_result
     ```

  2. Run the full batch generation:
     ```
     python -m src.main --prep-packets --all-tribes
     ```

     This should now produce:
     - `outputs/packets/internal/{tribe_slug}_internal_strategy_fy26.docx` (Doc A) for complete-data Tribes
     - `outputs/packets/congressional/{tribe_slug}_congressional_overview_fy26.docx` (Doc B) for all Tribes
     - `outputs/packets/regional/internal/{region_slug}_intertribal_strategy_fy26.docx` (Doc C) for 8 regions
     - `outputs/packets/regional/congressional/{region_slug}_congressional_overview_fy26.docx` (Doc D) for 8 regions
     - `outputs/packets/quality_report.md` with review results

  3. Verify INTG-02 target: count Doc A + Doc B pairs where both exist. Target: 400+ Tribes with complete packets (both Doc A and Doc B).

  4. If quality review finds critical issues, fix the most common patterns. The reviewer should guide what needs fixing (audience leakage, air gap violations, etc.). Focus on fixing systemic issues (patterns that affect many docs), not individual edge cases.

  5. Count final outputs:
     - Doc A generated: X (target: 400+)
     - Doc B generated: X (target: 592)
     - Doc C generated: X (target: 8)
     - Doc D generated: X (target: 8)
     - Quality review pass rate: X% (target: 95%+)

  NOTE: Batch generation may take 5-10 minutes for ~1200 documents. The existing gc.collect() every 25 Tribes is already in place. If memory is an issue, process in smaller batches.

  If the existing --all-tribes flag isn't working with the new multi-doc flow, troubleshoot by running a single Tribe first: `python -m src.main --prep-packets --tribe "Muckleshoot Indian Tribe"` and verifying 2 docs generated.
  </action>
  <verify>
  1. Count generated files:
     `python -c "from pathlib import Path; d=Path('outputs/packets'); print(f'Doc A: {len(list((d/\"internal\").glob(\"*.docx\")))}'); print(f'Doc B: {len(list((d/\"congressional\").glob(\"*.docx\")))}'); print(f'Doc C: {len(list((d/\"regional/internal\").glob(\"*.docx\")))}'); print(f'Doc D: {len(list((d/\"regional/congressional\").glob(\"*.docx\")))}')" `
  2. Read quality_report.md -- pass rate 95%+, zero critical audience leakage
  3. `python -m pytest tests/ -x -q` -- full suite passes
  </verify>
  <done>Batch generation produces Doc A for 400+ Tribes, Doc B for 500+ Tribes, Doc C for 8 regions, Doc D for 8 regions; quality review passes 95%+ with zero audience leakage; INTG-02 met</done>
</task>

</tasks>

<verification>
1. DocumentQualityReviewer catches audience leakage, air gap violations, placeholders
2. Batch generation completes for all Tribes and regions
3. 400+ Tribes have both Doc A + Doc B (INTG-02)
4. 8 regions have both Doc C + Doc D
5. Quality report shows 95%+ pass rate
6. Zero critical audience leakage issues in final output
7. Full test suite passes
</verification>

<success_criteria>
- Quality reviewer passes automated tests for all check categories
- 400+ Tribes have complete Doc A + Doc B packets (INTG-02)
- 8 regions have Doc C + Doc D
- Quality review: 95%+ documents pass all critical checks
- Zero audience leakage (internal content in congressional docs)
- Zero air gap violations (organizational names)
</success_criteria>

<output>
After completion, create `.planning/phases/14-integration/14-05-SUMMARY.md`
</output>
