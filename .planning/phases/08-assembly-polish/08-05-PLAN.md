---
phase: 08-assembly-polish
plan: 05
type: execute
wave: 3
depends_on: ["08-03"]
files_modified:
  - docs/web/index.html
  - docs/web/css/style.css
  - docs/web/js/app.js
  - docs/web/js/awesomplete.min.js
  - docs/web/css/awesomplete.css
  - scripts/build_web_index.py
  - .github/workflows/generate-packets.yml
  - tests/test_web_index.py
autonomous: true

must_haves:
  truths:
    - "Self-contained HTML/CSS/JS search widget at docs/web/index.html (no framework, no build step)"
    - "Tribe autocomplete via Awesomplete library (vendored, MIT license)"
    - "Info card shows Tribe name, state(s), ecoregion on selection"
    - "DOCX download via direct <a href> link with download attribute"
    - "Mobile-responsive (flexbox, stacks on <600px)"
    - "WCAG 2.1 AA accessible (focus states, aria labels, color contrast)"
    - "Total widget bundle <15KB (excluding data/tribes.json and DOCX files)"
    - "scripts/build_web_index.py generates tribes.json from registry + packet directory"
    - "GitHub Actions workflow: weekly schedule + manual trigger, generates packets, builds index, commits to docs/web/"
    - "SquareSpace iframe embed code documented"
    - "All 214+ existing tests still pass"
  artifacts:
    - path: "docs/web/index.html"
      provides: "Self-contained search page with semantic HTML5, autocomplete, info card, download button"
      min_lines: 60
    - path: "docs/web/css/style.css"
      provides: "Mobile-first responsive styles with TCR brand colors and WCAG 2.1 AA contrast"
      min_lines: 80
    - path: "docs/web/js/app.js"
      provides: "Widget logic: fetch tribes.json, init Awesomplete, handle selection, show card, set download link"
      min_lines: 60
    - path: "docs/web/js/awesomplete.min.js"
      provides: "Vendored Awesomplete autocomplete library (MIT license)"
    - path: "docs/web/css/awesomplete.css"
      provides: "Vendored Awesomplete styles"
    - path: "scripts/build_web_index.py"
      provides: "build_index() CLI with --registry, --packets, --output args"
      min_lines: 60
    - path: ".github/workflows/generate-packets.yml"
      provides: "CI workflow: cron Sunday 8AM Pacific + manual dispatch, generates packets and commits"
      min_lines: 30
    - path: "tests/test_web_index.py"
      provides: "5+ tests for build_index() output correctness"
      min_lines: 60
  key_links:
    - from: "scripts/build_web_index.py"
      to: "data/tribal_registry.json"
      via: "build_index() reads Tribe list from registry"
      pattern: "tribal_registry"
    - from: "scripts/build_web_index.py"
      to: "outputs/packets/tribes/"
      via: "build_index() scans for DOCX files to set has_packet and file_size_kb"
      pattern: "packets"
    - from: ".github/workflows/generate-packets.yml"
      to: "src/main.py"
      via: "Workflow runs python -m src.main --prep-packets --all-tribes"
      pattern: "prep-packets"
    - from: ".github/workflows/generate-packets.yml"
      to: "scripts/build_web_index.py"
      via: "Workflow runs build_web_index.py after packet generation"
      pattern: "build_web_index"
    - from: "docs/web/js/app.js"
      to: "docs/web/data/tribes.json"
      via: "Widget fetches tribes.json at runtime for autocomplete data"
      pattern: "tribes.json"
---

<objective>
Build the GitHub Pages search widget, web index builder, and CI workflow -- enabling Tribal advocacy packet discovery and download via a lightweight static web page embeddable in SquareSpace.

Purpose: WEB-01 requires a self-contained search+download widget. WEB-02 requires automated packet generation via GitHub Actions. WEB-03 requires SquareSpace iframe embed code. The widget uses no frameworks and no build step -- just HTML, CSS, and vanilla JS with vendored Awesomplete for autocomplete.
Output: Static widget in docs/web/, index builder script, GitHub Actions workflow, and tests.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-assembly-polish/08-CONTEXT.md
@.planning/phases/08-assembly-polish/08-MASTER-PROMPT.md
@.planning/phases/08-assembly-polish/08-03-SUMMARY.md

@data/tribal_registry.json
@src/packets/orchestrator.py
@src/main.py
@config/scanner_config.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docs/web/ static widget</name>
  <files>docs/web/index.html, docs/web/css/style.css, docs/web/js/app.js, docs/web/js/awesomplete.min.js, docs/web/css/awesomplete.css</files>
  <action>
**Create `docs/web/index.html`** -- semantic HTML5 search page:

- DOCTYPE html with lang="en"
- Meta viewport for mobile
- Title: "TCR Policy Scanner -- Tribal Advocacy Packet Search"
- Link to css/style.css and css/awesomplete.css
- Header: "Tribal Climate Resilience" with subtitle "Advocacy Packet Search"
- Main content:
  - Search section: label + text input with id="tribe-search", placeholder="Start typing a Tribe name...", role="combobox", aria-label="Search for a Tribal Nation"
  - Loading indicator: div with id="loading" showing "Loading Tribe data..." (hidden after fetch)
  - Error indicator: div with id="error" (hidden by default) for fetch failures
  - Info card: div with id="tribe-card" (hidden until selection) containing:
    - h2 for Tribe name
    - p elements for state(s) and ecoregion
    - Download button: `<a id="download-link" class="btn-download" role="button">Download Report</a>`
    - Packet status indicator (available/not yet generated)
  - Footer with "Download Strategic Overview" link and SquareSpace embed instructions as HTML comment
- Script tags for js/awesomplete.min.js and js/app.js (defer)

**Create `docs/web/css/style.css`** -- mobile-first responsive styles (~3KB):

- CSS custom properties for TCR brand: --tcr-primary: #1a5276, --tcr-primary-light: #2980b9, --tcr-bg: #f8f9fa, --tcr-text: #2c3e50, --tcr-card-bg: #ffffff, --tcr-border: #dee2e6
- Base: box-sizing border-box, system font stack, body bg #f8f9fa
- Header: dark teal (#1a5276) background, white text, padding
- .search-container: max-width 640px, centered, padding
- Input styles: full width, large text, rounded border, focus ring with outline-offset for WCAG
- .tribe-card: white card with subtle shadow, rounded corners, padding, hidden by default
- .btn-download: teal background, white text, padding, rounded, hover/focus states with outline
- .btn-download[aria-disabled="true"]: grayed out state for unavailable packets
- Loading/error states: centered text, muted colors
- Footer: muted text, centered, smaller font
- @media (max-width: 600px): stack layout, full-width card, larger touch targets (min 44px)
- @media (prefers-reduced-motion): remove transitions
- @media print: hide search, show card only
- All interactive elements have visible focus states (outline, not just color change)
- Color contrast ratio >= 4.5:1 for all text

**Create `docs/web/js/app.js`** -- widget logic (~5KB):

```javascript
(function () {
  "use strict";

  const TRIBES_URL = "data/tribes.json";

  const searchInput = document.getElementById("tribe-search");
  const loadingEl = document.getElementById("loading");
  const errorEl = document.getElementById("error");
  const cardEl = document.getElementById("tribe-card");
  // ... element references

  let tribesData = null;
  let tribeMap = new Map(); // name -> tribe object

  async function init() {
    try {
      const resp = await fetch(TRIBES_URL);
      if (!resp.ok) throw new Error(`HTTP ${resp.status}`);
      tribesData = await resp.json();

      // Build lookup map
      tribesData.tribes.forEach(t => tribeMap.set(t.name, t));

      // Init Awesomplete
      new Awesomplete(searchInput, {
        list: tribesData.tribes.map(t => t.name),
        minChars: 2,
        maxItems: 15,
        autoFirst: true
      });

      loadingEl.hidden = true;
      searchInput.disabled = false;
      searchInput.focus();
    } catch (err) {
      loadingEl.hidden = true;
      errorEl.hidden = false;
      errorEl.textContent = "Failed to load Tribe data. Please try again later.";
      console.error("Failed to load tribes.json:", err);
    }
  }

  searchInput.addEventListener("awesomplete-selectcomplete", function (evt) {
    const tribe = tribeMap.get(evt.text.value);
    if (!tribe) return;
    showCard(tribe);
  });

  function showCard(tribe) {
    // Populate card fields
    document.getElementById("tribe-name").textContent = tribe.name;
    document.getElementById("tribe-states").textContent = tribe.states.join(", ");
    document.getElementById("tribe-ecoregion").textContent = tribe.ecoregion || "N/A";

    const downloadLink = document.getElementById("download-link");
    if (tribe.has_packet) {
      downloadLink.href = "tribes/" + tribe.id + ".docx";
      downloadLink.setAttribute("download", "");
      downloadLink.removeAttribute("aria-disabled");
      downloadLink.textContent = "Download Report";
    } else {
      downloadLink.removeAttribute("href");
      downloadLink.setAttribute("aria-disabled", "true");
      downloadLink.textContent = "Packet Not Yet Available";
    }

    cardEl.hidden = false;
  }

  document.addEventListener("DOMContentLoaded", init);
})();
```

**Vendor Awesomplete** (MIT license) into js/ and css/:
- Download awesomplete.min.js (~2KB) from https://cdnjs.cloudflare.com/ajax/libs/awesomplete/1.1.7/awesomplete.min.js
- Download awesomplete.css (~1KB) from https://cdnjs.cloudflare.com/ajax/libs/awesomplete/1.1.7/awesomplete.css
- If download fails, create minimal stubs with a TODO comment and the CDN URL
- Include MIT license attribution comment at top of vendored files

**Critical notes:**
- No external CDN links in production HTML -- all assets vendored locally
- No framework, no build step, no npm
- All ARIA attributes: role="combobox", aria-expanded, aria-label on input; role="button" on download link
- Tab order: search input -> download button -> strategic overview link
- Error boundary: if tribes.json fails to load, show user-friendly error, do not break page
  </action>
  <verify>
Open docs/web/index.html in a browser -- search input visible, no JS errors in console (manual check).
Verify total file sizes: `python -c "import pathlib; total = sum(f.stat().st_size for f in pathlib.Path('docs/web').rglob('*') if f.is_file() and f.name != 'tribes.json' and f.suffix != '.docx'); print(f'{total} bytes ({total/1024:.1f} KB)')"` -- should be <15KB
  </verify>
  <done>Static widget created with semantic HTML, WCAG 2.1 AA accessible styles, and vanilla JS autocomplete. All assets vendored locally, no external dependencies. Bundle size under 15KB.</done>
</task>

<task type="auto">
  <name>Task 2: Create scripts/build_web_index.py</name>
  <files>scripts/build_web_index.py</files>
  <action>
**Create `scripts/build_web_index.py`** with CLI and build_index() function:

```python
#!/usr/bin/env python3
"""Build tribes.json index for the GitHub Pages widget.

Reads tribal_registry.json + scans packets directory to build
a searchable index with download metadata.

Usage:
    python scripts/build_web_index.py
    python scripts/build_web_index.py --registry data/tribal_registry.json \
        --packets outputs/packets/tribes --output docs/web/data/tribes.json
"""

import argparse
import json
import logging
from datetime import datetime, timezone
from pathlib import Path

logger = logging.getLogger(__name__)

DEFAULT_REGISTRY = Path("data/tribal_registry.json")
DEFAULT_PACKETS = Path("outputs/packets/tribes")
DEFAULT_OUTPUT = Path("docs/web/data/tribes.json")


def build_index(
    registry_path: Path,
    packets_dir: Path,
    output_path: Path,
) -> dict:
    """Build tribes.json with searchable index and packet metadata.

    Args:
        registry_path: Path to tribal_registry.json.
        packets_dir: Directory containing per-Tribe DOCX files.
        output_path: Where to write tribes.json.

    Returns:
        The index dict that was written.
    """
    # Read registry
    with open(registry_path, "r", encoding="utf-8") as f:
        size = registry_path.stat().st_size
        if size > 10 * 1024 * 1024:
            raise ValueError(f"Registry file too large: {size} bytes")
        registry = json.load(f)

    tribes_list = registry if isinstance(registry, list) else registry.get("tribes", [])

    # Scan packets directory for existing DOCX files
    existing_packets: dict[str, int] = {}
    if packets_dir.is_dir():
        for docx_file in packets_dir.glob("*.docx"):
            tribe_id = docx_file.stem
            size_kb = round(docx_file.stat().st_size / 1024, 1)
            existing_packets[tribe_id] = size_kb

    # Build index entries
    tribes_index = []
    for tribe in tribes_list:
        tribe_id = tribe.get("epa_id", tribe.get("id", ""))
        entry = {
            "id": tribe_id,
            "name": tribe.get("name", ""),
            "states": tribe.get("states", []),
            "ecoregion": tribe.get("ecoregion", ""),
            "has_packet": tribe_id in existing_packets,
            "file_size_kb": existing_packets.get(tribe_id, 0),
        }
        tribes_index.append(entry)

    index = {
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "packet_count": len(existing_packets),
        "total_tribes": len(tribes_index),
        "tribes": tribes_index,
    }

    # Write output (atomic: tmp + os.replace)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    tmp_path = output_path.with_suffix(".tmp")
    try:
        with open(tmp_path, "w", encoding="utf-8") as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
        import os
        os.replace(str(tmp_path), str(output_path))
    except Exception:
        if tmp_path.exists():
            tmp_path.unlink()
        raise

    logger.info(
        "Built tribes.json: %d tribes, %d packets",
        len(tribes_index),
        len(existing_packets),
    )
    return index


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Build tribes.json index for the web widget."
    )
    parser.add_argument(
        "--registry",
        type=Path,
        default=DEFAULT_REGISTRY,
        help=f"Path to tribal_registry.json (default: {DEFAULT_REGISTRY})",
    )
    parser.add_argument(
        "--packets",
        type=Path,
        default=DEFAULT_PACKETS,
        help=f"Directory containing per-Tribe DOCX files (default: {DEFAULT_PACKETS})",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT,
        help=f"Output path for tribes.json (default: {DEFAULT_OUTPUT})",
    )
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(message)s")
    index = build_index(args.registry, args.packets, args.output)
    print(f"Generated tribes.json: {index['total_tribes']} tribes, {index['packet_count']} packets")


if __name__ == "__main__":
    main()
```

**Critical notes:**
- 10MB size cap on registry file before json.load()
- Atomic write with tmp + os.replace() + cleanup on exception
- encoding="utf-8" on all file I/O
- datetime.now(timezone.utc) for timestamps
- Handle both list and dict registry formats (some versions wrap in {"tribes": [...]})
- Path traversal safe: only reads .stem from existing files in known directory
  </action>
  <verify>
Run: `python -c "from scripts.build_web_index import build_index"` -- import works (or run as script with mock data)
  </verify>
  <done>build_web_index.py generates valid tribes.json with correct has_packet and file_size_kb for all registry Tribes. Atomic write pattern. CLI with --registry, --packets, --output args.</done>
</task>

<task type="auto">
  <name>Task 3: Create .github/workflows/generate-packets.yml</name>
  <files>.github/workflows/generate-packets.yml</files>
  <action>
**Create `.github/workflows/generate-packets.yml`**:

```yaml
name: Generate Advocacy Packets

on:
  schedule:
    - cron: '0 15 * * 0'  # Sunday 8AM Pacific (15:00 UTC)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Generate all packets
        env:
          CONGRESS_API_KEY: ${{ secrets.CONGRESS_API_KEY }}
          SAM_API_KEY: ${{ secrets.SAM_API_KEY }}
        run: python -m src.main --prep-packets --all-tribes

      - name: Build web index
        run: python scripts/build_web_index.py

      - name: Stage for GitHub Pages
        run: |
          mkdir -p docs/web/tribes docs/web/data
          cp outputs/packets/tribes/*.docx docs/web/tribes/ || true
          cp outputs/packets/STRATEGIC-OVERVIEW.docx docs/web/tribes/ || true

      - name: Commit and push
        run: |
          git config user.name "TCR Policy Scanner"
          git config user.email "scanner@tcr-policy-scanner.local"
          git add docs/web/tribes/ docs/web/data/tribes.json
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            git commit -m "packets: generate $(date -u +%Y-%m-%d)"
            git push
          fi
```

**Critical notes:**
- Cron: 0 15 * * 0 = Sunday at 15:00 UTC = 8AM Pacific (PST) / 8AM PDT adjusted
- workflow_dispatch allows manual triggering from GitHub UI
- Secrets: CONGRESS_API_KEY and SAM_API_KEY must be configured in repo Settings > Secrets
- Timeout: 30 minutes (592 Tribes at ~2s each = ~20min max)
- `|| true` on cp commands prevents failure if no packets generated yet
- Only commits if there are actual changes (git diff --cached --quiet check)
- permissions: contents: write required for git push
  </action>
  <verify>
Verify YAML syntax: `python -c "import yaml; yaml.safe_load(open('.github/workflows/generate-packets.yml'))"` -- no parse errors
  </verify>
  <done>GitHub Actions workflow created with weekly cron + manual dispatch, packet generation, index build, and auto-commit to docs/web/.</done>
</task>

<task type="auto">
  <name>Task 4: Create tests/test_web_index.py</name>
  <files>tests/test_web_index.py</files>
  <action>
**Create `tests/test_web_index.py`** with tests for build_index():

```python
"""Tests for scripts/build_web_index.py -- web index builder."""

import json
from pathlib import Path

import pytest


def _write_json(path: Path, data) -> None:
    """Write JSON data to a file."""
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f)


def _mock_registry(count: int = 3) -> list[dict]:
    """Create a mock Tribal registry with count entries."""
    return [
        {
            "epa_id": f"epa_{i:03d}",
            "name": f"Test Tribe {i}",
            "states": ["WA"] if i % 2 == 0 else ["OR", "WA"],
            "ecoregion": "Pacific Northwest",
        }
        for i in range(1, count + 1)
    ]


class TestBuildIndex:
    """Tests for build_index() function."""

    def test_produces_valid_json(self, tmp_path):
        """build_index() produces valid JSON with required schema fields."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, _mock_registry())
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        assert "generated_at" in result
        assert "packet_count" in result
        assert "total_tribes" in result
        assert "tribes" in result
        assert isinstance(result["tribes"], list)

        # Verify file was written
        assert output_path.exists()
        with open(output_path, "r", encoding="utf-8") as f:
            written = json.load(f)
        assert written == result

    def test_all_registry_tribes_included(self, tmp_path):
        """All Tribes from registry appear in output."""
        from scripts.build_web_index import build_index

        registry = _mock_registry(5)
        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, registry)
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        assert result["total_tribes"] == 5
        names = {t["name"] for t in result["tribes"]}
        for tribe in registry:
            assert tribe["name"] in names

    def test_has_packet_true_when_docx_exists(self, tmp_path):
        """Tribes with DOCX files have has_packet=True."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, _mock_registry(3))
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        # Create a DOCX file for epa_001
        (packets_dir / "epa_001.docx").write_bytes(b"PK mock docx content here")
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        tribe_map = {t["id"]: t for t in result["tribes"]}
        assert tribe_map["epa_001"]["has_packet"] is True
        assert tribe_map["epa_002"]["has_packet"] is False
        assert tribe_map["epa_003"]["has_packet"] is False
        assert result["packet_count"] == 1

    def test_has_packet_false_when_no_docx(self, tmp_path):
        """Tribes without DOCX files have has_packet=False."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, _mock_registry(2))
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        for tribe in result["tribes"]:
            assert tribe["has_packet"] is False
        assert result["packet_count"] == 0

    def test_file_size_kb_accurate(self, tmp_path):
        """file_size_kb reflects actual DOCX file size."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, _mock_registry(1))
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        # Create a known-size file (2048 bytes = 2.0 KB)
        content = b"X" * 2048
        (packets_dir / "epa_001.docx").write_bytes(content)
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        tribe = result["tribes"][0]
        assert tribe["file_size_kb"] == 2.0

    def test_empty_packets_dir_does_not_exist(self, tmp_path):
        """build_index() handles missing packets directory gracefully."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, _mock_registry(2))
        packets_dir = tmp_path / "nonexistent_packets"
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        assert result["packet_count"] == 0
        assert result["total_tribes"] == 2

    def test_registry_dict_format(self, tmp_path):
        """build_index() handles registry wrapped in {tribes: [...]} format."""
        from scripts.build_web_index import build_index

        registry_path = tmp_path / "registry.json"
        _write_json(registry_path, {"tribes": _mock_registry(3)})
        packets_dir = tmp_path / "packets"
        packets_dir.mkdir()
        output_path = tmp_path / "tribes.json"

        result = build_index(registry_path, packets_dir, output_path)

        assert result["total_tribes"] == 3
```

**Critical notes:**
- Import build_index inside test functions (not at module level) to avoid import errors if scripts/ is not on sys.path during collection
- Use tmp_path for all file I/O (no writes to real project dirs)
- Mock registry matches the schema from data/tribal_registry.json (epa_id, name, states, ecoregion)
- Tests cover: valid JSON output, all Tribes included, has_packet true/false, file_size_kb accuracy, missing dir, dict-format registry
  </action>
  <verify>
Run: `python -m pytest tests/test_web_index.py -v --tb=short` -- all tests pass
Run: `python -m pytest tests/ --tb=short` -- full suite passes (214+ existing + new tests)
  </verify>
  <done>7 tests covering build_index() correctness: JSON validity, Tribe inclusion, has_packet detection, file size accuracy, missing dir handling, dict-format registry.</done>
</task>

<task type="auto">
  <name>Task 5: Document SquareSpace embed code</name>
  <files>docs/web/index.html</files>
  <action>
**Add SquareSpace embed documentation** as an HTML comment block at the bottom of docs/web/index.html (before closing body tag):

```html
<!--
  SquareSpace Embed Instructions
  ==============================
  To embed this widget in a SquareSpace page:

  1. Open your SquareSpace page editor
  2. Add a "Code" block (or "Embed" block)
  3. Paste the following HTML:

  <div style="width:100%;max-width:800px;margin:0 auto;">
    <iframe
      src="https://atniclimate.github.io/TCR-policy-scanner/"
      width="100%" height="700" frameborder="0"
      style="border:1px solid #e0e0e0;border-radius:8px;"
      title="TCR Policy Scanner - Tribal Advocacy Packet Search"
      loading="lazy">
    </iframe>
  </div>

  Notes:
  - The iframe title attribute is required for WCAG 2.1 AA accessibility
  - loading="lazy" defers loading until the iframe is near the viewport
  - Adjust height as needed (700px fits the widget comfortably)
  - The max-width:800px keeps the widget centered and readable on wide screens
-->
```

This is already included as part of Task 1's index.html creation, but verify it is present.
  </action>
  <verify>
Verify embed code is present: grep for "SquareSpace" in docs/web/index.html
  </verify>
  <done>SquareSpace iframe embed code documented in index.html HTML comment with accessibility notes.</done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_web_index.py -v` -- all 7 tests pass
2. `python scripts/build_web_index.py --help` -- CLI help displays (or import check)
3. `python -c "import yaml; yaml.safe_load(open('.github/workflows/generate-packets.yml'))"` -- valid YAML
4. `python -m pytest tests/ --tb=short` -- full suite passes (214+ existing + new tests)
5. Verify docs/web/index.html contains "SquareSpace" embed comment
6. Verify total widget bundle <15KB (excluding data/ and tribes/)
</verification>

<success_criteria>
- docs/web/index.html is a self-contained search page with WCAG 2.1 AA accessibility
- Awesomplete vendored locally (no CDN dependency)
- Info card shows Tribe name, states, ecoregion on selection
- Download link works for Tribes with has_packet=true
- Mobile-responsive layout (stacks on <600px)
- scripts/build_web_index.py generates valid tribes.json from registry + packets dir
- GitHub Actions workflow runs weekly + manual, generates packets, builds index, commits
- SquareSpace iframe embed code documented
- All 214+ existing tests still pass
- Widget bundle <15KB (excluding data/tribes.json and DOCX files)
</success_criteria>

<output>
After completion, create `.planning/phases/08-assembly-polish/08-05-SUMMARY.md`
</output>
