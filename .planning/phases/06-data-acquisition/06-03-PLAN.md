---
phase: 06-data-acquisition
plan: 03
type: execute
wave: 2
depends_on: ["06-01", "06-02"]
files_modified:
  - src/packets/orchestrator.py
  - src/packets/context.py
  - config/scanner_config.json
  - tests/test_packets.py
autonomous: true

must_haves:
  truths:
    - "PacketOrchestrator loads award cache and hazard profile for each Tribe during context building"
    - "TribePacketContext.awards field populated from award_cache JSON"
    - "TribePacketContext.hazard_profile field populated from hazard_profiles JSON"
    - "CLI --prep-packets --tribe displays award summary and top hazards alongside existing identity/delegation"
    - "All 592 Tribes can have context built with awards + hazards (even if empty)"
    - "Tests cover award matching logic, hazard profile building, and orchestrator integration"
  artifacts:
    - path: "src/packets/orchestrator.py"
      provides: "Updated orchestrator loading awards + hazards into context"
      contains: "award_cache"
    - path: "src/packets/context.py"
      provides: "TribePacketContext with populated awards and hazard_profile fields"
      contains: "hazard_profile"
    - path: "config/scanner_config.json"
      provides: "Config paths for award cache, hazard profiles, alias table, NRI, USFS"
      contains: "award_cache"
    - path: "tests/test_packets.py"
      provides: "Tests for awards, hazards, and updated orchestrator"
      contains: "test_award"
  key_links:
    - from: "src/packets/orchestrator.py"
      to: "data/award_cache/"
      via: "JSON file load per tribe_id"
      pattern: "award_cache.*json"
    - from: "src/packets/orchestrator.py"
      to: "data/hazard_profiles/"
      via: "JSON file load per tribe_id"
      pattern: "hazard_profiles.*json"
    - from: "tests/test_packets.py"
      to: "src/packets/awards.py"
      via: "Test imports and unit tests"
      pattern: "TribalAwardMatcher"
    - from: "tests/test_packets.py"
      to: "src/packets/hazards.py"
      via: "Test imports and unit tests"
      pattern: "HazardProfileBuilder"
---

<objective>
Wire award and hazard data into the PacketOrchestrator pipeline and build the test suite for all Phase 6 modules.

Purpose: Complete the data acquisition pipeline so that `--prep-packets --tribe <name>` displays a Tribe's award history and hazard profile alongside identity and delegation. Ensure all Phase 6 code is tested.
Output: Updated orchestrator, config, context display, and comprehensive test suite.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-data-acquisition/06-RESEARCH.md
@.planning/phases/06-data-acquisition/06-CONTEXT.md
@.planning/phases/06-data-acquisition/06-01-SUMMARY.md
@.planning/phases/06-data-acquisition/06-02-SUMMARY.md

Key source files:
@src/packets/orchestrator.py -- Current orchestrator to update
@src/packets/context.py -- TribePacketContext with awards/hazard_profile stub fields
@src/packets/awards.py -- TribalAwardMatcher (from 06-01)
@src/packets/hazards.py -- HazardProfileBuilder (from 06-02)
@config/scanner_config.json -- Config to update with new paths
@tests/test_packets.py -- Existing 31 tests to extend
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update orchestrator and config to load award + hazard data into context</name>
  <files>
    src/packets/orchestrator.py
    config/scanner_config.json
  </files>
  <action>
**Update `config/scanner_config.json`:**

Add these paths to the existing `"packets"` section (which already has tribal_registry, congressional_cache, ecoregion, output_dir):

```json
"awards": {
    "alias_path": "data/tribal_aliases.json",
    "cache_dir": "data/award_cache",
    "fuzzy_threshold": 85
},
"hazards": {
    "nri_dir": "data/nri",
    "usfs_dir": "data/usfs",
    "cache_dir": "data/hazard_profiles",
    "crosswalk_path": "data/aiannh_tribe_crosswalk.json"
}
```

Do NOT modify any existing config sections. Only add to the `packets` object.

**Update `src/packets/orchestrator.py`:**

Modify `_build_context()` to load cached award and hazard data:

1. Add imports at top: `import json` and `from pathlib import Path`

2. In `__init__()`, read cache directory paths from config:
   ```python
   packets_cfg = config.get("packets", {})
   self.award_cache_dir = Path(packets_cfg.get("awards", {}).get("cache_dir", "data/award_cache"))
   self.hazard_cache_dir = Path(packets_cfg.get("hazards", {}).get("cache_dir", "data/hazard_profiles"))
   ```

3. Add helper method `_load_tribe_cache(self, cache_dir: Path, tribe_id: str) -> dict`:
   ```python
   def _load_tribe_cache(self, cache_dir: Path, tribe_id: str) -> dict:
       """Load a per-Tribe JSON cache file. Returns empty dict if not found."""
       cache_file = cache_dir / f"{tribe_id}.json"
       if not cache_file.exists():
           return {}
       try:
           with open(cache_file, "r", encoding="utf-8") as f:
               return json.load(f)
       except (json.JSONDecodeError, OSError) as exc:
           logger.warning("Failed to load cache %s: %s", cache_file, exc)
           return {}
   ```

4. In `_build_context()`, after congressional delegation lookup, add:
   ```python
   # Award data (Phase 6)
   award_data = self._load_tribe_cache(self.award_cache_dir, tribe_id)
   awards = award_data.get("awards", [])

   # Hazard profile (Phase 6)
   hazard_data = self._load_tribe_cache(self.hazard_cache_dir, tribe_id)
   hazard_profile = hazard_data.get("sources", {})
   ```

5. Pass `awards=awards` and `hazard_profile=hazard_profile` to the TribePacketContext constructor. The context dataclass already has these fields as stubs from Phase 5.

6. Update `_display_tribe_info()` to show award and hazard summaries after the congressional delegation section:

   **Awards section:**
   ```
   Award History:
     Total Obligation: $X,XXX,XXX across N awards
     Programs: BIA TCR ($X), FEMA BRIC ($Y), ...
   ```
   Or for zero-award Tribes:
   ```
   Award History:
     No federal climate resilience awards in tracked programs.
     First-time applicant opportunity.
   ```

   **Hazard section:**
   ```
   Climate Hazard Profile:
     Overall Risk: [rating] (score: XX.X)
     Social Vulnerability: [rating] (score: XX.X)
     Top Hazards:
       1. Wildfire (score: XX.X, EAL: $X,XXX)
       2. Drought (score: XX.X, EAL: $X,XXX)
       3. Hurricane (score: XX.X, EAL: $X,XXX)
     Wildfire Risk (USFS): [rating/metric]
   ```
   Or if no hazard data:
   ```
   Climate Hazard Profile:
     No hazard profile data available.
   ```

IMPORTANT: The award and hazard cache loading is read-only (loads JSON files). It does NOT call APIs or run the award matcher / hazard builder. Those are separate data-generation steps. The orchestrator just reads pre-cached results.
  </action>
  <verify>
    - `python -c "from src.packets.orchestrator import PacketOrchestrator; print('Import OK')"` confirms updated orchestrator imports
    - `python -c "import json; c=json.load(open('config/scanner_config.json','r',encoding='utf-8')); assert 'awards' in c['packets']; assert 'hazards' in c['packets']; print('Config OK')"` confirms config updated
    - Existing tests still pass: `pytest tests/ -v`
  </verify>
  <done>
    - PacketOrchestrator loads award cache + hazard profile per Tribe
    - _display_tribe_info() shows award summary and top hazards
    - Config has award and hazard paths
    - Cache loading is read-only with graceful missing-file handling
    - No regressions in existing tests
  </done>
</task>

<task type="auto">
  <name>Task 2: Build comprehensive test suite for Phase 6 modules</name>
  <files>
    tests/test_packets.py
  </files>
  <action>
**Extend `tests/test_packets.py`:**

Add three new test classes covering Phase 6 modules. All tests use `tmp_path` fixtures with mock data (no real API calls, no real data files). Follow the same patterns as existing test classes in this file.

**Class `TestTribalAwardMatcher`:** (8-10 tests for AWARD-01 + AWARD-02)

1. `test_alias_table_load` -- Create a mock alias JSON file, verify TribalAwardMatcher loads it correctly
2. `test_match_tier1_exact_alias` -- Verify exact alias table match returns correct Tribe dict
3. `test_match_tier2_fuzzy_token_sort` -- Verify fuzzy matching with score >= 85 returns correct Tribe
4. `test_match_tier2_below_threshold` -- Verify score < 85 returns None (false negative, not false positive)
5. `test_match_state_overlap_rejection` -- Verify state mismatch causes rejection even with high fuzzy score. Example: "Choctaw Nation" with state="MS" should NOT match "Choctaw Nation of Oklahoma" (state="OK")
6. `test_match_state_overlap_pass` -- Verify state match allows the match through
7. `test_match_no_match_returns_none` -- Verify completely unrecognizable name returns None
8. `test_match_all_awards_grouping` -- Verify awards are correctly grouped by tribe_id after matching
9. `test_write_cache_zero_awards` -- Verify zero-award Tribes get cache file with no_awards_context field
10. `test_write_cache_numeric_amounts` -- Verify award amounts are stored as float, not string

Create mock data fixtures:
- Mini registry with 3-5 Tribes (different states, some with alternate names)
- Mini alias table mapping known variants
- Mock USASpending results (a few awards with known Recipient Names)

**Class `TestHazardProfileBuilder`:** (6-8 tests for HAZ-01 + HAZ-02)

1. `test_nri_hazard_codes_count` -- Verify NRI_HAZARD_CODES has exactly 18 entries
2. `test_safe_float_conversion` -- Verify _safe_float handles "", None, "N/A", "12.5", and integer inputs
3. `test_nri_county_parsing` -- Create a mock NRI CSV (3 columns minimum: STCOFIPS, RISK_SCORE, WFIR_RISKS), verify parsing extracts correct values
4. `test_tribe_profile_aggregation` -- Verify that multi-county Tribes get max risk scores across counties
5. `test_top_hazards_ranking` -- Verify top 3 hazards are ordered by risk score descending
6. `test_empty_profile_for_unmatched` -- Verify unmatched Tribes get a profile with zero/null values (not a crash)
7. `test_cache_file_encoding` -- Verify cache file is written with UTF-8 encoding (write a Tribe name with special characters)
8. `test_build_profiles_creates_directory` -- Verify cache directory is created if missing

Create mock data fixtures:
- Mini NRI CSV file (tmp_path) with 3-4 county rows and a few hazard columns
- Mini AIANNH crosswalk mapping 2 Tribes to counties
- Mini registry with 3 Tribes

**Class `TestOrchestratorPhase6Integration`:** (4-5 tests)

1. `test_context_includes_awards` -- Create mock award cache JSON, verify _build_context() populates context.awards
2. `test_context_includes_hazard_profile` -- Create mock hazard cache JSON, verify _build_context() populates context.hazard_profile
3. `test_context_missing_cache_files` -- Verify _build_context() works when no cache files exist (awards=[], hazard_profile={})
4. `test_display_award_summary` -- Verify _display_tribe_info() outputs award total when awards present (capture stdout)
5. `test_display_hazard_summary` -- Verify _display_tribe_info() outputs top hazards when hazard profile present

The existing test classes (TestEcoregionMapper, TestTribalRegistry, TestCongressionalMapper, TestTribePacketContext, TestPacketOrchestrator) must remain unchanged and still pass.

**Test count target:** 18-23 new tests, bringing total from 83 to ~101-106.
  </action>
  <verify>
    - `pytest tests/test_packets.py -v` passes ALL tests (existing + new)
    - `pytest tests/ -v` passes ALL tests across entire project
    - `pytest tests/test_packets.py -v -k "TestTribalAwardMatcher"` runs 8-10 award tests
    - `pytest tests/test_packets.py -v -k "TestHazardProfileBuilder"` runs 6-8 hazard tests
    - `pytest tests/test_packets.py -v -k "TestOrchestratorPhase6"` runs 4-5 integration tests
  </verify>
  <done>
    - TestTribalAwardMatcher: 8-10 tests covering alias lookup, fuzzy matching, state validation, cache writing
    - TestHazardProfileBuilder: 6-8 tests covering NRI parsing, aggregation, top hazards ranking
    - TestOrchestratorPhase6Integration: 4-5 tests covering context loading and display
    - All existing 83 tests still pass
    - Total test count: 101+ tests
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/ -v` passes ALL tests (existing + new Phase 6 tests)
2. `python -m src.main --prep-packets --tribe "Navajo Nation"` displays identity + delegation + awards + hazards
3. Config has award and hazard paths in packets section
4. PacketOrchestrator gracefully handles missing cache files
5. Tests cover: alias matching, fuzzy matching, state validation, cache writing, hazard aggregation, orchestrator integration
</verification>

<success_criteria>
- Orchestrator loads award + hazard cache data into TribePacketContext
- CLI displays award summary and hazard profile alongside existing output
- Config updated with award/hazard paths
- 18+ new tests covering all Phase 6 modules
- All tests pass (existing + new)
- Graceful degradation when cache files missing
</success_criteria>

<output>
After completion, create `.planning/phases/06-data-acquisition/06-03-SUMMARY.md`
</output>
