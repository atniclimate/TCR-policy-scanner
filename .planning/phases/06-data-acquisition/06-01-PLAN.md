---
phase: 06-data-acquisition
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/packets/awards.py
  - data/tribal_aliases.json
  - src/scrapers/usaspending.py
autonomous: true

must_haves:
  truths:
    - "Batch query fetches ALL Tribal awards for each of the 12 tracked CFDAs with full pagination"
    - "Curated alias table maps known USASpending name variants to tribe_id"
    - "Fuzzy matching uses token_sort_ratio >= 85 (NOT WRatio) with state-overlap validation"
    - "Every Tribe gets a cache file -- zero-award Tribes get no_awards_context advocacy framing"
    - "Award amounts are numeric floats, not formatted strings"
    - "False positives are prevented by state-overlap validation and strict threshold"
  artifacts:
    - path: "src/packets/awards.py"
      provides: "TribalAwardMatcher class with batch fetch, two-tier matching, and cache writing"
      exports: ["TribalAwardMatcher"]
    - path: "data/tribal_aliases.json"
      provides: "Curated alias table mapping USASpending recipient names to tribe_ids"
      contains: "aliases"
    - path: "src/scrapers/usaspending.py"
      provides: "Modified scraper with fetch_tribal_awards_for_cfda batch method"
      contains: "fetch_tribal_awards"
  key_links:
    - from: "src/packets/awards.py"
      to: "src/scrapers/usaspending.py"
      via: "USASpendingScraper.fetch_tribal_awards_for_cfda()"
      pattern: "fetch_tribal_awards"
    - from: "src/packets/awards.py"
      to: "data/tribal_aliases.json"
      via: "JSON load of alias table for Tier 1 matching"
      pattern: "tribal_aliases"
    - from: "src/packets/awards.py"
      to: "src/packets/registry.py"
      via: "TribalRegistry.get_all() and get_by_id() for matching candidates"
      pattern: "registry"
    - from: "src/packets/awards.py"
      to: "data/award_cache/"
      via: "Per-Tribe JSON cache file writes"
      pattern: "award_cache"
---

<objective>
Build the Tribal award matching pipeline: batch USASpending queries (AWARD-01) and two-tier name matching with per-Tribe caching (AWARD-02).

Purpose: Enable any Tribe's federal funding track record to be retrieved from local cache without API calls, supporting Phase 7 economic impact multiplier calculations.
Output: TribalAwardMatcher class, curated alias table, modified USASpendingScraper, per-Tribe award cache files.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-data-acquisition/06-RESEARCH.md
@.planning/phases/06-data-acquisition/06-CONTEXT.md
@.planning/phases/05-foundation/05-04-SUMMARY.md

Key source files to understand:
@src/scrapers/usaspending.py -- Existing scraper to modify (add batch Tribal query method)
@src/scrapers/base.py -- BaseScraper with _request_with_retry, _create_session
@src/packets/registry.py -- TribalRegistry with get_all(), get_by_id(), resolve()
@src/packets/context.py -- TribePacketContext (has awards stub field)
@data/tribal_registry.json -- 592 Tribes with tribe_id, name, states, alternate_names
@data/program_inventory.json -- 11 programs, 12 unique CFDAs (some null, fema_bric has array)
@config/scanner_config.json -- Has usaspending base_url config
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add batch Tribal query method to USASpendingScraper and build curated alias table</name>
  <files>
    src/scrapers/usaspending.py
    data/tribal_aliases.json
  </files>
  <action>
**Modify `src/scrapers/usaspending.py`:**

Add a new async method `fetch_tribal_awards_for_cfda(self, session, cfda)` to USASpendingScraper that:

1. POSTs to `{base_url}/search/spending_by_award/` with:
   - `filters.award_type_codes`: `["02", "03", "04", "05"]` (grants)
   - `filters.program_numbers`: `[cfda]`
   - `filters.recipient_type_names`: `["indian_native_american_tribal_government"]` (exact value -- verified from USASpending source code)
   - NO `time_period` filter (fetch all historical awards, not just FY26)
   - `fields`: `["Award ID", "Recipient Name", "Award Amount", "Total Obligation", "Start Date", "End Date", "Description", "CFDA Number", "Awarding Agency", "recipient_id"]`
   - `subawards`: False
   - `limit`: 100 (practical max for pagination)
   - `sort`: "Award Amount", `order`: "desc"

2. Paginates using `page_metadata.hasNext` -- starts at page 1, increments until hasNext is false or results is empty. Uses `_request_with_retry` for each page.

3. Returns `list[dict]` of raw award results (not normalized through _normalize -- the awards module needs raw fields).

Add a second async method `fetch_all_tribal_awards(self)` that:
1. Reads CFDAs from the existing `CFDA_TO_PROGRAM` dict keys (12 entries)
2. Iterates each CFDA, calls `fetch_tribal_awards_for_cfda` for each
3. Returns `dict[str, list[dict]]` keyed by CFDA number
4. Sleeps 0.5s between CFDAs for rate limiting courtesy
5. Catches exceptions per-CFDA (logs error, continues with empty list for that CFDA)

IMPORTANT: Do NOT modify the existing `scan()` or `_fetch_obligations()` methods. These serve the v1.0 pipeline and must remain unchanged. The new methods are additional.

**Create `data/tribal_aliases.json`:**

Build a curated alias table with this structure:
```json
{
  "_metadata": {
    "description": "Curated mapping: USASpending recipient name (lowercased, stripped) -> tribe_id",
    "version": "1.0",
    "last_updated": "2026-02-10"
  },
  "aliases": {
    "navajo nation": "epa_100000306",
    "the navajo nation": "epa_100000306",
    ...
  }
}
```

Bootstrap the alias table by:
1. Loading `data/tribal_registry.json`
2. For each Tribe, add the lowercased official name -> tribe_id
3. For each Tribe, add all lowercased alternate_names -> tribe_id
4. Add common USASpending naming patterns:
   - "THE {name}" variants for large Tribes
   - All-caps variants of official names
   - Known abbreviation patterns (e.g., "muscogee (creek) nation" and "muscogee creek nation")

Write a bootstrap script inline in the alias file creation -- or create a small script at `scripts/build_tribal_aliases.py` that reads the registry and generates the file. The executor can run it once. The key is having a comprehensive initial alias table that covers official names + alternate names + common patterns.

The alias table should have 600+ entries (592 official names + all alternate_names + common variants).
  </action>
  <verify>
    - `python -c "import json; d=json.load(open('data/tribal_aliases.json','r',encoding='utf-8')); print(f'Aliases: {len(d[\"aliases\"])} entries'); assert len(d['aliases']) > 500"` confirms alias table has sufficient entries
    - `python -c "from src.scrapers.usaspending import USASpendingScraper; print('Import OK')"` confirms modified scraper still imports
    - Existing tests still pass: `pytest tests/ -v`
  </verify>
  <done>
    - USASpendingScraper has `fetch_tribal_awards_for_cfda()` and `fetch_all_tribal_awards()` methods
    - Existing `scan()` and `_fetch_obligations()` methods unchanged
    - `data/tribal_aliases.json` exists with 500+ alias entries bootstrapped from registry
    - All existing tests pass (no regressions)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create TribalAwardMatcher with two-tier matching and per-Tribe cache</name>
  <files>
    src/packets/awards.py
  </files>
  <action>
**Create `src/packets/awards.py`:**

Build a `TribalAwardMatcher` class that:

**Constructor `__init__(self, config: dict)`:**
- Loads the TribalRegistry (from config, same pattern as other packet modules)
- Loads the alias table from `data/tribal_aliases.json` (path configurable via config.packets.awards.alias_path, default "data/tribal_aliases.json")
- Sets cache directory from config (default "data/award_cache")
- Builds a reverse lookup: tribe name (lowercased) -> tribe dict for all 592 Tribes

**Method `match_recipient_to_tribe(self, recipient_name: str, recipient_state: str | None = None) -> dict | None`:**

Two-tier matching -- returns matched Tribe dict or None (skip):

Tier 1: Curated alias table lookup
- Normalize: `recipient_name.strip().lower()`
- Look up in `self.alias_table` dict -> tribe_id -> registry.get_by_id(tribe_id)
- If found, return the Tribe dict immediately (O(1) lookup)

Tier 2: rapidfuzz token_sort_ratio fallback
- Import: `from rapidfuzz import fuzz`
- For each Tribe in registry.get_all():
  - Check official name + alternate_names
  - Score: `fuzz.token_sort_ratio(normalized_recipient, name.lower())`
  - Threshold: >= 85 (configurable but default 85)
  - Track best match (highest score above threshold)
- State-overlap validation (critical anti-false-positive guard):
  - If `recipient_state` is provided AND the candidate Tribe has states:
    - recipient_state must appear in the Tribe's states list
    - If state mismatch: SKIP this candidate (continue to next)
  - If recipient_state is None or Tribe has no states: skip state check (permissive)
- Return best match Tribe dict, or None if nothing >= 85 with valid state

IMPORTANT: Use `fuzz.token_sort_ratio`, NOT `fuzz.WRatio`. WRatio is for the interactive registry resolve() (Phase 5). Award matching needs the stricter, word-order-invariant token_sort_ratio as specified in AWARD-02.

**Method `match_all_awards(self, awards_by_cfda: dict[str, list[dict]]) -> dict[str, list[dict]]`:**

Takes the output of `fetch_all_tribal_awards()` (dict keyed by CFDA) and returns a dict keyed by tribe_id with matched awards:

1. For each CFDA, for each award in the list:
   - Extract `recipient_name = award.get("Recipient Name", "")`
   - Extract state from recipient_name if available (parse from trailing ", XX" pattern or use None)
   - Call `match_recipient_to_tribe(recipient_name, state)`
   - If matched: normalize award data and add to that Tribe's list:
     ```python
     {
         "award_id": award.get("Award ID", ""),
         "cfda": cfda,
         "program_id": CFDA_TO_PROGRAM.get(cfda, ""),
         "recipient_name_raw": award.get("Recipient Name", ""),
         "obligation": float(award.get("Total Obligation") or award.get("Award Amount") or 0),
         "start_date": award.get("Start Date", ""),
         "end_date": award.get("End Date", ""),
         "description": award.get("Description", ""),
         "awarding_agency": award.get("Awarding Agency", ""),
     }
     ```
   - If not matched: log as unmatched (DEBUG level) for future alias table refinement
2. Log summary: N total awards matched to M Tribes, K unmatched

CRITICAL: `obligation` must be `float`, not formatted string. Use `float(value or 0)` with try/except for safety.

**Method `write_cache(self, matched_awards: dict[str, list[dict]]) -> int`:**

Writes per-Tribe JSON cache files to `data/award_cache/{tribe_id}.json`:

1. Create cache directory if not exists
2. For ALL 592 Tribes (not just matched ones):
   - Get awards list (may be empty)
   - Build cache data:
     ```python
     {
         "tribe_id": tribe_id,
         "tribe_name": tribe["name"],
         "awards": awards,
         "total_obligation": sum(a["obligation"] for a in awards),
         "award_count": len(awards),
         "cfda_summary": {cfda: {"count": N, "total": $X} for each CFDA with awards},
     }
     ```
   - If no awards, add `"no_awards_context"` field:
     `"No federal climate resilience awards found in tracked programs. This represents a first-time applicant opportunity -- the Tribe can leverage this status to demonstrate unmet need in competitive grant applications."`
   - Write with `json.dump(data, f, indent=2, ensure_ascii=False)` and `encoding="utf-8"`
3. Return count of files written (should be 592)

**Method `run(self, scraper: USASpendingScraper) -> dict`:**

High-level orchestration method:
1. Call `scraper.fetch_all_tribal_awards()` (async -- this method must be called from async context, or use `asyncio.run()`)
2. Call `self.match_all_awards(result)`
3. Call `self.write_cache(matched)`
4. Return summary dict with stats (total_awards, matched_tribes, unmatched_count, cache_files_written)

Use logging throughout (logger = logging.getLogger("tcr_scanner.packets.awards")).
All file operations use `encoding="utf-8"`.
  </action>
  <verify>
    - `python -c "from src.packets.awards import TribalAwardMatcher; print('Import OK')"` confirms module imports
    - `python -c "from src.packets.awards import TribalAwardMatcher; m = TribalAwardMatcher({}); result = m.match_recipient_to_tribe('Navajo Nation'); print(f'Matched: {result[\"name\"] if result else None}')"` confirms matching works against registry
    - Existing tests still pass: `pytest tests/ -v`
  </verify>
  <done>
    - `src/packets/awards.py` exists with TribalAwardMatcher class
    - Two-tier matching: alias table (Tier 1) + token_sort_ratio >= 85 with state validation (Tier 2)
    - `match_all_awards()` processes batch results and returns per-tribe_id award lists
    - `write_cache()` writes 592 JSON files (one per Tribe) to data/award_cache/
    - Zero-award Tribes get no_awards_context field
    - All award amounts stored as float (not string)
    - All file I/O uses encoding="utf-8"
  </done>
</task>

</tasks>

<verification>
1. USASpendingScraper still passes existing tests (no regression)
2. `src/packets/awards.py` imports cleanly
3. Alias table has 500+ entries covering all official names and alternate names
4. TribalAwardMatcher.match_recipient_to_tribe() returns correct Tribe for known names
5. match_recipient_to_tribe() returns None for unrecognizable names (false negative, not false positive)
6. All existing 83 tests pass
</verification>

<success_criteria>
- TribalAwardMatcher class complete with batch fetch, two-tier matching, and per-Tribe cache writing
- Curated alias table bootstrapped from registry with 500+ entries
- USASpendingScraper has batch Tribal query methods (existing scan() unchanged)
- Award amounts stored as numeric floats
- Zero-award Tribes get advocacy-framed cache files
- No regressions in existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/06-data-acquisition/06-01-SUMMARY.md`
</output>
