---
phase: 20-flood-water-data
plan: 04
type: execute
wave: 2
depends_on: ["20-01"]
files_modified:
  - src/packets/flood_nfhl.py
  - tests/test_flood_nfhl.py
autonomous: true

must_haves:
  truths:
    - "NFIP Community Status Book data fetched per state from OpenFEMA"
    - "Community participation, CRS class, and effective map dates extracted"
    - "Tribal communities identified via tribal flag in API response"
    - "Flood zone distribution derived from NFIP claims data (ratedFloodZone field)"
    - "Map currency dates enable 'flood maps last updated YYYY' advocacy narrative"
    - "Communities mapped to Tribes via county FIPS crosswalk"
  artifacts:
    - path: "src/packets/flood_nfhl.py"
      provides: "NFHLBuilder following 9-step builder template"
      contains: "class NFHLBuilder"
    - path: "tests/test_flood_nfhl.py"
      provides: "Tests for NFHL community status fetch and map date extraction"
      contains: "test_aggregate_tribe_nfhl"
  key_links:
    - from: "src/packets/flood_nfhl.py"
      to: "src/packets/_flood_common.py"
      via: "fetch_openfema_paginated, normalize_county_fips, get_tribe_county_weights"
      pattern: "from src.packets._flood_common import"
    - from: "src/packets/flood_nfhl.py"
      to: "src/schemas/flood.py"
      via: "NFHLProfile, NFHLCommunityStatus, FloodSourceMetadata"
      pattern: "from src.schemas.flood import"
---

<objective>
Build the NFHL community status builder (FLOOD-03): fetch NFIP Community Status Book from OpenFEMA, extract participation status, CRS ratings, map effective dates, and supplement with flood zone distribution from NFIP claims data.

Purpose: Per 20-RESEARCH.md, the original NFHL WFS plan is replaced by the Community Status Book API (no 1000-feature limit). This provides NFIP participation status (critical -- many Tribal Nations are not NFIP participants), CRS discount ratings, and map currency dates. Outdated flood maps are a powerful advocacy tool per 20-CONTEXT.md.

Output: `src/packets/flood_nfhl.py` with NFHLBuilder class and `tests/test_flood_nfhl.py`.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-flood-water-data/20-CONTEXT.md
@.planning/phases/20-flood-water-data/20-RESEARCH.md

@src/packets/svi_builder.py -- 9-step builder template
@src/packets/_flood_common.py -- fetch_openfema_paginated, normalize_county_fips, get_tribe_county_weights (from Plan 01)
@src/schemas/flood.py -- NFHLProfile, NFHLCommunityStatus (from Plan 01)
@src/paths.py -- FLOOD_CACHE_DIR
@.planning/phases/20-flood-water-data/20-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement NFHLBuilder</name>
  <files>src/packets/flood_nfhl.py</files>
  <action>
    Create `src/packets/flood_nfhl.py` following the 9-step builder template.

    **Step 1: __init__(config: dict)**
    - Load crosswalk and area weights
    - Initialize state-to-communities cache and county-to-communities mapping

    **Step 2-3: Load crosswalk and area weights**

    **Step 4: fetch_community_status_by_state(state: str) -> list[dict]**
    - Endpoint: `NfipCommunityStatusBook` (v1, note: v1 not v2)
    - URL: `https://www.fema.gov/api/open/v1/NfipCommunityStatusBook`
    - Filter: `state eq '{state}'`
    - Note: 25,053 total communities. Fetching per-state is efficient (~500 per state avg).
    - Key fields: communityIdNumber, county, state, participatingInNFIP (or equivalent bool field), classRating (CRS 1-10), sfhaDiscount, nonSfhaDiscount, currentlyEffectiveMapDate, tribal (bool)
    - Cache by state to avoid re-fetching
    - Identify all unique states from the crosswalk county FIPS codes (derive state from first 2 digits)

    **Step 5: _map_communities_to_counties(communities: list[dict], state: str) -> dict[str, list[dict]]**
    - Map each community to its county FIPS using the county field in the response
    - The API response has a `county` field (name, not FIPS). Need to match county name to FIPS.
    - Strategy: Use the state FIPS (2-digit) + county name matching. The crosswalk already has county FIPS codes -- build a reverse lookup from FIPS to county name at init time.
    - Alternative: The `communityIdNumber` field (6-digit: SSCCCC format where SS=state, CCCC=community number) may encode county information. Examine field format at runtime.
    - Return dict: county_fips -> [community records for that county]

    **Step 6: _aggregate_tribe_nfhl(tribe_id) -> NFHLProfile**
    - Get county weights for Tribe
    - For each county: get communities from mapped data
    - Build NFHLCommunityStatus objects for each community
    - Determine any_participating: True if any community in Tribe's counties participates
    - Determine map dates: oldest_map_date and newest_map_date from currentlyEffectiveMapDate
    - Flood zone distribution: If NFIP claims data is available (from Plan 02 output), aggregate ratedFloodZone counts. Otherwise, leave as empty dict.
    - CRS class: best (lowest number) CRS class across communities
    - coverage_pct from crosswalk
    - If no communities found: data_gap = NO_RECORDS, gap_advocacy_action from MONITORING_GAP_ACTIONS["nfhl"]

    **Step 7: build_all_profiles() -> int**
    - Phase 1: Identify all unique states from crosswalk county FIPS
    - Phase 2: Fetch community status for all states
    - Phase 3: Map communities to counties
    - Phase 4: Aggregate to Tribes
    - Log progress

    **Step 8: Atomic write**
    - Write to FLOOD_CACHE_DIR / f"{tribe_id}_nfhl.json"

    **Step 9: Coverage report**
    - Tribes with community data vs without
    - NFIP participation rate across Tribal communities
    - Tribes with tribal-flagged communities
    - Map age statistics (oldest, newest, median effective date)
    - CRS participation rate

    IMPORTANT: The Community Status Book may use different field names than documented. Log all field names from first response for debugging. Handle field name variations gracefully.
  </action>
  <verify>
    Run: `python -c "from src.packets.flood_nfhl import NFHLBuilder; print('Import OK')"` -- succeeds.
  </verify>
  <done>
    NFHLBuilder fetches NFIP Community Status Book per state, maps communities to counties, extracts participation status, CRS ratings, and map effective dates. Identifies tribal communities. Handles county-name-to-FIPS matching.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write NFHL builder tests</name>
  <files>tests/test_flood_nfhl.py</files>
  <action>
    Create `tests/test_flood_nfhl.py` with comprehensive tests.

    **Test fixtures:**
    - `sample_community_data`: 5 community records with varying participation, CRS classes, map dates
    - `sample_tribal_community`: Community record with tribal=True flag
    - `sample_crosswalk_data`: Minimal crosswalk for testing

    **TestCommunityMapping:**
    - test_map_communities_to_counties_basic: 3 communities in 2 counties mapped correctly
    - test_map_communities_to_counties_no_match: Community with unknown county -> skipped with warning
    - test_map_communities_tribal_flag: Tribal community identified

    **TestNFHLAggregation:**
    - test_aggregate_basic: 2 communities in Tribe's county -> correct profile
    - test_aggregate_participation: any_participating True when at least one participates
    - test_aggregate_no_participation: any_participating False when none participate
    - test_aggregate_map_dates: Oldest and newest dates extracted correctly
    - test_aggregate_crs_best_class: Lowest CRS number selected
    - test_aggregate_no_communities: Zero communities -> NO_RECORDS gap
    - test_aggregate_coverage_pct: Correct weight fraction

    **TestNFHLBuilder (integration with mocks):**
    - test_builder_init: Constructor loads crosswalk
    - test_fetch_community_status_mocked: Mocked OpenFEMA returns community data
    - test_fetch_state_extraction: Correct states derived from county FIPS
    - test_build_all_profiles_mocked: Full loop -> JSON files in tmp_path
    - test_coverage_report_participation_rate: Report shows participation stats

    **TestNFHLValidation:**
    - test_nfhl_profile_validates: Builder output passes NFHLProfile schema
    - test_nfhl_community_validates: Community record passes schema
    - test_map_date_format: Dates in ISO format

    Use `unittest.mock.patch("requests.get")` for HTTP mocking.
  </action>
  <verify>
    Run: `python -m pytest tests/test_flood_nfhl.py -v` -- all tests pass.
    Run: `python -m pytest tests/ -x -q` -- all tests pass.
  </verify>
  <done>
    25+ tests cover community-to-county mapping, participation detection, map date extraction, CRS rating, tribal community identification, and Pydantic validation. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.packets.flood_nfhl import NFHLBuilder; print('Import OK')"` -- succeeds
2. `python -m pytest tests/test_flood_nfhl.py -v` -- all tests pass
3. `python -m pytest tests/ -x -q` -- all 1257+ tests pass
</verification>

<success_criteria>
- Community Status Book fetched per state (not WFS -- avoiding 1000-feature limit)
- NFIP participation status and CRS class ratings extracted
- Map effective dates enable "flood maps last updated" advocacy
- Tribal communities identified via API tribal flag
- Communities mapped to Tribes via county FIPS crosswalk
- 25+ tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/20-flood-water-data/20-04-SUMMARY.md`
</output>
