---
phase: 16-document-quality-assurance
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/validate_docx_structure.py
  - outputs/docx_review/design-aficionado_findings.json
  - outputs/docx_review/accuracy-agent_findings.json
  - outputs/docx_review/pipeline-surgeon_findings.json
  - outputs/docx_review/gatekeeper_findings.json
  - outputs/docx_review/gap-finder_findings.json
autonomous: true

must_haves:
  truths:
    - "Structural validation script checks all generated DOCX documents in under 60 seconds and reports per-document results for heading hierarchy, table population, page count, header presence, placeholder absence, font consistency, and image integrity"
    - "5 audit agents each produce a machine-readable findings JSON file with severity-classified defects (P0-P3) for their specific quality dimension"
    - "Design audit identifies style system integrity gaps, font/color issues, and contrast violations across all 4 doc types"
    - "Accuracy audit traces dollar amounts to source data, verifies Tribe names, checks audience differentiation, and flags air gap violations in renderer code"
    - "Pipeline audit traces every TribePacketContext field from population to consumption and verifies cache safety, calculation correctness, and error handling"
    - "Quality gate audit verifies priority hierarchy logic, air gap regex completeness, audience leakage detection, and MAX_PAGES enforcement"
    - "Test coverage gap analysis maps function-level coverage across all packet source files and identifies untested edge cases with risk-prioritized recommendations"
  artifacts:
    - path: "scripts/validate_docx_structure.py"
      provides: "DOCX structural validation across 992 documents"
      contains: "validate_document"
    - path: "outputs/docx_review/design-aficionado_findings.json"
      provides: "Design & layout audit findings"
      contains: "DESIGN-"
    - path: "outputs/docx_review/accuracy-agent_findings.json"
      provides: "Content accuracy audit findings"
      contains: "ACCURACY-"
    - path: "outputs/docx_review/pipeline-surgeon_findings.json"
      provides: "Pipeline integrity audit findings"
      contains: "PIPE-"
    - path: "outputs/docx_review/gatekeeper_findings.json"
      provides: "Quality gate enforcement audit findings"
      contains: "GATE-"
    - path: "outputs/docx_review/gap-finder_findings.json"
      provides: "Test coverage gap analysis findings"
      contains: "GAP-"
  key_links:
    - from: "scripts/validate_docx_structure.py"
      to: "outputs/ DOCX files"
      via: "python-docx Document traversal"
      pattern: "Document\\(str\\(docx_path\\)\\)"
    - from: "outputs/docx_review/*_findings.json"
      to: "16-02-PLAN.md fix wave"
      via: "findings JSON consumed by fix wave"
      pattern: "severity.*P[0-3]"
---

<objective>
Audit the entire 992-document corpus and all DOCX generation code across 5 quality dimensions using a structural validation script and 5 specialist agents operating in read-only mode.

Purpose: Wave 1 of the two-wave Phase 16 structure. This audit wave produces the complete defect inventory that Wave 2 (fix wave) will act on. No source code modifications happen in this plan -- it is purely diagnostic.

Output:
- `scripts/validate_docx_structure.py` -- reusable structural validation script (DOCX-01)
- 5 agent findings JSON files in `outputs/docx_review/` covering design (DOCX-02), accuracy (DOCX-03), pipeline integrity (DOCX-04), quality gates (DOCX-05), and test coverage gaps (DOCX-06)
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-document-quality-assurance/16-CONTEXT.md
@.planning/phases/16-document-quality-assurance/16-RESEARCH.md

# Agent definitions (read these to understand each agent's checklist and output format)
@.planning/design-aficionado.md
@.planning/accuracy-agent.md
@.planning/pipeline-surgeon.md
@.planning/gatekeeper.md
@.planning/gap-finder.md

# Source files under audit (read for agent work)
@src/packets/docx_styles.py
@src/packets/docx_template.py
@src/packets/docx_hotsheet.py
@src/packets/docx_sections.py
@src/packets/docx_regional_sections.py
@src/packets/orchestrator.py
@src/packets/context.py
@src/packets/economic.py
@src/packets/relevance.py
@src/packets/agent_review.py
@src/packets/quality_review.py
@src/packets/doc_types.py
@src/packets/docx_engine.py

# Test files (for Gap Finder)
@tests/test_docx_hotsheet.py
@tests/test_docx_integration.py
@tests/test_docx_styles.py
@tests/test_docx_template.py
@tests/test_packets.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build structural validation script and run it</name>
  <files>scripts/validate_docx_structure.py</files>
  <action>
Create `scripts/validate_docx_structure.py` that validates the structural integrity of all generated DOCX documents. The script must:

1. **Discovery**: Find all DOCX files in `outputs/packets/` (Doc A/B per Tribe) and `outputs/regional_packets/` (Doc C/D per region). Handle both directory structures.

2. **Per-document checks** (all checks run on a single Document object opened once):
   - **Heading hierarchy**: Verify no heading level gaps (e.g., H1 -> H3 without H2). Iterate `doc.paragraphs`, filter by style name starting with "Heading", extract level ints, check sequential validity.
   - **Table population**: Every `doc.tables` entry must have at least one non-empty cell. Flag empty tables with their index.
   - **Page count estimate**: Count page breaks in run XML (`w:br` with `w:type="page"`). Tribal docs expect 5-80 pages. Flag outliers.
   - **Tribe name in header**: Check `section.header.paragraphs` for non-empty text. Doc A/B should have Tribe name; Doc C/D should have region name.
   - **Placeholder absence**: Scan all paragraph text for TBD, [INSERT, PLACEHOLDER, data pending (case-insensitive). Flag any found.
   - **Font consistency**: Iterate all runs across paragraphs. Flag any `run.font.name` that is not None and not "Arial".
   - **Broken images**: Check `doc.inline_shapes` access doesn't throw. Count images.

3. **Aggregation**: Collect per-document results into a summary with:
   - Total documents checked
   - Pass/fail counts per check type
   - List of failing documents with specific failures
   - Elapsed time

4. **Performance**: Target ~60ms per document. Open each DOCX exactly once. Process sequentially (python-docx is not thread-safe). The full 992-document corpus must complete in under 60 seconds.

5. **Output**: Print human-readable summary to stdout. Write machine-readable JSON to `outputs/docx_review/structural_validation.json`.

6. **CLI**: Accept optional `--sample N` flag to validate a random sample of N documents (for quick checks). Default: validate all.

7. **Encoding**: Use `encoding="utf-8"` for all file writes.

8. **Run the script**: Execute `python scripts/validate_docx_structure.py` against whatever documents exist in the outputs directories. If no documents exist (data files not committed), run with `--sample 0` to verify the script loads without error, then document that full validation requires document generation first.

Key patterns from 16-RESEARCH.md:
- `from docx import Document` then `doc = Document(str(docx_path))`
- `para.style.name.startswith("Heading ")` for heading detection
- `run._r.xml` for page break detection (check `"w:br"` and `'w:type="page"'`)
- Use `pathlib.Path` for all paths, never string concatenation
- Use `json.dumps(results, indent=2, ensure_ascii=False)` for output
  </action>
  <verify>
- `python scripts/validate_docx_structure.py --help` runs without error
- If documents exist: script completes in under 60 seconds, outputs JSON to `outputs/docx_review/structural_validation.json`
- If no documents: script reports "0 documents found" gracefully
- `python -m pytest tests/ -v --tb=short` still passes (no regressions)
  </verify>
  <done>Structural validation script exists at scripts/validate_docx_structure.py, handles all 7 check types, respects 60-second budget, produces machine-readable JSON output</done>
</task>

<task type="auto">
  <name>Task 2: Execute 5 parallel audit agents and collect findings</name>
  <files>
outputs/docx_review/design-aficionado_findings.json
outputs/docx_review/accuracy-agent_findings.json
outputs/docx_review/pipeline-surgeon_findings.json
outputs/docx_review/gatekeeper_findings.json
outputs/docx_review/gap-finder_findings.json
  </files>
  <action>
Execute the 5 audit agents. Each agent reads its assigned source files (NOT generated documents -- they read the generation CODE) and produces a findings JSON file. Agents operate in READ-ONLY mode -- no source code modifications.

**Ensure `outputs/docx_review/` directory exists** before writing findings.

**For each agent, follow their agent definition file exactly:**

### Agent 1: Design Aficionado (DOCX-02)
Read: `src/packets/docx_styles.py`, `src/packets/docx_template.py`
Cross-reference: style names used in `docx_sections.py` and `docx_hotsheet.py`
Checklist: Color/contrast, font size hierarchy, style system integrity (orphans/phantoms), template pre-baking, table layout
Output: `outputs/docx_review/design-aficionado_findings.json` with findings array, style_inventory, contrast_audit
Severity mapping: P0=critical, P1=major, P2=moderate, P3=minor per 16-RESEARCH.md definitions

### Agent 2: Accuracy Agent (DOCX-03)
Read: `src/packets/docx_hotsheet.py`, `src/packets/docx_sections.py`, `src/packets/docx_regional_sections.py`
Reference: `src/packets/doc_types.py`, `src/packets/context.py`
Checklist: Data formatting (format_dollars usage, FY hardcoding, Tribe names), hazard/award data, edge cases (empty data), air gap compliance, audience differentiation, python-docx gotchas (OxmlElement reuse, page vs section breaks, paragraph.clear)
Output: `outputs/docx_review/accuracy-agent_findings.json` with findings array, air_gap_scan, audience_crosscheck
Critical by default: Dollar amounts outside format_dollars(), air gap violations, audience leakage, OxmlElement reuse

### Agent 3: Pipeline Surgeon (DOCX-04)
Read: `src/packets/orchestrator.py`, `src/packets/context.py`, `src/packets/economic.py`, `src/packets/relevance.py`
Checklist: TribePacketContext field completeness (trace every field source->consumption), cache/file loading safety (10MB limit, UTF-8, atomic reads), economic calculations (zero guards, BCR accuracy, rounding), relevance filtering (8-12 program range, deterministic ordering), error handling (graceful degradation for 592 Tribes), security (path traversal), concurrency (single-writer)
Output: `outputs/docx_review/pipeline-surgeon_findings.json` with findings array, context_field_trace, error_path_map
Critical by default: Path traversal, unguarded calculations, missing size checks on cache loads

### Agent 4: Gatekeeper (DOCX-05)
Read: `src/packets/agent_review.py`, `src/packets/quality_review.py`, `src/packets/doc_types.py`
Checklist: Agent priority hierarchy (accuracy>audience>political>design>copy), quality gate logic (3/5 minimum, failure handling), MAX_PAGES enforcement, doc type config completeness (all flags, no contradictions), air gap regex completeness (case variations, abbreviations), audience leakage detection (internal content in congressional docs), data structure serialization
Output: `outputs/docx_review/gatekeeper_findings.json` with findings array, air_gap_regex_audit, gate_scenario_analysis
Critical by default: Bypass paths, incomplete air gap regex, auto-pass on partial data

### Agent 5: Gap Finder (DOCX-06)
Read: All test files (`tests/test_docx_hotsheet.py`, `tests/test_docx_integration.py`, `tests/test_docx_styles.py`, `tests/test_docx_template.py`, `tests/test_packets.py`)
Cross-reference: All source files in `src/packets/` to build function-level coverage map
Checklist: Function-level coverage (every public function), edge case coverage (empty awards, empty hazards, zero economic, missing delegation, special chars), doc type coverage (all 4 types), regional coverage (Doc C/D renderers), fixture quality (realistic data), assertion depth (content checks vs no-crash-only)
Output: `outputs/docx_review/gap-finder_findings.json` with coverage_map, missing_tests array, fixture_assessment, assertion_depth_assessment, recommended_test_additions
Critical by default: Missing Doc B/D audience leakage tests, untested congressional doc renderers

**Severity definitions (from 16-RESEARCH.md):**
- P0 Critical: Document unusable or dangerous (wrong data, audience leakage, air gap violation, crash)
- P1 Major: Document misleading or incomplete (missing section, broken table, placeholder text)
- P2 Moderate: Correct but quality/polish issues (font inconsistency, style drift)
- P3 Minor: Cosmetic or pedantic (extra whitespace, orphan style)

**Each findings JSON must include:**
- `agent`: Agent name
- `timestamp`: ISO-8601
- `files_audited`: List of files read with LOC counts
- `findings`: Array with id, severity (P0/P1/P2/P3), category, file, line, description, fix_recommendation
- `summary`: Object with total, p0, p1, p2, p3 counts

**Important:** Read every line of every file in each agent's domain. No skimming. Follow the agent's checklist item by item. Use the exact output format specified in each agent definition file.
  </action>
  <verify>
- All 5 JSON files exist in `outputs/docx_review/`
- Each JSON file is valid JSON (parseable)
- Each JSON file contains the required fields: agent, timestamp, files_audited, findings, summary
- Each finding has: id, severity, category, file, line, description
- Summary counts match actual findings array counts
- No source files were modified (read-only audit)
- `python -m pytest tests/ -v --tb=short` still passes (no regressions)
  </verify>
  <done>5 agent findings JSON files exist in outputs/docx_review/, each containing severity-classified defects for their quality dimension, with complete coverage of all checklist items from the agent definition files</done>
</task>

</tasks>

<verification>
1. `scripts/validate_docx_structure.py` exists and runs without error
2. All 5 findings JSON files exist in `outputs/docx_review/` and are valid JSON
3. Each findings file has the standard schema (agent, timestamp, files_audited, findings[], summary{})
4. No source files in `src/` were modified (this is a read-only audit wave)
5. All existing tests still pass: `python -m pytest tests/ -v --tb=short`
6. Each agent covered every item on their checklist (cross-reference agent definition files)
7. Severity classifications follow the P0-P3 definitions from 16-RESEARCH.md
</verification>

<success_criteria>
- Structural validation script handles 7 check types and respects 60-second performance budget
- 5 agent findings files collectively cover all 6 DOCX requirements (DOCX-01 through DOCX-06)
- Every P0 and P1 finding has a concrete fix_recommendation that can be actioned in Wave 2
- The audit is purely diagnostic -- zero source code changes in this plan
</success_criteria>

<output>
After completion, create `.planning/phases/16-document-quality-assurance/16-01-SUMMARY.md`
</output>
