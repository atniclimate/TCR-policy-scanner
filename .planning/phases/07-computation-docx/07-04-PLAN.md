---
phase: 07-computation-docx
plan: 04
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - src/packets/docx_sections.py
  - src/packets/docx_engine.py
  - src/packets/orchestrator.py
  - config/scanner_config.json
  - tests/test_docx_integration.py
autonomous: true

must_haves:
  truths:
    - "Cover page renders with Tribe name, date, state/ecoregion info, and congress session"
    - "Appendix lists omitted programs with brief descriptions and why they were lower priority"
    - "DocxEngine.generate() orchestrates full document assembly: cover -> hot sheets -> appendix"
    - "PacketOrchestrator has a generate_packet() method that produces a .docx file per Tribe"
    - "scanner_config.json has packets.docx section with output_dir setting"
    - "A generated .docx opens correctly (verified by python-docx re-reading the file)"
    - "Full test suite passes: 106 existing + all new Phase 7 tests"
    - "Zero-award, zero-hazard Tribes generate valid packets with appropriate framing"
  artifacts:
    - path: "src/packets/docx_sections.py"
      provides: "render_cover_page, render_appendix, render_table_of_contents"
      min_lines: 100
    - path: "src/packets/docx_engine.py"
      provides: "DocxEngine.generate() fully implemented with section assembly"
      min_lines: 120
    - path: "src/packets/orchestrator.py"
      provides: "PacketOrchestrator.generate_packet() method"
      contains: "generate_packet"
    - path: "config/scanner_config.json"
      provides: "packets.docx configuration section"
      contains: "docx"
    - path: "tests/test_docx_integration.py"
      provides: "Integration tests for full document generation pipeline"
      min_lines: 150
  key_links:
    - from: "src/packets/docx_engine.py"
      to: "src/packets/docx_hotsheet.py"
      via: "DocxEngine.generate() calls HotSheetRenderer.render_all_hotsheets()"
      pattern: "render_all_hotsheets"
    - from: "src/packets/docx_engine.py"
      to: "src/packets/docx_sections.py"
      via: "DocxEngine.generate() calls render_cover_page() and render_appendix()"
      pattern: "render_cover_page"
    - from: "src/packets/orchestrator.py"
      to: "src/packets/docx_engine.py"
      via: "PacketOrchestrator.generate_packet() creates DocxEngine and calls generate()"
      pattern: "DocxEngine"
    - from: "src/packets/orchestrator.py"
      to: "src/packets/economic.py"
      via: "generate_packet() calls EconomicImpactCalculator.compute()"
      pattern: "EconomicImpactCalculator"
---

<objective>
Complete the DOCX generation pipeline: cover page, appendix, engine assembly, orchestrator integration, and config wiring -- making `generate_packet()` produce a full per-Tribe .docx file.

Purpose: This plan connects all Phase 7 modules into a working end-to-end pipeline. After this plan, PacketOrchestrator.generate_packet(tribe_name) produces a complete .docx file with cover page, Hot Sheets, and appendix.
Output: Completed docx_engine.py, new docx_sections.py, orchestrator integration, config update, and integration tests.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-computation-docx/07-RESEARCH.md
@.planning/phases/07-computation-docx/07-01-SUMMARY.md
@.planning/phases/07-computation-docx/07-02-SUMMARY.md
@.planning/phases/07-computation-docx/07-03-SUMMARY.md

@src/packets/context.py
@src/packets/orchestrator.py
@src/packets/economic.py
@src/packets/relevance.py
@src/packets/docx_styles.py
@src/packets/docx_engine.py
@src/packets/docx_hotsheet.py
@config/scanner_config.json
@data/graph_schema.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create docx_sections.py and complete docx_engine.py</name>
  <files>src/packets/docx_sections.py, src/packets/docx_engine.py</files>
  <action>
**Create `src/packets/docx_sections.py`** with:

**Function render_cover_page(document: Document, context: TribePacketContext, style_manager: StyleManager) -> None:**
- Add blank paragraph for top spacing
- Add title "FY26 Climate Resilience Program Priorities" in Heading 1 style
- Add subtitle with Tribe name in HS Title style (large, bold, primary_dark)
- Add metadata block:
  - "Prepared for the offices of:" followed by delegation summary (count of senators + representatives)
  - "State(s): {', '.join(context.states)}"
  - "Ecoregion(s): {', '.join(context.ecoregions)}"
  - "Congressional Session: {context.congress_session}"
  - "Generated: {context.generated_at[:10]}" (date portion only)
- Add "CONFIDENTIAL -- For Congressional Office Use Only" in HS Small style, centered
- Add page break after cover page

**Function render_table_of_contents(document: Document, programs: list[dict], style_manager: StyleManager) -> None:**
- Add heading "Program Hot Sheets" in Heading 2 style
- For each program: add numbered entry with program name and CI status badge inline
- Brief note: "This packet contains {len(programs)} program analyses tailored to {tribe_name}'s climate risk profile and geographic context."
- Add page break after TOC

**Function render_appendix(document: Document, omitted_programs: list[dict], style_manager: StyleManager) -> None:**
- Add heading "Appendix: Additional Programs" in Heading 2 style
- If no omitted programs: add "All tracked programs are included in this packet." and return
- Brief intro: "The following programs were assessed as lower priority for {tribe_name} based on hazard profile and geographic relevance. They may still be relevant for specific project needs."
- For each omitted program:
  - Program name (bold) + CI status inline
  - Description (from program["description"])
  - Access type and funding type
  - "Learn more: Contact your program specialist or visit {agency} for current application information."

**Then complete `src/packets/docx_engine.py`** -- replace the generate() stub:

**DocxEngine.generate(self, context: TribePacketContext, relevant_programs: list[dict], economic_summary: TribeEconomicSummary, structural_asks: list[dict], omitted_programs: list[dict] | None = None) -> Path:**

1. Create document and style manager via create_document()
2. Call render_cover_page(document, context, style_manager)
3. Call render_table_of_contents(document, relevant_programs, style_manager)
4. Create HotSheetRenderer(document, style_manager)
5. Build a lookup: economic_by_program = {imp.program_id: imp for imp in economic_summary.by_program}
6. Call renderer.render_all_hotsheets(context, relevant_programs, economic_summary, structural_asks)
7. If omitted_programs: call render_appendix(document, omitted_programs, style_manager)
8. Call save(document, context.tribe_id)
9. Return the output path

**Update imports in docx_engine.py:**
- Add: `from src.packets.docx_styles import StyleManager`
- Add: `from src.packets.docx_hotsheet import HotSheetRenderer`
- Add: `from src.packets.docx_sections import render_cover_page, render_table_of_contents, render_appendix`
- Add: `from src.packets.economic import TribeEconomicSummary`
- Add: `from src.packets.context import TribePacketContext`

**Critical notes:**
- Cover page does NOT include an image/map (that would require map generation infrastructure -- deferred to Phase 8)
- Use `encoding="utf-8"` on any text file I/O
- Use `datetime.now(timezone.utc)` for any timestamps
- Atomic save pattern already in DocxEngine.save() from Plan 07-02
- Do NOT add new Word sections (add_section()) for cover page -- use page breaks only. All Hot Sheets share the same header/footer.
  </action>
  <verify>
Run: `python -c "from src.packets.docx_sections import render_cover_page, render_appendix; from src.packets.docx_engine import DocxEngine"` -- imports work
  </verify>
  <done>DocxEngine.generate() fully implemented. Cover page, TOC, and appendix render correctly. Complete document assembly pipeline working.</done>
</task>

<task type="auto">
  <name>Task 2: Wire orchestrator, update config, and create integration tests</name>
  <files>src/packets/orchestrator.py, config/scanner_config.json, tests/test_docx_integration.py</files>
  <action>
**Update `src/packets/orchestrator.py`** -- add generate_packet() method:

Add imports at top:
```python
from src.packets.economic import EconomicImpactCalculator
from src.packets.relevance import ProgramRelevanceFilter
from src.packets.docx_engine import DocxEngine
```

Add to PacketOrchestrator.__init__():
```python
# Phase 7: DOCX generation components
self.economic_calculator = EconomicImpactCalculator()
self.relevance_filter = ProgramRelevanceFilter(self.programs)
```

Add new method:
```python
def generate_packet(self, tribe_name: str) -> Path | None:
    """Generate a complete DOCX advocacy packet for a single Tribe.

    Args:
        tribe_name: Tribe name or partial name to resolve.

    Returns:
        Path to generated .docx file, or None if Tribe not found.
    """
```

Implementation:
1. Resolve tribe via self.registry.resolve(tribe_name) -- handle None/list/dict same as run_single_tribe()
2. Build context via self._build_context(tribe)
3. Compute economic impact: `economic_summary = self.economic_calculator.compute(context.awards, context.districts, self.programs)`
4. Store in context: `context.economic_impact = economic_summary.to_dict() if hasattr(economic_summary, 'to_dict') else {}` (or use asdict)
5. Filter relevant programs: `relevant = self.relevance_filter.filter_for_tribe(context.hazard_profile, context.ecoregions, self.ecoregion)`
6. Get omitted: `omitted = self.relevance_filter.get_omitted_programs(relevant)`
7. Load structural asks from graph_schema.json: read from `data/graph_schema.json` (use config path if available, else default)
8. Create DocxEngine and generate: `engine = DocxEngine(self.config, self.programs); path = engine.generate(context, relevant, economic_summary, structural_asks, omitted)`
9. Return path

Also update run_single_tribe() to call generate_packet() after _display_tribe_info():
```python
# After displaying info, generate DOCX if configured
if self.config.get("packets", {}).get("docx", {}).get("enabled", True):
    try:
        path = self.generate_packet_from_context(context, tribe)
        print(f"\n  DOCX packet generated: {path}")
    except Exception as exc:
        logger.error("Failed to generate DOCX for %s: %s", tribe["name"], exc)
        print(f"\n  DOCX generation failed: {exc}")
```

Add helper `generate_packet_from_context(self, context, tribe)` that does steps 3-9 above (shared between generate_packet and run_single_tribe to avoid duplicate code).

**Load structural asks helper:**
```python
def _load_structural_asks(self) -> list[dict]:
    """Load structural asks from graph_schema.json."""
    graph_path = Path("data/graph_schema.json")
    if not graph_path.exists():
        return []
    try:
        with open(graph_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("structural_asks", [])
    except (json.JSONDecodeError, OSError) as exc:
        logger.warning("Failed to load graph schema: %s", exc)
        return []
```

**Update `config/scanner_config.json`** -- add docx section inside packets:
```json
"docx": {
    "enabled": true,
    "output_dir": "outputs/packets"
}
```
Add this inside the existing "packets" object, after "hazards". Do NOT change any other config values.

**Create `tests/test_docx_integration.py`** with end-to-end tests:

**Fixtures:**
- `full_phase7_config(tmp_path)`: Merge all sub-configs (registry, ecoregion, congress, awards, hazards) + docx config. Create mock data files for one Tribe (epa_001). Include mock graph_schema.json with structural_asks. Include mock program_inventory with at least 4 programs (2 critical, 2 high priority).

**Integration tests:**
- test_generate_packet_single_tribe: Generate a full .docx for a Tribe with awards and hazards. Verify file exists, file size > 0, and python-docx can re-read it (`Document(path)` succeeds).
- test_generate_packet_zero_awards_zero_hazards: Generate for a Tribe with no awards and no hazard data. Verify .docx created with "First-Time Applicant" content.
- test_generate_packet_returns_path: generate_packet() returns a Path object to the .docx file.
- test_generate_packet_invalid_tribe: generate_packet() returns None for nonexistent Tribe.
- test_docx_has_cover_page: Open generated .docx and verify first paragraphs contain Tribe name.
- test_docx_has_hotsheets: Open generated .docx and verify paragraphs contain program names from inventory.
- test_docx_has_appendix: Open generated .docx and verify appendix content present if programs were omitted.
- test_economic_summary_in_context: After generation, context.economic_impact is populated (not empty dict).
- test_config_docx_section: Verify config loading with docx section works.
- test_full_suite_no_regression: Run pytest on all test files, assert 106+ tests pass (this is a meta-test that runs the full suite).

**Critical notes for tests:**
- Create mock data files in tmp_path: tribal_registry.json, ecoregion_config.json, congressional_cache.json, award_cache/epa_001.json, hazard_profiles/epa_001.json, graph_schema.json (with structural_asks)
- Use `Document(str(output_path))` to re-read and verify .docx validity
- Each test creates its own PacketOrchestrator instance with tmp_path config
- Do NOT modify test_packets.py (keep existing 106 tests untouched)

Run full suite at the end: `python -m pytest tests/ -v --tb=short`
  </action>
  <verify>
Run: `python -m pytest tests/test_docx_integration.py -v --tb=short` -- all integration tests pass
Run: `python -m pytest tests/ --tb=short` -- full suite passes (must be >= 130 total tests, all passing)
  </verify>
  <done>PacketOrchestrator.generate_packet() produces a valid .docx per Tribe. Full test suite passes with all Phase 7 tests + 106 existing tests. Config updated with docx section.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.packets.orchestrator import PacketOrchestrator"` -- import still works with new methods
2. `python -c "from src.packets.docx_engine import DocxEngine"` -- fully implemented generate() method
3. `python -c "from src.packets.docx_sections import render_cover_page, render_appendix"` -- imports work
4. `python -m pytest tests/test_docx_integration.py -v` -- all integration tests pass
5. `python -m pytest tests/ --tb=short` -- full suite passes (106 existing + all new Phase 7 tests)
6. Verify `config/scanner_config.json` has `packets.docx.output_dir` key
7. Verify `outputs/packets/` directory is created on first generate call
</verification>

<success_criteria>
- PacketOrchestrator.generate_packet("Alpha Tribe") produces a .docx file in outputs/packets/
- Generated .docx re-opens in python-docx without errors (Document(path) succeeds)
- Cover page contains Tribe name, states, ecoregions, congress session
- Hot Sheets contain program names, CI badges, advocacy language, economic impact
- Appendix lists omitted programs with descriptions
- Zero-award, zero-hazard Tribes generate valid packets with appropriate framing
- scanner_config.json has packets.docx section
- Full test suite passes: 106 existing + all new Phase 7 tests (target >= 130 total)
</success_criteria>

<output>
After completion, create `.planning/phases/07-computation-docx/07-04-SUMMARY.md`
</output>
