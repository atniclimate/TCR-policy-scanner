---
phase: 07-computation-docx
plan: 03
type: execute
wave: 2
depends_on: ["07-01", "07-02"]
files_modified:
  - src/packets/docx_hotsheet.py
  - tests/test_docx_hotsheet.py
autonomous: true

must_haves:
  truths:
    - "Each Hot Sheet renders with fixed section order: status badge, program description, award history, hazard relevance, economic impact, advocacy language, key ask callout, structural asks, delegation info"
    - "Empty sections are omitted (hidden), not shown with N/A"
    - "CI status badge shows colored Unicode circle plus human-readable label"
    - "Award history renders as zebra-striped table for Tribes with awards, or First-Time Applicant Advantage framing for zero-award Tribes"
    - "Economic impact shows range with BEA methodology citation as footnote"
    - "Advocacy language comes from tightened_language field (with fallback to description + advocacy_lever when tightened_language is absent)"
    - "Key Ask callout renders as prominent 3-line block: ASK / WHY / IMPACT"
    - "Structural asks show which asks advance the current program with urgency and description"
    - "Committee-match flag appears when delegation member sits on relevant committee"
    - "Framing shifts by CI status: defensive (AT_RISK/FLAGGED), protective (UNCERTAIN/STABLE_BUT_VULNERABLE), growth (STABLE/SECURE)"
    - "Hot Sheets ordered by relevance score (highest-priority programs first)"
  artifacts:
    - path: "src/packets/docx_hotsheet.py"
      provides: "HotSheetRenderer with render_hotsheet() and render_all_hotsheets()"
      min_lines: 350
    - path: "tests/test_docx_hotsheet.py"
      provides: "Comprehensive tests for Hot Sheet rendering including all CI statuses and edge cases"
      min_lines: 200
  key_links:
    - from: "src/packets/docx_hotsheet.py"
      to: "src/packets/docx_styles.py"
      via: "Uses StyleManager, add_status_badge, set_cell_shading, apply_zebra_stripe, format_header_row"
      pattern: "from src.packets.docx_styles import"
    - from: "src/packets/docx_hotsheet.py"
      to: "src/packets/economic.py"
      via: "Uses ProgramEconomicImpact and EconomicImpactCalculator.format_impact_narrative"
      pattern: "from src.packets.economic import"
    - from: "src/packets/docx_hotsheet.py"
      to: "data/graph_schema.json structural_asks"
      via: "Lookup which structural asks include the current program"
      pattern: "structural_asks"
---

<objective>
Build the HotSheetRenderer -- the core per-program section builder that produces the content-rich Hot Sheet pages for each relevant program in a Tribe's advocacy packet.

Purpose: DOC-02 (Hot Sheet content), DOC-03 (advocacy language assembly), and DOC-04 (structural asks integration) all converge in this single renderer module. Each Hot Sheet is a self-contained 1-2 page section with status badge, award history, hazard relevance, economic impact, advocacy language, Key Ask callout, structural asks, and delegation info.
Output: HotSheetRenderer module with comprehensive tests covering all section types and edge cases.
</objective>

<execution_context>
@D:\Claude-Workspace\.claude/get-shit-done/workflows/execute-plan.md
@D:\Claude-Workspace\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-computation-docx/07-RESEARCH.md
@.planning/phases/07-computation-docx/07-01-SUMMARY.md
@.planning/phases/07-computation-docx/07-02-SUMMARY.md

@src/packets/context.py
@src/packets/economic.py
@src/packets/relevance.py
@src/packets/docx_styles.py
@src/packets/docx_engine.py
@data/program_inventory.json
@data/graph_schema.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create HotSheetRenderer module</name>
  <files>src/packets/docx_hotsheet.py</files>
  <action>
Create `src/packets/docx_hotsheet.py` with these components:

**Imports:**
- From docx: Document, Pt, Inches, RGBColor
- From src.packets.docx_styles: StyleManager, add_status_badge, set_cell_shading, apply_zebra_stripe, format_header_row, CI_STATUS_COLORS, CI_STATUS_LABELS, COLORS
- From src.packets.economic: EconomicImpactCalculator, ProgramEconomicImpact, TribeEconomicSummary, METHODOLOGY_CITATION

**Constants:**
- `FRAMING_BY_STATUS`: dict mapping CI status categories to framing language:
  - Defensive (FLAGGED, AT_RISK): {"tone": "defensive", "verbs": ["protect", "defend", "restore", "prevent loss of"], "prefix": "Critical:"}
  - Protective (UNCERTAIN, STABLE_BUT_VULNERABLE): {"tone": "protective", "verbs": ["safeguard", "ensure continuity of", "prepare", "maintain"], "prefix": "Watch:"}
  - Growth (STABLE, SECURE): {"tone": "growth", "verbs": ["expand", "build on", "strengthen", "invest in"], "prefix": "Opportunity:"}

- `RELEVANT_COMMITTEE_KEYWORDS`: list of substrings to match committees to programs:
  ["Appropriations", "Indian Affairs", "Energy", "Natural Resources", "Environment", "Commerce", "Transportation", "Agriculture"]

**Class HotSheetRenderer:**
- `__init__(self, document: Document, style_manager: StyleManager)`: Store document and style manager references.

- `render_all_hotsheets(self, context: TribePacketContext, programs: list[dict], economic_summary: TribeEconomicSummary, structural_asks: list[dict]) -> int`:
  Iterate through programs (already filtered and sorted by relevance), call render_hotsheet() for each. Add page break between Hot Sheets (but not after the last one). Return count of Hot Sheets rendered.

- `render_hotsheet(self, context, program: dict, economic_impact: ProgramEconomicImpact | None, structural_asks: list[dict]) -> None`:
  Render a single Hot Sheet section into self.document. Section order (omit sections with no data):
  1. _add_title_and_status(program)
  2. _add_program_description(program)
  3. _add_award_history(context, program)
  4. _add_hazard_relevance(context, program)
  5. _add_economic_impact(economic_impact, context, program)
  6. _add_advocacy_language(program)
  7. _add_key_ask(program, context, economic_impact)
  8. _add_structural_asks(program, structural_asks, context)
  9. _add_delegation_info(context, program)
  10. _add_methodology_footnote()

**Private section methods (each adds content to self.document):**

`_add_title_and_status(self, program: dict)`:
- Paragraph with style "HS Title": program["name"]
- Below: paragraph with agency, access_type, funding_type
- Below: add_status_badge() with program["ci_status"]
- Below: CI determination text (program["ci_determination"]) in HS Body style

`_add_program_description(self, program: dict)`:
- Section heading "Program Overview" in HS Section style
- program["description"] in HS Body style
- If program has "federal_home": add "Federal Home: {federal_home}" line

`_add_award_history(self, context: TribePacketContext, program: dict)`:
- Section heading "Award History" in HS Section style
- Normalize CFDA: `cfda_list = [program["cfda"]] if isinstance(program["cfda"], str) else (program["cfda"] or [])`
- Filter context.awards where award["program_id"] == program["id"] OR award["cfda"] in cfda_list
- If matching awards found: create table with headers [Program, CFDA, Obligation, Period], populate rows, apply zebra_stripe, format_header_row. Show total.
- If NO matching awards: render "First-Time Applicant Advantage" framing block:
  - Bold heading: "First-Time Applicant Advantage"
  - Body text: "{tribe_name} has not yet received funding through {program_name}. This positions the Tribe as a first-time applicant -- a category often given priority consideration in competitive programs."
  - Use no_awards_context from award cache if available in context

`_add_hazard_relevance(self, context: TribePacketContext, program: dict)`:
- Section heading "Local Hazard Relevance" in HS Section style
- Extract top_hazards from context.hazard_profile["fema_nri"]["top_hazards"]
- If no hazard data: brief note about ecoregion-based relevance
- If hazard data: list top 3 hazards with risk scores, connect each to the program relevance
- USFS wildfire data: if program is wildfire-related AND usfs_wildfire data exists, show risk_to_homes and likelihood

`_add_economic_impact(self, economic_impact: ProgramEconomicImpact | None, context: TribePacketContext, program: dict)`:
- Section heading "District Economic Impact" in HS Section style
- If economic_impact is None: skip section entirely (return early)
- Use EconomicImpactCalculator.format_impact_narrative() for the main narrative
- If is_benchmark: use benchmark framing ("Based on program averages...")
- If multi-district (len(context.districts) > 1): show total PLUS per-district breakdown
- If FEMA BCR applicable: add EconomicImpactCalculator.format_bcr_narrative()

`_add_advocacy_language(self, program: dict)`:
- Section heading "Advocacy Position" in HS Section style
- Determine framing from FRAMING_BY_STATUS based on program["ci_status"]
- If program has "tightened_language": insert it directly (HS Body style), preceded by framing prefix
- Else: combine description + advocacy_lever: "{FRAMING_PREFIX} {program['advocacy_lever']}. {program['description']}"
- If program has "proposed_fix": add it as additional paragraph
- If program has "specialist_focus": add specialist callout in bold

`_add_key_ask(self, program: dict, context: TribePacketContext, economic_impact: ProgramEconomicImpact | None)`:
- Section heading "Key Ask" in HS Section style
- Render 3-line callout box using HS Callout / HS Callout Detail styles:
  - ASK: derived from advocacy_lever (the one-line specific ask)
  - WHY: "{tribe_name}'s {hazard context} makes this program critical for community resilience"
  - IMPACT: economic impact one-liner from format_impact_narrative(), or benchmark framing
- Apply callout background shading (COLORS.callout_bg) to each paragraph if feasible (add left border or indent for visual separation)

`_add_structural_asks(self, program: dict, structural_asks: list[dict], context: TribePacketContext)`:
- Section heading "Structural Policy Asks" in HS Section style
- Filter structural_asks where program["id"] is in ask["programs"]
- For each matching ask: render ask["name"], ask["description"], ask["target"], ask["urgency"]
- Connect to Tribe evidence: if relevant hazard data or award data supports the ask, add a brief evidence line

`_add_delegation_info(self, context: TribePacketContext, program: dict)`:
- Section heading "Your Delegation" in HS Section style
- List senators and representatives with formatted_name
- **Committee-match flag**: For each member, check if any of their committees match RELEVANT_COMMITTEE_KEYWORDS. If match found: bold callout "[Member] sits on [Committee] -- direct influence on this program"
- If no delegation data: note "Congressional delegation data not available"

`_add_methodology_footnote(self)`:
- Add METHODOLOGY_CITATION text in HS Small style
- Horizontal rule (thin line) above the footnote

**Critical implementation notes:**
- CFDA normalization: `[cfda] if isinstance(cfda, str) else (cfda or [])` -- do this in EVERY method that uses cfda
- tightened_language is NOT present on all programs. Check `program.get("tightened_language")` and fall back gracefully
- All 6 CI statuses must be handled. Use .get() with defaults everywhere.
- Avoid hardcoding program count -- iterate whatever is passed in
- Each section method should check for data presence and return early if empty (the "hide empty sections" requirement)
- Use `self.document.add_page_break()` between Hot Sheets, NOT `self.document.add_section()` (page breaks are cosmetic; section breaks change headers/footers)
- Do NOT modify any Phase 5-6 modules
- Use `logging.getLogger("tcr_scanner.packets.docx_hotsheet")`
  </action>
  <verify>
Run: `python -c "from src.packets.docx_hotsheet import HotSheetRenderer"` -- import works
  </verify>
  <done>HotSheetRenderer renders complete Hot Sheet sections with all 10 sub-sections in correct order, omitting empty sections.</done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive Hot Sheet tests</name>
  <files>tests/test_docx_hotsheet.py</files>
  <action>
Create `tests/test_docx_hotsheet.py` with comprehensive tests:

**Fixtures (shared mock data):**
- `mock_context`: TribePacketContext with tribe_id="epa_001", tribe_name="Alpha Tribe of Arizona", states=["AZ"], ecoregions=["southwest"], districts=[{"district": "AZ-02", "state": "AZ", "overlap_pct": 95.0}], senators=[{"formatted_name": "Sen. Jane Smith (D-AZ)", "committees": [{"committee_name": "Senate Committee on Indian Affairs", "role": "member"}]}], representatives=[{"formatted_name": "Rep. Carol Lee (D-AZ-02)", "committees": [{"committee_name": "House Committee on Appropriations", "role": "member"}]}], awards=[{"award_id": "A001", "cfda": "15.156", "program_id": "bia_tcr", "obligation": 500000.0, "start_date": "2024-01-01", "end_date": "2025-01-01"}], hazard_profile={"fema_nri": {"top_hazards": [{"type": "Wildfire", "code": "WFIR", "risk_score": 92.0, "risk_rating": "Very High", "eal_total": 500000.0}], "composite": {"risk_score": 85.5}}, "usfs_wildfire": {"risk_to_homes": 0.85}}

- `mock_context_zero_awards`: Same as above but awards=[], hazard_profile={}

- `mock_program_stable`: {"id": "bia_tcr", "name": "BIA Tribal Climate Resilience", "agency": "BIA", "ci_status": "STABLE", "tightened_language": "Protect the $34.291M base...", "advocacy_lever": "Protect/expand the line", "description": "Core BIA program...", "priority": "critical", "cfda": "15.156", "access_type": "direct", "funding_type": "Discretionary", "confidence_index": 0.88, "federal_home": "Bureau of Indian Affairs", "ci_determination": "FY26 funded at $34.291M."}

- `mock_program_at_risk`: {"id": "irs_elective_pay", "name": "IRS Elective Pay", ...with ci_status "AT_RISK", tightened_language present...}

- `mock_program_no_tightened`: {"id": "epa_stag", "name": "EPA STAG", ...WITHOUT tightened_language field...}

- `mock_structural_asks`: List from graph_schema.json structural_asks (at least ask_multi_year and ask_match_waivers)

- `mock_economic_impact`: ProgramEconomicImpact with known values

**Tests:**

Rendering tests:
- test_render_hotsheet_creates_content: Render one Hot Sheet, verify document has paragraphs
- test_render_all_hotsheets_count: render_all_hotsheets with 3 programs returns 3
- test_render_all_hotsheets_page_breaks: Page breaks between Hot Sheets but not after last

Section-specific tests:
- test_title_and_status: Program name and CI badge rendered
- test_award_history_with_awards: Table created with correct row count
- test_award_history_zero_awards: "First-Time Applicant Advantage" text rendered
- test_hazard_relevance_with_data: Top hazards listed
- test_hazard_relevance_empty: Section omitted when no hazard data
- test_economic_impact_with_data: Impact range rendered
- test_economic_impact_benchmark: Benchmark framing for zero-award
- test_economic_impact_none_skipped: Section omitted when impact is None

Advocacy language tests:
- test_advocacy_with_tightened_language: tightened_language text appears in document
- test_advocacy_fallback_no_tightened: description + advocacy_lever used when no tightened_language
- test_framing_defensive_at_risk: AT_RISK program gets defensive framing prefix
- test_framing_growth_stable: STABLE program gets growth framing prefix

Structural asks tests:
- test_structural_asks_linked: Matching asks rendered for program
- test_structural_asks_none_matching: Section omitted when no asks match the program

Delegation tests:
- test_delegation_rendered: Senator and representative names appear
- test_committee_match_flag: Committee match callout rendered when member sits on relevant committee

Edge case tests:
- test_all_ci_statuses_render: All 6 CI status values render without error
- test_cfda_string_normalized: CFDA string field handled correctly
- test_cfda_list_normalized: CFDA list field (like fema_bric's ["97.047", "97.039"]) handled correctly
- test_cfda_null_handled: CFDA null field does not crash

All tests create a fresh Document via DocxEngine or direct Document() + StyleManager. Tests verify content by checking paragraph text, table presence, and run formatting. No file I/O needed except for tests that verify .docx saves (use tmp_path).

Run full suite at the end: `python -m pytest tests/ --tb=short`
  </action>
  <verify>
Run: `python -m pytest tests/test_docx_hotsheet.py -v --tb=short` -- all new tests pass
Run: `python -m pytest tests/ --tb=short` -- full suite passes with no regressions
  </verify>
  <done>All Hot Sheet rendering tests pass. All 6 CI statuses render correctly. Advocacy fallback works. Structural asks link correctly. CFDA string/list/null all handled. 106 existing tests still pass.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.packets.docx_hotsheet import HotSheetRenderer"` -- import works
2. `python -m pytest tests/test_docx_hotsheet.py -v` -- all new tests pass
3. `python -m pytest tests/ --tb=short` -- full suite passes (106 existing + all new tests from plans 01-03)
4. Quick manual check: Create a test .docx with one Hot Sheet and open in Word to verify formatting (optional, non-blocking)
</verification>

<success_criteria>
- HotSheetRenderer.render_hotsheet() renders complete Hot Sheet with all applicable sections
- Empty sections are omitted (not shown as blank)
- tightened_language used when present, description+advocacy_lever fallback when absent
- Key Ask callout renders as 3-line ASK/WHY/IMPACT block
- Structural asks link to correct programs with urgency labels
- Committee-match flag highlights delegation members on relevant committees
- All 6 CI statuses produce correct color badges and framing tone
- CFDA normalization handles string, list, and null types
- All tests pass with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/07-computation-docx/07-03-SUMMARY.md`
</output>
