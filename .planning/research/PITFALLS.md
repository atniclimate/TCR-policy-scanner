# Domain Pitfalls: v1.3 Production Launch for TCR Policy Scanner

**Domain:** Adding production launch features to a Tribal Climate Resilience advocacy system
**Project:** TCR Policy Scanner v1.3 -- Production Launch
**Researched:** 2026-02-12
**Confidence:** MEDIUM-HIGH (findings verified against codebase inspection, GitHub Pages official docs, browser security specifications, WCAG 2.1 AA spec, and Indigenous data governance frameworks)

**Governing constraints:**
- 743 tests passing, daily scan + weekly batch workflows on GitHub Actions
- 592 Tribal Nations served, TSDF T0 (Open) classification
- React/Vite/Tailwind frontend must embed in SquareSpace and serve real DOCX files
- 3 of 4 scrapers currently do NOT paginate (silently truncating results)
- 47 known website issues spanning P0 (fake downloads) to P3 (typography)
- Trust is everything -- Tribal Leaders are the primary audience

---

## Critical Pitfalls

Mistakes that break core functionality, erode Tribal Leader trust, or create legal/ethical violations. These turn a "launch" milestone into a credibility crisis.

---

### C-1: Fake Downloads -- The Current System Generates Text Files, Not Real DOCX Documents

**What goes wrong:** The current `TribeSelector.tsx` (lines 38-51) and `RegionSelector.tsx` (lines 23-36) create in-browser Blob objects containing plain text, then trigger a download with a `.txt` extension. This is a P0 issue that has already been identified in the 47 known website issues. The system labels the button "DOWNLOAD REPORT" and shows a "REPORT READY FOR DOWNLOAD" status indicator, but the downloaded file is a 5-line plaintext stub, not the actual DOCX advocacy packet generated by the Python `DocxEngine`.

The disconnect: the Python backend generates real, professionally formatted DOCX documents (via `src/packets/docx_engine.py` with `python-docx`, `StyleManager`, `HotSheetRenderer`, 9-section assembly). But the React frontend does not connect to these files. It generates a fake Blob instead.

**Why it happens:** The React frontend was developed as a SquareSpace-embeddable search widget (Phase 8, WEB-01), while the DOCX generation pipeline runs as a Python batch process on GitHub Actions. The frontend was designed to provide search and discovery, with actual downloads served from static files on GitHub Pages. But the download button was wired to a placeholder Blob rather than to the actual DOCX file URLs.

**Consequences:** A Tribal Leader selects their Nation, sees "REPORT READY FOR DOWNLOAD," clicks download, and receives a 5-line text file that says "This report contains strategic analysis for Tribal climate resilience initiatives." This is the single most trust-destroying behavior possible. It looks professional, promises intelligence, and delivers nothing.

**Warning signs:** Any manual test of the download button reveals this immediately. The `.txt` extension (not `.docx`) is visible in the downloaded file name. The file size is ~200 bytes instead of ~150KB.

**Prevention:**
1. Replace the in-browser Blob generation with a URL-based download pointing to the actual DOCX files on GitHub Pages: `packets/internal/{tribe_id}.docx` and `packets/congressional/{tribe_id}.docx`.
2. Wire the download button to construct the correct URL from the `tribes.json` index data, using the `documents` field already built by `build_web_index.py`.
3. If the DOCX file does not exist for a given Tribe, show a clear message ("Document not yet available for this Nation") instead of offering a download button that delivers a fake file.
4. Test the complete flow: search for a Tribe -> click download -> verify the file opens in Microsoft Word with correct formatting, real data, and all 9 sections.
5. Remove all Blob-based download code from both `TribeSelector.tsx` and `RegionSelector.tsx`.

**Detection:** Open the downloaded file in Microsoft Word. If it is a text file, the fix has not been applied.

**Severity:** DESTROYS TRUST -- the single highest priority fix in the entire milestone.

**Phase mapping:** Must be addressed in the very first phase of v1.3.

---

### C-2: GitHub Pages Serves DOCX Files as `application/octet-stream` or `application/zip`, Not as the Correct MIME Type

**What goes wrong:** GitHub Pages determines MIME types from file extensions using its internal mapping. The correct MIME type for `.docx` files is `application/vnd.openxmlformats-officedocument.wordprocessingml.document`. However, GitHub Pages may serve `.docx` files as `application/octet-stream` (generic binary) or even `application/zip` (because DOCX is technically a ZIP archive). There is a known issue where DOCX files are misidentified as `application/zip`.

This matters because:
- Some browsers will try to open `application/zip` files by unzipping them rather than launching Word.
- Mobile devices (especially iOS) may not know what to do with `application/octet-stream`.
- `Content-Disposition` headers on GitHub Pages are not configurable -- you cannot force `attachment; filename="report.docx"` on a static hosting platform.

**Why it happens:** GitHub Pages is a static file server with no user-configurable MIME types. Unlike Apache (`.htaccess`), Nginx (`mime.types`), or Cloudflare Workers, there is no mechanism to set custom `Content-Type` headers for specific file extensions.

**Consequences:** On some browsers and devices, clicking the download link opens a confusing binary blob or tries to unzip the file. The user experience degrades silently -- you will not see an error, just confusion.

**Prevention:**
1. Test actual DOCX downloads from GitHub Pages on Chrome, Firefox, Safari, Edge, iOS Safari, and Android Chrome. Verify the file opens correctly in Microsoft Word (or the device's default handler).
2. If MIME type issues arise, use a JavaScript-mediated download: `fetch()` the DOCX file as a blob, set the correct type, and trigger a download via `URL.createObjectURL()` with explicit `application/vnd.openxmlformats-officedocument.wordprocessingml.document` type.
3. Add the `download` attribute to all `<a>` tags pointing to DOCX files. The `download` attribute hints to the browser that the link should be downloaded, not navigated to.
4. Verify that the `.nojekyll` file exists in the GitHub Pages root to prevent Jekyll from interfering with binary files.
5. Consider hosting DOCX files on a CDN that supports custom MIME types as a fallback if GitHub Pages proves unreliable.

**Warning signs:** DOCX downloads produce ZIP files, or mobile users report they cannot open downloaded files.

**Detection:** Use browser DevTools Network tab to check the `Content-Type` header on a DOCX file response from GitHub Pages.

**Severity:** DEGRADES USER EXPERIENCE -- silent failure on some devices, especially mobile.

**Phase mapping:** Test during deployment phase; JavaScript download wrapper as mitigation.

---

### C-3: SquareSpace Sandbox Attribute Blocks Downloads from Iframed Content

**What goes wrong:** When the React app is embedded in SquareSpace via an iframe, SquareSpace applies security attributes to the iframe. Starting with Chrome 83, downloads initiated from sandboxed iframes are blocked unless the `allow-downloads` attribute is explicitly included in the iframe's `sandbox` attribute list. The error message is: "Download is disallowed. The frame initiating or instantiating the download is sandboxed, but the flag 'allow-downloads' is not set."

SquareSpace's embed blocks use the `<iframe>` element, but users have limited control over the sandbox attribute. If SquareSpace sets `sandbox="allow-scripts allow-same-origin"` without `allow-downloads`, every download attempt from the embedded React app will silently fail. The user clicks "DOWNLOAD REPORT" and nothing happens.

**Why it happens:** The iframe sandbox security model was designed to prevent untrusted embedded content from initiating downloads (a potential vector for drive-by downloads). SquareSpace applies sandboxing by default to protect site owners from malicious embedded code.

**Consequences:** The entire download flow -- the core purpose of the application -- fails when the app is embedded in SquareSpace. No error is shown to the user. The button click is simply swallowed.

**Prevention:**
1. Use a SquareSpace **Code Block** (not Embed Block) to add the iframe manually with full control over attributes: `<iframe src="..." sandbox="allow-scripts allow-same-origin allow-downloads allow-popups" ...>`.
2. As a fallback, instead of triggering downloads directly from the iframe, open the download URL in a new tab/window using `window.open()`. This escapes the iframe sandbox because `allow-popups` is more commonly allowed than `allow-downloads`.
3. Test the complete flow in SquareSpace's actual preview mode, not just in a standalone browser. The sandbox restrictions only manifest inside the iframe context.
4. If neither `allow-downloads` nor `window.open()` works within SquareSpace's iframe, implement a "Copy Download Link" button that puts the direct GitHub Pages URL into the clipboard. The user can then paste it into a new tab.
5. Add a detection mechanism: if `window.parent !== window` (embedded in iframe), and the download fails, show a fallback message with a direct link.

**Warning signs:** Download button works in standalone browser but fails when embedded in SquareSpace. No error message appears. Console shows sandbox violation error only.

**Detection:** Open the SquareSpace-embedded version and attempt a download. Check browser console for sandbox-related errors.

**Severity:** BLOCKS CORE FUNCTIONALITY when embedded -- this is the primary deployment target.

**Phase mapping:** Must be validated during SquareSpace integration phase.

---

### C-4: Three of Four Scrapers Silently Truncate Results (No Pagination)

**What goes wrong:** The `CongressGovScraper._search_congress()` (line 105: `"limit": 50`), `CongressGovScraper._search()` (line 125: `"limit": 50`), `FederalRegisterScraper._search()` (line 88: `"per_page": 50`), and `GrantsGovScraper._search_cfda()` (line 114: `"rows": 25`) all request a single page of results and never check for pagination tokens or next-page indicators. Only the `USASpendingScraper.fetch_tribal_awards_for_cfda()` (line 136) implements full pagination with `page_metadata.hasNext`.

If any API returns more results than the page size, the excess results are silently dropped. For Federal Register searches during active rulemaking periods, 50 results may not capture all relevant documents. For Grants.gov CFDA searches during open funding windows, 25 results per CFDA may miss opportunities.

**Why it happens:** During v1.0 development, the scan window was set to 14 days (`scan_window_days: 14`), which typically produces fewer than 50 results per query. The pagination gap was not visible because the small window kept result counts low. As the system matures and the scan window potentially widens, or during periods of high federal activity (e.g., end-of-fiscal-year funding pushes), truncation becomes a real problem.

**Consequences:** Missing policy documents, grant opportunities, or legislative actions. A Tribal Leader's advocacy packet may omit a relevant funding opportunity because it was result #26 of 40 and the scraper only fetched 25. This is an accuracy failure in a system that promises "policy intelligence."

**Prevention:**
1. Implement pagination for each API using its native pagination mechanism:
   - **Congress.gov:** Response includes `pagination.next` URL. Loop until `pagination.next` is null.
   - **Federal Register:** Response includes `next_page_url`. Loop until `next_page_url` is null.
   - **Grants.gov:** Response includes `totalHits` and `offset`. Loop until `offset + rows >= totalHits`.
2. Add a safety cap to prevent infinite loops: maximum 10 pages (500-1000 results) per query. Log a warning if the cap is hit.
3. Add a test that asserts the scraper requests multiple pages when the API indicates more results are available (mock the API response with pagination metadata).
4. Emit a metric in the scan log: "Congress.gov: fetched 73 items across 2 pages (total available: 73)" so truncation is visible.
5. Do NOT change the default `limit`/`per_page`/`rows` values -- keep them at 25-50 per page. The fix is adding pagination, not increasing page size (which would hit rate limits).

**Warning signs:** Scan log shows round numbers at page-size boundaries (exactly 50, exactly 25) for a given query. Total item count seems low for a broad query.

**Detection:** Compare scraper output count against the API's reported `totalResults` or `totalHits` count. If they differ, pagination is needed.

**Severity:** DEGRADES DATA ACCURACY -- silent data loss, impossible to detect without comparing against API totals.

**Phase mapping:** Scraper pagination should be a dedicated phase early in the milestone.

---

### C-5: Vite Base Path Not Configured for GitHub Pages Repository Path

**What goes wrong:** The current `vite.config.ts` does not set the `base` property. By default, Vite uses `base: "/"`. When deployed to GitHub Pages at `https://username.github.io/tcr-policy-scanner/`, all assets (JS, CSS, images) will be requested from `https://username.github.io/main.js` instead of `https://username.github.io/tcr-policy-scanner/main.js`, resulting in 404 errors for all assets. The deployed page will be blank.

Additionally, if React Router is added later, `BrowserRouter` will not work on GitHub Pages without either:
- A `404.html` redirect hack (copy `index.html` to `404.html` during build)
- Switching to `HashRouter` (which adds `#` to all URLs)

The current app does not use React Router (it is a single-page widget), but this is a known landmine for future development.

**Why it happens:** Vite defaults to `base: "/"` which works for root-level hosting (e.g., `custom-domain.com/`) but fails for repository-level hosting (e.g., `github.io/repo-name/`). This is the most common GitHub Pages deployment failure for Vite apps.

**Consequences:** The deployed site shows a blank white page. All JavaScript and CSS files return 404. The HTML loads correctly but the `<script type="module" src="/src/main.tsx">` resolves against the wrong root.

**Prevention:**
1. Set `base` in `vite.config.ts` to the repository name:
   ```ts
   export default defineConfig({
     base: '/tcr-policy-scanner/',
     // ... rest of config
   })
   ```
   Or use a conditional for local development:
   ```ts
   base: process.env.NODE_ENV === 'production' ? '/tcr-policy-scanner/' : '/',
   ```
2. Update `index.html` to use relative paths: `<script type="module" src="./src/main.tsx">` (the `./` makes it relative to the document, not the domain root).
3. If deploying to a custom domain, `base: "/"` is correct. Document which configuration is active and why.
4. After deployment, verify that the Network tab in DevTools shows all assets loading with 200 status codes, not 404s.
5. Add a `404.html` that copies `index.html` to handle direct navigation to sub-paths, even if the app currently has no routing.

**Warning signs:** Deployed site shows blank page. Browser console shows multiple 404 errors for `.js` and `.css` files.

**Detection:** Open the deployed GitHub Pages URL and check the browser console. If any asset returns 404, `base` is misconfigured.

**Severity:** BREAKS DEPLOYMENT -- site is completely non-functional without this fix.

**Phase mapping:** Must be fixed before first deployment. Part of deployment configuration phase.

---

### C-6: Indigenous Data Sovereignty Violations via Third-Party Tracking Scripts

**What goes wrong:** Under TSDF T0 (Open) classification, the data itself is publishable, but the system must not leak behavioral metadata about which Tribal Nations are viewing or downloading their reports. If the React app includes:
- Google Analytics or any third-party analytics
- Google Fonts loaded from Google CDN (leaks IP + page views to Google)
- Third-party error tracking (Sentry, LogRocket, FullStory)
- Social media embed SDKs
- Third-party CDN-loaded JavaScript

...then every Tribal Leader who searches for their Nation's name has their identity and interest correlated in a third-party database. This violates the CARE Principles for Indigenous Data Governance (Authority to Control) and potentially OCAP principles (Ownership, Control, Access, Possession) depending on the data flowing through these trackers.

The risk is not theoretical. A tracking script that records "User searched for 'Muckleshoot Indian Tribe' at 3:47 PM from IP 198.xxx" creates a dataset of which Tribal Nations are actively seeking federal climate resilience intelligence. This behavioral metadata is sensitive even when the underlying policy data is T0 (Open).

**Why it happens:** Developers routinely add analytics and CDN-loaded fonts during the "production polish" phase. These are standard practices for web applications. The unique context of a Tribal advocacy system makes these standard practices harmful.

**Consequences:** Behavioral data about 592 Tribal Nations' policy interests is collected by third parties. This violates data sovereignty principles. If discovered, it destroys trust with the Tribal communities this system serves.

**Prevention:**
1. **Audit all external requests:** Use the browser's Network tab to verify that the deployed app makes ZERO requests to third-party domains. Every request should go to `github.io` or same-origin resources.
2. **Self-host all fonts:** The app currently uses `League Spartan` and `Roboto` fonts via inline `fontFamily` CSS. These must be bundled in the build, not loaded from Google Fonts CDN. Verify by checking for `fonts.googleapis.com` requests.
3. **No analytics:** Do not add Google Analytics, Plausible, Fathom, or any analytics service. If usage metrics are needed, use GitHub Pages' built-in traffic analytics (which is visible only to repository admins, not third parties).
4. **No error tracking services:** Do not add Sentry, LogRocket, or similar. Use browser console error handling with local state only.
5. **CSP header via `<meta>` tag:** Add a Content-Security-Policy meta tag to `index.html` that restricts connections to the same origin:
   ```html
   <meta http-equiv="Content-Security-Policy"
         content="default-src 'self'; font-src 'self'; connect-src 'self'; img-src 'self' data:;">
   ```
6. **Document the constraint:** Add a "Data Sovereignty Compliance" section to the project README explaining why third-party tracking is prohibited.
7. **Pre-deployment audit checklist:** Before every deployment, run: open the site in an incognito window with DevTools Network tab open, interact with all features, verify zero third-party requests.

**Warning signs:** Network tab shows requests to domains other than `github.io`. `fonts.googleapis.com` appears in the request list.

**Detection:** Automated: add a CI test that builds the app and scans all HTML/JS output for third-party URLs. Manual: Network tab audit.

**Severity:** VIOLATES DATA SOVEREIGNTY -- ethical and potentially legal implications for Tribal communities.

**Phase mapping:** Must be validated at every deployment. Add as a CI check.

---

## Moderate Pitfalls

Mistakes that cause significant user experience degradation, data quality issues, or accessibility barriers, but do not break core functionality.

---

### M-1: Autocomplete/Search Widget Fails WCAG 2.1 AA for Keyboard and Screen Reader Users

**What goes wrong:** The current `TribeSelector.tsx` autocomplete has multiple accessibility failures:

1. **No ARIA roles:** The input has no `role="combobox"`, no `aria-expanded`, no `aria-controls`, no `aria-activedescendant`. Screen readers do not know this is an autocomplete widget and cannot announce the suggestion list.
2. **No keyboard navigation in suggestions:** The suggestion list (lines 124-139) is a set of `<button>` elements with `onClick` handlers, but there is no `onKeyDown` handler for arrow-key navigation through the list. A keyboard-only user can Tab to each suggestion, but cannot use arrow keys as expected for a combobox pattern.
3. **No live region announcements:** When the suggestion list updates (new filtered results), there is no `aria-live` region to announce the count of results to screen reader users (e.g., "8 results available").
4. **Color contrast:** The `text-cyan-300/60` label text (approximately #67C5C9 at 60% opacity on dark background) may fail the 4.5:1 contrast ratio requirement for WCAG AA normal text.
5. **Focus management:** When a user selects a suggestion, focus returns to the input (`inputRef.current?.focus()`) but does not announce the selected value.
6. **The RegionSelector dropdown** (lines 80-98) uses a `<button>` element styled as a dropdown but has no `role="listbox"`, no `aria-expanded`, and no keyboard support for option selection.

**Why it happens:** The component was developed as a visual prototype matching a Figma design. Accessibility was not part of the Phase 8 scope.

**Consequences:** Keyboard-only users and screen reader users cannot effectively use the search/download flow. This excludes Tribal climate coordinators and federal partners who use assistive technology. Per Section 508 (which applies to federal-facing tools), this is a compliance gap.

**Prevention:**
1. Follow the WAI-ARIA Combobox Pattern (W3C APG) exactly: `role="combobox"` on the input, `role="listbox"` on the suggestions container, `role="option"` on each suggestion, `aria-activedescendant` tracking, arrow-key navigation.
2. Add an `aria-live="polite"` region that announces suggestion count changes: "8 Tribal Nations found" or "No results."
3. Run `axe-core` or `pa11y` against the built page as a CI check.
4. Test with NVDA (Windows) and VoiceOver (macOS) manually before launch.
5. Verify color contrast ratios using WebAIM's contrast checker for all text/background combinations on the dark theme.
6. For the RegionSelector, consider using Radix UI's `Select` component (already in the project's dependencies at `@radix-ui/react-select@^2.1.6`) which has built-in WCAG compliance.

**Warning signs:** Tabbing through the page skips the suggestion list. Screen reader announces "text input" with no indication it is a combobox.

**Detection:** Keyboard-only test: try to search, select a suggestion, and download a report without using the mouse. If any step is impossible, accessibility is broken.

**Severity:** EXCLUDES USERS -- violates WCAG 2.1 AA and Section 508.

**Phase mapping:** Dedicated accessibility phase required.

---

### M-2: 592 DOCX Files Exceed GitHub Pages Repository Size Recommendations

**What goes wrong:** GitHub Pages recommends repositories be under 1 GB, with published sites no larger than 1 GB. If each DOCX file averages 150 KB:
- 592 Tribes x 2 document types (internal + congressional) = 1,184 files
- 1,184 x 150 KB = ~173 MB per generation
- Plus regional documents (7 regions x 2 types = 14 files)
- Plus the strategic overview document

With git history, multiple generations accumulate. After 6 monthly generations: 6 x 173 MB = ~1 GB of DOCX files in git history, even if old files are overwritten (git stores all versions).

Additionally, the bandwidth limit is 100 GB/month. If each download is ~150 KB and 200 concurrent users each download 2-4 documents per session: 200 users x 3 documents x 150 KB = 90 MB per burst. This is far below the monthly limit for normal usage but could become an issue if the tool gains widespread adoption across all 592 Nations.

**Why it happens:** GitHub Pages is designed for documentation sites and small web apps, not for serving a large corpus of binary files. DOCX files are binary (compressed XML in a ZIP container) and do not benefit from git's delta compression.

**Consequences:** Repository becomes slow to clone. GitHub may display warnings about repository size. In extreme cases, GitHub may contact the repository owner about exceeding recommended limits.

**Prevention:**
1. Use `git lfs` (Git Large File Storage) for `.docx` files. This stores the binary files outside the main git repository and serves them via LFS endpoints. GitHub Pages supports LFS.
2. Alternatively, use GitHub Releases to host DOCX archives (one ZIP per batch generation) and link to release assets from the web widget.
3. Set up `.gitattributes` to track `*.docx` files with LFS:
   ```
   *.docx filter=lfs diff=lfs merge=lfs -text
   ```
4. Monitor repository size with `git count-objects -vH` after each batch generation.
5. Consider generating DOCX files on-demand via a serverless function (Cloudflare Workers, Vercel Edge Functions) instead of pre-generating all 1,184 files. This is a larger architectural change but eliminates the storage problem entirely.

**Warning signs:** `git clone` takes more than 30 seconds. GitHub shows "This repository is over 1 GB" warning. GitHub Actions build times increase significantly.

**Detection:** Check repository size after each batch generation deployment.

**Severity:** DEGRADES INFRASTRUCTURE -- slow builds, potential GitHub warnings, eventual hosting issues.

**Phase mapping:** Address during deployment architecture phase.

---

### M-3: Confidence Scores May Create Overconfidence Bias in Tribal Leaders

**What goes wrong:** Research on AI confidence calibration shows that users over-rely on systems displaying high confidence scores and under-rely on systems displaying low scores. When the TCR Policy Scanner shows "Data Confidence: HIGH (0.95)" next to an award figure, a Tribal Leader may treat that number as more authoritative than it deserves, especially if:
- The confidence score reflects data freshness, not data accuracy
- The score is computed from source tier assignments that were themselves set by the developer, not calibrated against actual error rates
- The base tier scores (T1=1.00, T2=0.95, etc.) were chosen for intuitive readability, not empirical calibration

The confidence scoring proposal (in `docs/proposals/confidence-scoring.md`) assigns T1 (1.00) to USASpending API records. But USASpending data has known quality issues: award amounts may reflect obligations, not outlays; recipient names may be entity-level, not Tribe-level; deobligations may not be reflected in point-in-time queries.

**Why it happens:** Confidence scoring is a well-intentioned transparency feature (the proposal explicitly states "honest data is more valuable than impressive data"). But the initial calibration reflects developer assumptions about source reliability, not empirical validation against known outcomes.

**Consequences:** Tribal Leaders may cite uncalibrated confidence scores in congressional testimony or funding applications, potentially undermining their credibility if the data later proves incorrect. The confidence score itself becomes a source of false trust.

**Prevention:**
1. **Use qualitative labels, not numeric scores, in user-facing output.** Show "VERIFIED" / "ESTIMATED" / "PENDING" instead of "0.95" / "0.70" / "0.00". Research shows numeric scores create false precision.
2. **Calibrate against known outcomes before displaying scores.** Compare USASpending award data against known Tribal government award announcements. If the match rate is 85%, the confidence score for USASpending data should be 0.85, not 1.00.
3. **Add disclaimers to the DOCX output** explaining what "Data Confidence: HIGH" means in plain language: "This data comes directly from the federal financial system and has been verified against multiple sources. However, it reflects obligations, not final expenditures."
4. **Never display confidence scores as percentages** (which imply probability). Use descriptive labels or shaded indicators.
5. **Start conservative.** Launch with simple "Verified / Unverified / Pending" labels. Add numeric scores only after empirical calibration.

**Warning signs:** Tribal Leaders ask "what does 0.95 confidence mean?" and the answer is "we assigned that number because it comes from a government API" rather than "we validated 95% of these records against known outcomes."

**Detection:** Review the confidence scoring implementation for empirical calibration vs. developer assumptions.

**Severity:** ERODES TRUST -- creates false precision that undermines credibility when questioned.

**Phase mapping:** Confidence scoring phase; defer numeric scores to after calibration.

---

### M-4: Rate Limiting During Paginated Scraper Runs Causes Cascading Failures

**What goes wrong:** When pagination is added to the three unpaginated scrapers (C-4), the number of API requests per scan increases significantly:
- Congress.gov: 11 targeted queries x 50/page, if each returns 150 results = 11 x 3 pages = 33 requests (up from 11)
- Federal Register: ~10 queries x 50/page, if some return 100+ results = ~30 requests (up from ~10)
- Grants.gov: 12 CFDA queries + keyword queries, if each returns 50+ results = ~36 requests (up from ~12)

Congress.gov has a rate limit of 5,000 requests/hour with API key. The current 0.3-second delay between requests (line 77 of `congress_gov.py`) means ~200 requests/minute = 12,000/hour, well above the limit. With pagination tripling the request count, rate limiting will kick in hard.

The existing `BaseScraper._request_with_retry()` handles 429 responses by waiting for `Retry-After`, but the circuit breaker (added in v1.2) may misinterpret sustained 429 responses as API failure and trip open, as already documented in the v1.2 PITFALLS.md (C-1).

**Why it happens:** The inter-request delay (0.3s) was set for the unpaginated case where each query produced one request. Pagination multiplies the request count without adjusting the delay.

**Consequences:** Scrapers hit rate limits during pagination, triggering long Retry-After delays. Circuit breakers may trip. Scan runtime balloons from 2-3 minutes to 15-20 minutes. GitHub Actions `timeout-minutes` may expire.

**Prevention:**
1. Increase inter-request delay to 0.5-1.0 seconds for paginated requests.
2. Add per-source request budgets: "Congress.gov: maximum 100 requests per scan."
3. Between pagination pages within the same query, use a shorter delay (0.3s). Between different queries, use a longer delay (1.0s).
4. Log the total request count per source at the end of each scan: "Congress.gov: 47 requests across 11 queries."
5. Adjust GitHub Actions `timeout-minutes` to accommodate longer scan times.
6. Ensure the circuit breaker exempts 429 responses from failure counting (this should already be in place from v1.2 fixes).

**Warning signs:** Scan logs show multiple 429 responses during a single scan. Scan runtime exceeds 5 minutes.

**Detection:** Monitor scan log for 429 response counts and total runtime.

**Severity:** DEGRADES SCRAPER RELIABILITY -- potential data loss if scans time out.

**Phase mapping:** Must be addressed alongside scraper pagination (C-4).

---

### M-5: GitHub Pages 404 Fallback Creates Silent Failures for Missing DOCX Files

**What goes wrong:** If a DOCX file does not exist for a given Tribe (e.g., the batch generation skipped that Tribe due to insufficient data), GitHub Pages returns a 404 response. But if a `404.html` file exists (for SPA routing), the browser receives a 200 response containing the `404.html` HTML content, not a true 404 error. The download attempt silently delivers an HTML file instead of a DOCX file.

This is specific to the `404.html` SPA redirect hack. Without the hack, the user gets a proper 404. With the hack, the user gets a confusing HTML file that may be saved with a `.docx` extension.

**Why it happens:** The SPA redirect hack works by serving `404.html` (a copy of `index.html`) for all unknown paths. This is correct for route-based navigation but breaks for file downloads where a 404 should be a real 404.

**Consequences:** A user attempts to download a DOCX file that does not exist. Instead of an error message, they receive an HTML file saved as `tribe_name.docx`. When they try to open it in Word, it either fails or shows garbled HTML. Trust is damaged.

**Prevention:**
1. **Do not use the `404.html` SPA redirect hack** unless the app actually needs client-side routing. The current app is a single-page widget with no routes -- it does not need this hack.
2. If `404.html` is needed for routing, place all DOCX files under a path prefix (e.g., `/packets/`) and serve the SPA only from the root. GitHub Pages `404.html` applies globally, but you can structure the directory to avoid conflicts.
3. **Pre-validate download links:** In the JavaScript download handler, use a `HEAD` request or check the `tribes.json` index for `has_complete_data: true` before offering the download button. Only show the download button if the file is confirmed to exist in the index.
4. **Verify Content-Type in download handler:** After fetching, check that the response `Content-Type` is not `text/html`. If it is, the file does not exist.
5. **Graceful degradation:** If a Tribe has no DOCX files, show "Document generation pending -- data for your Nation is being compiled" instead of a download button.

**Warning signs:** Downloaded files are very small (a few KB) or very large (matching the full `index.html` size). Word fails to open the downloaded file.

**Detection:** Download a file for a Tribe known to have no generated DOCX. If you receive an HTML file instead of an error, this pitfall is active.

**Severity:** CONFUSES USERS -- delivers wrong file type silently.

**Phase mapping:** Address during download handler implementation.

---

### M-6: SquareSpace CSP and X-Frame-Options Interactions With GitHub Pages

**What goes wrong:** When embedding the GitHub Pages-hosted React app into SquareSpace:

1. **X-Frame-Options:** GitHub Pages sets `X-Frame-Options: DENY` or `X-Frame-Options: SAMEORIGIN` on some responses. If set, the browser will refuse to render the GitHub Pages content inside a SquareSpace iframe. The iframe will show a blank space or a "refused to connect" error.
2. **Content-Security-Policy frame-ancestors:** Modern browsers use the `frame-ancestors` CSP directive instead of `X-Frame-Options`. GitHub Pages does not allow custom CSP headers, so you cannot add `frame-ancestors https://yoursquarespace.com`.
3. **Mixed content:** SquareSpace serves over HTTPS. GitHub Pages also serves over HTTPS. This is fine -- but if any resource loaded by the React app uses HTTP, the browser will block it.

**Why it happens:** GitHub Pages is designed to serve websites, not to be embedded in third-party sites. Its security headers are configured for direct browsing, not iframe embedding.

**Consequences:** The React app may not load at all inside SquareSpace. The page shows a blank iframe or an error. No download functionality is available.

**Prevention:**
1. **Test iframe embedding immediately.** Before building any features, create a minimal test: deploy a "Hello World" page to GitHub Pages, embed it in a SquareSpace Code Block, and verify it renders. If it does not, explore alternatives before investing in features.
2. **Check actual headers:** Use `curl -I https://username.github.io/repo/` to inspect `X-Frame-Options` and `Content-Security-Policy` headers from GitHub Pages.
3. **If GitHub Pages blocks iframe embedding:** Deploy the React app to an alternative that allows cross-origin embedding:
   - Cloudflare Pages (allows custom headers via `_headers` file)
   - Vercel (allows custom headers via `vercel.json`)
   - Netlify (allows custom headers via `_headers` file)
4. **Fallback plan:** If iframe embedding is not possible on any platform, provide a direct link from SquareSpace to the GitHub Pages site. This is a UX compromise but maintains full functionality.
5. **Test periodically:** GitHub may change their header policy. What works today may break tomorrow.

**Warning signs:** The SquareSpace page shows a blank space where the widget should be. Browser console shows "Refused to display in a frame because 'X-Frame-Options' is set to 'DENY'."

**Detection:** Embed the GitHub Pages URL in any iframe and check if it renders.

**Severity:** BLOCKS EMBEDDING -- may require alternative hosting platform.

**Phase mapping:** Must be the very first thing tested in the SquareSpace integration phase.

---

## Technical Debt Patterns

Patterns that create compounding problems if not addressed during the production launch.

---

### TD-1: Mock Data Hardcoded in Frontend While Real Data Exists in Backend

**What goes wrong:** The `mockData.ts` file contains 46 hardcoded Tribe names and 30 hardcoded region names. The real `tribal_registry.json` contains 592 Tribes with `tribe_id`, `name`, `states`, `ecoregion`, and other metadata. The `build_web_index.py` script builds a `tribes.json` index with all 592 Tribes and their document availability.

If the frontend continues using `mockData.ts` instead of loading `tribes.json`, the autocomplete will only show 46 of 592 Tribes. A Tribal Leader searching for their Nation will find nothing if their Nation is not in the hardcoded list.

**Prevention:**
1. Replace `import { TRIBES } from '../data/mockData'` with a fetch call to `tribes.json` at startup.
2. Build the autocomplete suggestion list from the `tribes.json` data, which includes document availability flags (`has_complete_data`, `documents` object).
3. Only offer the download button for Tribes that have documents listed in the index.
4. Remove `mockData.ts` entirely to prevent accidental reuse.

**Severity:** WRONG DATA -- 546 of 592 Tribes are invisible in the current frontend.

---

### TD-2: No Error Handling or Loading States for DOCX Downloads

**What goes wrong:** The current download handler uses Blob-based downloads with no error handling. When replaced with URL-based downloads from GitHub Pages, multiple failure modes need handling:
- Network failure during download
- File not found (Tribe has no generated documents)
- GitHub Pages rate limiting (429 response)
- Partial download (network interruption)
- CORS issues if downloading from a different origin

The current code has no try/catch, no loading spinner during download, no error messages, and no retry logic.

**Prevention:** Implement proper download handling with states: idle -> downloading -> complete / error. Show a loading spinner during download, success confirmation, or actionable error message.

**Severity:** POOR UX -- user confusion when downloads fail silently.

---

## Integration Gotchas

Specific to connecting v1.3 features with the existing v1.0-v1.2 system.

---

### IG-1: Web Index (`tribes.json`) Must Be Regenerated After Every Batch Run

**What goes wrong:** The `build_web_index.py` script scans the `outputs/packets/` directory for existing DOCX files and builds the `tribes.json` index. If the batch generation workflow runs but `build_web_index.py` does not run afterward, the index is stale. New or updated DOCX files will not appear in the web widget's search results.

The GitHub Actions workflow must chain: `batch generation -> build_web_index.py -> deploy to Pages`.

**Prevention:** Ensure the workflow calls `build_web_index.py` as a step after batch generation and before Pages deployment. Add a CI check that verifies `tribes.json` `generated_at` timestamp is within 1 hour of the latest DOCX file modification time.

**Severity:** STALE INDEX -- users cannot find newly generated documents.

---

### IG-2: Font Loading in DOCX vs. Font Loading in React App

**What goes wrong:** The React app uses `League Spartan` and `Roboto` fonts via CSS `fontFamily`. The DOCX documents use different fonts defined in `StyleManager` (likely Times New Roman, Calibri, or similar professional document fonts). If a user expects visual consistency between the web interface and the downloaded document, they will be confused.

More critically: if the React app references fonts via Google Fonts CDN (even as a fallback in CSS), this creates the data sovereignty violation described in C-6.

**Prevention:** Self-host `League Spartan` and `Roboto` font files in the Vite build. Add explicit `@font-face` declarations pointing to local files, not CDN URLs. Document the intentional difference between web interface fonts and DOCX document fonts.

**Severity:** LOW -- cosmetic inconsistency + potential sovereignty violation.

---

### IG-3: Build Pipeline Must Produce Both SPA and Static DOCX Assets

**What goes wrong:** The Vite build process produces a single-page app (`index.html`, `assets/`, etc.). The DOCX files are produced by a separate Python batch process. The GitHub Pages deployment must merge both outputs into a single directory structure:

```
/                          <- Vite SPA output
/assets/                   <- Vite JS/CSS bundles
/packets/internal/         <- DOCX files from Python batch
/packets/congressional/    <- DOCX files from Python batch
/data/tribes.json          <- Web index from build_web_index.py
```

If the GitHub Actions workflow deploys the Vite build without including the DOCX files, the download links will all 404. If it deploys the DOCX files without the Vite build, the search widget will not load.

**Prevention:** Create a deployment step that merges Vite build output and Python batch output into a single directory before deploying to GitHub Pages. Use the `actions/upload-pages-artifact` action on the merged directory.

**Severity:** BREAKS DEPLOYMENT if either half is missing.

---

## Performance Traps

---

### PT-1: 592-Entry Autocomplete JSON Loaded on Every Page View

**What goes wrong:** The `tribes.json` file with 592 entries, document availability flags, states, and ecoregion data could be 100-200 KB. If loaded synchronously on page load, it blocks rendering. If loaded without caching headers, it is re-fetched on every visit.

Inside the SquareSpace iframe, this is worse: the parent page may already be heavy, and adding a 200 KB fetch to an iframe delays the embedded widget's interactivity.

**Prevention:**
1. Lazy-load `tribes.json` only when the user focuses the search input (not on page load).
2. Compress `tribes.json` using gzip or brotli during the build step (Vite can be configured for this).
3. Consider a minimal initial payload (just Tribe names and IDs) with full metadata loaded on demand.
4. GitHub Pages serves with caching headers that the browser will respect. Verify the `Cache-Control` header to ensure repeat visits use the cache.

**Severity:** SLOW LOAD -- noticeable delay on first interaction, especially on mobile.

---

### PT-2: Concurrent Users on GitHub Pages During Tribal Climate Events

**What goes wrong:** GitHub Pages has a 100 GB/month bandwidth limit. During major federal climate announcements (e.g., new FEMA BRIC funding round), many Tribal climate coordinators may access the tool simultaneously. If 200 users each download 4 DOCX files (150 KB each): 200 x 4 x 150 KB = 120 MB per burst. This is negligible against the 100 GB monthly limit.

However, GitHub Pages may enforce undocumented per-minute or per-second rate limits. The official documentation says "rate limits may be enforced" with 429 responses. If the site returns 429s during a critical period, Tribal Leaders cannot access their advocacy intelligence when they need it most.

**Prevention:**
1. Place a CDN (Cloudflare, with free tier) in front of GitHub Pages for DOCX file distribution. Cloudflare caches static files and absorbs traffic bursts.
2. Pre-generate a single ZIP file containing all DOCX files for bulk download, reducing the number of individual requests.
3. Monitor GitHub Pages traffic analytics to establish baseline usage patterns before major announcements.
4. Have a fallback distribution plan: if GitHub Pages goes down, DOCX files can be shared via Google Drive or direct email.

**Severity:** UNLIKELY BUT HIGH IMPACT -- only manifests during critical usage spikes.

---

## Security Mistakes

---

### S-1: GitHub Pages Exposes Full Repository History Including Intermediate Data

**What goes wrong:** GitHub Pages is deployed from a repository that may also contain:
- Scraper API keys in environment variables (not in code, but in workflow secrets)
- Intermediate data files with individual award amounts per Tribe
- Draft documents with unreviewed confidence scores
- Test fixtures with Tribal Nation names and mock data

While the Pages site only serves the built output, the source repository is public (or could become public). Any data committed to git history is permanently accessible.

**Prevention:**
1. Keep the GitHub Pages deployment in a separate branch or repository from the Python pipeline code.
2. Add `outputs/`, `data/award_cache/`, `data/hazard_profiles/` to `.gitignore` to prevent accidental commit of intermediate data.
3. Use GitHub Actions secrets for all API keys (already in place).
4. Never commit per-Tribe data files to the Pages repository -- only the final DOCX output and the web index.

**Severity:** DATA EXPOSURE RISK -- intermediate data visible in public repository.

---

## UX Pitfalls

---

### UX-1: "Generating" State is a 2-Second setTimeout, Not Real Generation

**What goes wrong:** Both `TribeSelector.tsx` (line 34: `setTimeout(() => { setStatus('ready'); }, 2000)`) and `RegionSelector.tsx` (line 19: `setTimeout(() => { setStatus('ready'); }, 2000)`) use a fake 2-second delay to simulate report generation. There is no actual backend call, no data processing, nothing happening during those 2 seconds.

When this is replaced with real download functionality (fetching a DOCX from GitHub Pages), the actual delay will depend on network speed. A fast connection will download in <1 second; a slow connection might take 5-10 seconds. The fake 2-second delay creates incorrect expectations.

**Prevention:**
1. Replace `setTimeout` with actual fetch/download logic. Show the spinner during the real network request.
2. If using pre-generated DOCX files (no server-side generation), skip the "generating" state entirely. Go directly from "idle" to "downloading" to "ready."
3. Rename the "PROCESSING" status to "DOWNLOADING" to accurately describe what is happening.
4. Add progress indication for large files if possible (though `fetch()` does not natively support progress on downloads without `ReadableStream`).

**Severity:** MISLEADING UX -- creates false impression of computation happening.

---

### UX-2: No Feedback When Tribe Is Not Found in 592-Nation Database

**What goes wrong:** If a user types a Tribal Nation name that does not match any of the 592 entries in `tribes.json` (e.g., a state-recognized but not federally-recognized Tribe, or a misspelling), the current autocomplete simply shows no suggestions. There is no "no results found" message. The user does not know whether:
- They misspelled the name
- Their Nation is not in the database
- The system is broken

**Prevention:**
1. Show "No Tribal Nations found matching [search term]" when the filter returns 0 results.
2. Add fuzzy matching (the backend already uses `rapidfuzz` -- port this concept to the frontend with a lightweight fuzzy search library like `fuse.js`).
3. Include alternate names/aliases from `tribal_aliases.json` (3,751 entries) in the searchable index.
4. Add a "Don't see your Nation?" link with contact information or an explanation of the 592 federally-recognized Tribes scope.

**Severity:** CONFUSING UX -- silent failure for Nations with non-standard names.

---

## "Looks Done But Isn't" Checklist

Items that pass casual inspection but fail under production conditions.

| Item | What Looks Done | What Is Actually Wrong | How to Verify |
|------|-----------------|------------------------|---------------|
| Download button | Button says "DOWNLOAD REPORT" and triggers a file download | Downloads a 200-byte text file, not a real DOCX | Open the file in Microsoft Word |
| Tribe search | Autocomplete shows suggestions and allows selection | Only 46 of 592 Tribes are searchable | Search for "Muckleshoot" (in registry but not in mockData) |
| Report generation | "PROCESSING" spinner shows for 2 seconds | No actual processing occurs, it is a setTimeout | Check Network tab -- zero requests during "PROCESSING" |
| SquareSpace embed | Embed code exists in HTML comments | Not tested inside actual SquareSpace iframe | Deploy and test in SquareSpace preview |
| DOCX download | Download link constructed correctly | May receive HTML 404 page saved as .docx | Open downloaded file in Word, check file size |
| Accessibility | Interactive elements are clickable | No ARIA roles, no keyboard navigation, no screen reader support | Try using the app with keyboard only |
| Mobile responsiveness | CSS uses clamp() for responsive sizing | Download behavior not tested on mobile (iOS/Android) | Test on actual mobile devices, not just DevTools emulation |
| Data freshness | Documents show "Generated: [date]" | Date is client-side JavaScript `new Date()`, not actual generation date | Check if date changes on every download (it should not) |
| Pagination | Scrapers return results | 3 of 4 scrapers return only first page of results | Compare scraper output count vs API total count |
| Font loading | Fonts render correctly in development | Fonts may load from Google CDN in production (sovereignty violation) | Check Network tab for `fonts.googleapis.com` requests |

---

## Pitfall-to-Phase Mapping

| Phase Topic | Pitfall | Severity | Priority |
|-------------|---------|----------|----------|
| **Fake Downloads Fix** | C-1: Text file downloads instead of DOCX | CRITICAL | P0 -- fix first |
| **Vite Deployment Config** | C-5: Base path not configured | CRITICAL | P0 -- fix first |
| **Mock Data Replacement** | TD-1: Only 46 of 592 Tribes visible | CRITICAL | P0 -- fix first |
| **SquareSpace Iframe Test** | M-6: X-Frame-Options may block embedding | MODERATE | P0 -- test first |
| **SquareSpace Iframe Test** | C-3: Sandbox blocks downloads | CRITICAL | P0 -- test first |
| **Scraper Pagination** | C-4: 3 scrapers silently truncate | CRITICAL | P1 -- data integrity |
| **Scraper Pagination** | M-4: Rate limiting during pagination | MODERATE | P1 -- paired with C-4 |
| **DOCX File Serving** | C-2: MIME type issues on GitHub Pages | CRITICAL | P1 -- deployment |
| **DOCX File Serving** | M-5: 404 hack delivers HTML as DOCX | MODERATE | P1 -- deployment |
| **Download Handler** | TD-2: No error handling for downloads | MODERATE | P1 -- UX |
| **Download Handler** | UX-1: Fake 2-second setTimeout | MODERATE | P1 -- UX |
| **Build Pipeline** | IG-3: Must merge Vite + Python outputs | CRITICAL | P1 -- deployment |
| **Build Pipeline** | IG-1: tribes.json must follow batch generation | MODERATE | P1 -- deployment |
| **Accessibility** | M-1: WCAG 2.1 AA failures throughout | MODERATE | P2 -- compliance |
| **Data Sovereignty** | C-6: Third-party tracking scripts | CRITICAL | P2 -- every deployment |
| **Confidence Scoring** | M-3: Overconfidence bias risk | MODERATE | P2 -- calibration |
| **Repository Size** | M-2: 592 DOCX files in git history | MODERATE | P3 -- infrastructure |
| **Performance** | PT-1: Large JSON on page load | LOW | P3 -- optimization |
| **Performance** | PT-2: Concurrent users during events | LOW | P3 -- monitoring |
| **Security** | S-1: Repository history exposure | LOW | P3 -- hygiene |
| **UX Polish** | UX-2: No feedback for unfound Tribes | LOW | P3 -- polish |

---

## Sources

### Verified (HIGH confidence)

- **Codebase inspection:** `TribeSelector.tsx`, `RegionSelector.tsx`, `mockData.ts`, `App.tsx`, `vite.config.ts`, `package.json`, `index.html`, `build_web_index.py`, `docx_engine.py`, `congress_gov.py`, `federal_register.py`, `grants_gov.py`, `usaspending.py`, `base.py`
- **v1.1 Milestone Audit** (`.planning/milestones/v1.1-MILESTONE-AUDIT.md`): 287 tests, 22/22 requirements
- **v1.2 Milestone Audit** (`.planning/milestones/v1.2-MILESTONE-AUDIT.md`): 743 tests, 24/24 requirements
- **Confidence Scoring Proposal** (`docs/proposals/confidence-scoring.md`): Tier model, freshness decay, DOCX rendering plan
- **[GitHub Pages Limits](https://docs.github.com/en/pages/getting-started-with-github-pages/github-pages-limits):** 1 GB site size, 100 GB/month bandwidth, 10 builds/hour
- **[W3C WAI-ARIA Combobox Pattern](https://www.w3.org/WAI/ARIA/apg/patterns/combobox/examples/combobox-autocomplete-list/):** Required ARIA roles for autocomplete
- **[MDN: aria-autocomplete](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/Reference/Attributes/aria-autocomplete):** Inline, list, and both modes
- **[MDN: Content-Security-Policy sandbox](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Content-Security-Policy/sandbox):** Sandbox attribute flags including allow-downloads
- **[Chrome Platform Status: Downloads in Sandboxed Iframes](https://chromestatus.com/feature/5706745674465280):** Chrome 83+ blocks downloads without allow-downloads flag

### Partially verified (MEDIUM confidence)

- **[Deploy Vite React to GitHub Pages](https://paulserban.eu/blog/post/deploy-vite-react-with-react-router-app-to-github-pages/):** Base path configuration and 404.html hack
- **[GitHub Pages SPA Hack](https://github.com/rafgraph/spa-github-pages):** Session storage redirect approach for SPA routing
- **[Vite Plugin GitHub Pages SPA](https://github.com/sctg-development/vite-plugin-github-pages-spa):** Automated 404.html generation for Vite
- **[SquareSpace Embed Blocks Help](https://support.squarespace.com/hc/en-us/articles/206543617-Embed-blocks):** oEmbed standard, Code Block vs Embed Block
- **[SquareSpace Code Blocks Help](https://support.squarespace.com/hc/en-us/articles/206543167-Code-blocks):** JavaScript and iframe support requirements
- **[CARE Principles for Indigenous Data Governance](https://datascience.codata.org/articles/dsj-2020-043):** Authority to Control, Ethics
- **[FNIGC OCAP Principles](https://fnigc.ca/ocap-training/):** Ownership, Control, Access, Possession
- **[Understanding Miscalibrated AI Confidence (arXiv)](https://arxiv.org/abs/2402.07632):** Users over-rely on overconfident AI, under-rely on underconfident AI
- **[DOCX MIME type misidentification (GitHub)](https://github.com/transloadit/uppy/issues/732):** DOCX detected as application/zip
- **[Apify Pagination Guide](https://docs.apify.com/academy/api-scraping/general-api-scraping/handling-pagination):** Offset vs cursor, safety caps

### Training data only (LOW confidence -- needs validation)

- GitHub Pages specific behavior with `X-Frame-Options` headers for iframe embedding (needs empirical test with actual deployed site)
- SquareSpace-specific sandbox attribute behavior for Code Block iframes (needs testing in live SquareSpace environment)
- DOCX MIME type behavior on GitHub Pages specifically (needs verification with actual deployed `.docx` file -- may work correctly)
- Concurrent user behavior at 100-200 users on GitHub Pages (no published benchmarks; 100 GB/month limit is documented but per-second throttling is not)
