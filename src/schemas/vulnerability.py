"""Pydantic v2 vulnerability assessment models for TCR Policy Scanner.

Defines data contracts for the v1.4 Climate Vulnerability Intelligence
pipeline. All downstream builders, renderers, and pipeline components
code against these schemas.

Models:
- DataGapType: 6-value enum for gap classification
- InvestmentPriorityTier: 5-tier enum with from_score() classifier
- NRIExpanded: FEMA NRI expanded risk profile with field clamping
- SVITheme: CDC SVI individual theme profile (-999 sentinel rejection)
- SVIProfile: Multi-theme SVI composite (max 3 themes, mean consistency)
- CompositeComponent: Weighted vulnerability component
- CompositeScore: 3-component composite with tier/score consistency
- VulnerabilityProfile: Top-level per-Tribe vulnerability container

Data sources modeled:
- FEMA NRI v1.20 county-level risk data -> NRIExpanded
- CDC SVI 2022 Tribal tract data -> SVITheme, SVIProfile
- Composite formula (0.40 hazard + 0.35 social + 0.25 adaptive) -> CompositeScore
- Per-Tribe vulnerability_profiles/*.json -> VulnerabilityProfile

REG-03: Schema-first approach. Schema violations are bugs, not warnings.
"""

from __future__ import annotations

from enum import StrEnum
from typing import Optional

from pydantic import BaseModel, Field, field_validator, model_validator


# ── Enums ──


class DataGapType(StrEnum):
    """Classification of data gaps in vulnerability profiles.

    Used to document missing or partial data at both the component
    and profile level. Data gaps inform confidence scoring and
    narrative generation for Alaska and other partial-coverage areas.
    """

    MISSING_SVI = "MISSING_SVI"
    PARTIAL_NRI = "PARTIAL_NRI"
    ZERO_AREA_WEIGHT = "ZERO_AREA_WEIGHT"
    ALASKA_PARTIAL = "ALASKA_PARTIAL"
    NO_COASTAL_DATA = "NO_COASTAL_DATA"
    SOURCE_UNAVAILABLE = "SOURCE_UNAVAILABLE"


class InvestmentPriorityTier(StrEnum):
    """Climate Resilience Investment Priority tier classification.

    Tiers classify composite vulnerability scores into actionable
    categories for advocacy prioritization. Boundaries use >= for
    tier assignment (e.g., score=0.80 -> CRITICAL, not HIGH).

    Framing per DEC-05 (Hybrid Option D): "Climate Resilience
    Investment Priority" headings, not "vulnerability level."
    """

    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    ELEVATED = "ELEVATED"
    MODERATE = "MODERATE"
    LOW = "LOW"

    @classmethod
    def from_score(cls, score: float) -> InvestmentPriorityTier:
        """Classify a composite vulnerability score into a tier.

        Boundaries (>= comparison, checked top-down):
        - CRITICAL: score >= 0.80
        - HIGH:     score >= 0.60
        - ELEVATED: score >= 0.40
        - MODERATE: score >= 0.20
        - LOW:      score < 0.20
        """
        if score >= 0.80:
            return cls.CRITICAL
        if score >= 0.60:
            return cls.HIGH
        if score >= 0.40:
            return cls.ELEVATED
        if score >= 0.20:
            return cls.MODERATE
        return cls.LOW


# ── NRI Expanded Risk Profile ──


class NRIExpanded(BaseModel):
    """Expanded FEMA National Risk Index profile for a Tribal Nation.

    Contains per-Tribe NRI risk data derived from county-level FEMA NRI
    v1.20 records geocoded via AIANNH boundary overlap. Fields include
    risk score, percentile ranking, Expected Annual Loss breakdowns,
    social vulnerability and community resilience indices, and top hazards.

    Key validation:
    - risk_percentile is clamped to [0.0, 100.0] (mode="before")
    - tribe_id must start with "epa_"
    - top_hazards max 5 entries
    - coverage_pct in [0.0, 1.0]
    """

    tribe_id: str = Field(
        ...,
        description="EPA Tribal identifier (format: epa_XXXXXXXXX)",
        examples=["epa_100000001"],
    )
    risk_score: float = Field(
        ...,
        ge=0.0,
        description="Composite NRI risk score (area-weighted across overlapping counties)",
    )
    risk_percentile: float = Field(
        ...,
        description="National percentile rank of risk score (0.0-100.0, clamped)",
    )
    eal_total: float = Field(
        ...,
        ge=0.0,
        description="Total Expected Annual Loss in USD across all hazards",
    )
    eal_buildings: float = Field(
        ...,
        ge=0.0,
        description="Expected Annual Loss to buildings in USD",
    )
    eal_population: float = Field(
        ...,
        ge=0.0,
        description="Expected Annual Loss to population in USD",
    )
    eal_agriculture: float = Field(
        ...,
        ge=0.0,
        description="Expected Annual Loss to agriculture in USD",
    )
    eal_population_equivalence: float = Field(
        ...,
        ge=0.0,
        description="Expected Annual Loss population equivalence in USD",
    )
    community_resilience: float = Field(
        ...,
        ge=0.0,
        le=100.0,
        description="Community Resilience score (0.0-100.0)",
    )
    social_vulnerability_nri: float = Field(
        ...,
        ge=0.0,
        le=100.0,
        description="NRI Social Vulnerability Index score (0.0-100.0)",
    )
    hazard_count: int = Field(
        ...,
        ge=0,
        description="Number of distinct hazard types with nonzero risk",
    )
    top_hazards: list[dict] = Field(
        ...,
        max_length=5,
        description="Top hazards ranked by risk score (max 5)",
    )
    coverage_pct: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Fraction of Tribal land area covered by NRI data (0.0-1.0)",
    )

    @field_validator("risk_percentile", mode="before")
    @classmethod
    def clamp_risk_percentile(cls, v: float) -> float:
        """Clamp risk_percentile to [0.0, 100.0].

        NRI percentile data occasionally exceeds bounds due to
        area-weighted interpolation across county boundaries.
        """
        if v < 0.0:
            return 0.0
        if v > 100.0:
            return 100.0
        return v

    @field_validator("tribe_id")
    @classmethod
    def validate_tribe_id_format(cls, v: str) -> str:
        """Ensure tribe_id starts with 'epa_'."""
        if not v.startswith("epa_"):
            raise ValueError(f"tribe_id must start with 'epa_', got '{v}'")
        return v


# ── SVI Theme and Profile ──


VALID_SVI_THEME_IDS = frozenset({"theme1", "theme2", "theme4"})
"""Valid SVI theme IDs.

Theme 3 (Racial & Ethnic Minority Status) is excluded per DEC-02:
Tribal SVI uses custom composite from Themes 1+2+4 average only.
"""


class SVITheme(BaseModel):
    """CDC Social Vulnerability Index individual theme profile.

    Each theme represents one dimension of social vulnerability.
    Valid themes for Tribal SVI (per DEC-02):
    - theme1: Socioeconomic Status
    - theme2: Household Characteristics & Disability
    - theme4: Housing Type & Transportation

    Theme 3 (Racial & Ethnic Minority Status) is excluded.
    Percentile of -999 (CDC sentinel for suppressed data) is rejected.
    """

    theme_id: str = Field(
        ...,
        description="SVI theme identifier (theme1, theme2, or theme4)",
        examples=["theme1", "theme2", "theme4"],
    )
    name: str = Field(
        ...,
        description="Human-readable theme name",
        examples=["Socioeconomic Status"],
    )
    percentile: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Theme percentile ranking (0.0-1.0). -999 sentinel rejected.",
    )
    flag_count: int = Field(
        ...,
        ge=0,
        description="Number of flagged indicators within this theme",
    )

    @field_validator("theme_id")
    @classmethod
    def validate_theme_id(cls, v: str) -> str:
        """Ensure theme_id is one of theme1, theme2, theme4."""
        if v not in VALID_SVI_THEME_IDS:
            raise ValueError(
                f"Invalid theme_id '{v}'. Must be one of: {sorted(VALID_SVI_THEME_IDS)}. "
                f"Theme 3 excluded per Tribal SVI design (DEC-02)."
            )
        return v

    @field_validator("percentile", mode="before")
    @classmethod
    def reject_sentinel_value(cls, v: float) -> float:
        """Reject CDC -999 sentinel value for suppressed data."""
        if v == -999 or v == -999.0:
            raise ValueError(
                "Percentile value -999 is a CDC sentinel for suppressed data. "
                "Cannot use suppressed SVI data in vulnerability profiles."
            )
        return v


class SVIProfile(BaseModel):
    """Multi-theme SVI composite profile for a Tribal Nation.

    Aggregates up to 3 SVI themes (1, 2, 4) into a composite percentile.
    The composite must equal the arithmetic mean of theme percentiles
    within 0.01 tolerance.

    Validation:
    - Max 3 themes (Themes 1, 2, 4 only)
    - Composite must match mean(theme percentiles) within 0.01
    - tribe_id must start with "epa_"
    """

    tribe_id: str = Field(
        ...,
        description="EPA Tribal identifier",
        examples=["epa_100000001"],
    )
    themes: list[SVITheme] = Field(
        ...,
        max_length=3,
        description="SVI themes (max 3: theme1, theme2, theme4)",
    )
    composite: float = Field(
        ...,
        description="Composite SVI percentile (mean of theme percentiles)",
    )
    coverage_pct: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Fraction of Tribal area covered by SVI tract data",
    )
    source_year: int = Field(
        default=2022,
        description="CDC SVI data release year",
    )
    data_gaps: list[DataGapType] = Field(
        default_factory=list,
        description="Data gaps affecting this SVI profile",
    )

    @field_validator("tribe_id")
    @classmethod
    def validate_tribe_id_format(cls, v: str) -> str:
        """Ensure tribe_id starts with 'epa_'."""
        if not v.startswith("epa_"):
            raise ValueError(f"tribe_id must start with 'epa_', got '{v}'")
        return v

    @model_validator(mode="after")
    def validate_composite_mean(self) -> "SVIProfile":
        """Ensure composite matches mean of theme percentiles within 0.01 tolerance."""
        if not self.themes:
            # No themes means composite should be 0.0
            if abs(self.composite) > 0.01:
                raise ValueError(
                    f"composite must be ~0.0 when no themes present, got {self.composite}"
                )
            return self

        actual_mean = sum(t.percentile for t in self.themes) / len(self.themes)
        if abs(self.composite - actual_mean) > 0.01:
            raise ValueError(
                f"composite ({self.composite}) does not match mean of theme "
                f"percentiles ({actual_mean:.4f}). Tolerance: 0.01."
            )
        return self


# ── Composite Vulnerability Score ──


VALID_COMPONENT_NAMES = frozenset({
    "hazard_exposure",
    "social_vulnerability",
    "adaptive_capacity_deficit",
})
"""Valid composite component names per DEC-04.

3-component formula: 0.40 hazard + 0.35 social + 0.25 adaptive capacity deficit.
"""


class CompositeComponent(BaseModel):
    """Single weighted component of the composite vulnerability score.

    Three components per DEC-04:
    - hazard_exposure (base weight 0.40): FEMA NRI risk score
    - social_vulnerability (base weight 0.35): CDC SVI composite
    - adaptive_capacity_deficit (base weight 0.25): inverse of resilience

    When a component is unavailable (available=False), its weight is
    redistributed proportionally to available components.
    """

    component: str = Field(
        ...,
        description="Component identifier",
        examples=["hazard_exposure", "social_vulnerability", "adaptive_capacity_deficit"],
    )
    raw_score: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Normalized component score (0.0-1.0)",
    )
    base_weight: float = Field(
        ...,
        description="Default weight before redistribution",
    )
    weight: float = Field(
        ...,
        description="Actual weight after redistribution (may differ if components unavailable)",
    )
    weighted_score: float = Field(
        ...,
        description="raw_score * weight",
    )
    available: bool = Field(
        default=True,
        description="Whether this component has data available",
    )

    @field_validator("component")
    @classmethod
    def validate_component_name(cls, v: str) -> str:
        """Ensure component is one of the 3 valid names."""
        if v not in VALID_COMPONENT_NAMES:
            raise ValueError(
                f"Invalid component '{v}'. Must be one of: {sorted(VALID_COMPONENT_NAMES)}"
            )
        return v


class CompositeScore(BaseModel):
    """Composite vulnerability score combining 3 weighted components.

    The composite score (0.0-1.0) maps to an InvestmentPriorityTier
    via from_score(). The tier field must be consistent with the score.

    Validation:
    - score in [0.0, 1.0]
    - tier must match InvestmentPriorityTier.from_score(score)
    """

    score: float = Field(
        ...,
        ge=0.0,
        le=1.0,
        description="Composite vulnerability score (0.0-1.0)",
    )
    tier: str = Field(
        ...,
        description="Investment priority tier (must match from_score(score))",
        examples=["CRITICAL", "HIGH", "ELEVATED", "MODERATE", "LOW"],
    )
    data_completeness: float = Field(
        ...,
        description="Fraction of data sources available (0.0-1.0)",
    )
    components: list[CompositeComponent] = Field(
        ...,
        description="Weighted components of the composite score",
    )

    @model_validator(mode="after")
    def validate_tier_score_consistency(self) -> "CompositeScore":
        """Ensure tier matches InvestmentPriorityTier.from_score(score)."""
        expected_tier = InvestmentPriorityTier.from_score(self.score)
        if self.tier != expected_tier.value:
            raise ValueError(
                f"tier '{self.tier}' does not match expected tier "
                f"'{expected_tier.value}' for score {self.score}. "
                f"Use InvestmentPriorityTier.from_score() for classification."
            )
        return self


# ── Top-Level Vulnerability Profile ──


class VulnerabilityProfile(BaseModel):
    """Per-Tribe vulnerability profile combining NRI, SVI, and composite scores.

    Top-level container for all vulnerability assessment data. Maps to
    vulnerability_profiles/{tribe_id}.json. Consumed by Doc E renderer
    and website visualization pipeline.

    All sub-profiles (nri, svi, composite) are optional to support
    incremental data population and partial-coverage Tribal Nations.
    """

    tribe_id: str = Field(
        ...,
        description="EPA Tribal identifier",
        examples=["epa_100000001"],
    )
    tribe_name: str = Field(
        ...,
        description="Official Tribal Nation name",
        examples=["Confederated Tribes of Grand Ronde"],
    )
    nri: Optional[NRIExpanded] = Field(
        default=None,
        description="FEMA NRI expanded risk profile (None if no NRI data)",
    )
    svi: Optional[SVIProfile] = Field(
        default=None,
        description="CDC SVI multi-theme profile (None if no SVI data)",
    )
    composite: Optional[CompositeScore] = Field(
        default=None,
        description="Composite vulnerability score (None if insufficient data)",
    )
    is_coastal: bool = Field(
        default=False,
        description="Whether the Tribal Nation has coastal exposure",
    )
    data_gaps: list[DataGapType] = Field(
        default_factory=list,
        description="Aggregate data gaps across all sub-profiles",
    )
    previous_tier: Optional[str] = Field(
        default=None,
        description="Previous assessment tier for trend tracking (None if first assessment)",
    )
    generated_at: str = Field(
        ...,
        description="ISO 8601 timestamp of profile generation",
        examples=["2026-02-17T12:00:00+00:00"],
    )
    nri_version: str = Field(
        ...,
        description="FEMA NRI data version used",
        examples=["1.20"],
    )
    svi_version: str = Field(
        ...,
        description="CDC SVI data release year",
        examples=["2022"],
    )

    @field_validator("tribe_id")
    @classmethod
    def validate_tribe_id_format(cls, v: str) -> str:
        """Ensure tribe_id starts with 'epa_'."""
        if not v.startswith("epa_"):
            raise ValueError(f"tribe_id must start with 'epa_', got '{v}'")
        return v
